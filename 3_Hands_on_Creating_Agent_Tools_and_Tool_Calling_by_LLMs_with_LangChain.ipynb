{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Tools in LangChain"
      ],
      "metadata": {
        "id": "-CVPAiNAy9MH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ],
      "metadata": {
        "id": "L1KvMtf54l0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "yXgPP-n3lDy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain  # ==0.3.14\n",
        "!pip install langchain-openai # ==0.3.0\n",
        "!pip install langchain-community # ==0.3.14"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2evPp14fy258",
        "outputId": "3e84614a-17b5-4a82-c6f6-050038909fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.24)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.76 (from langchain-openai)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.106.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "Successfully installed langchain-core-0.3.76 langchain-openai-0.3.33\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.24)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Data Extraction APIs"
      ],
      "metadata": {
        "id": "TlfidBdQZRGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to create custom tools\n",
        "!pip install wikipedia # ==1.4.0\n",
        "!pip install markitdown\n",
        "# to highlight json\n",
        "!pip install rich"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZKQDgQURhmF",
        "outputId": "0e4f9b35-31bc-4cb4-9b88-38afc56f5f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=cce98182f11efaca20f100a39444ebb7c0024051f972a849a347f1e5f5fc8506\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Collecting markitdown\n",
            "  Downloading markitdown-0.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown) (3.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown) (0.7.1)\n",
            "Collecting magika~=0.6.1 (from markitdown)\n",
            "  Downloading magika-0.6.2-py3-none-manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
            "Collecting markdownify (from markitdown)\n",
            "  Downloading markdownify-1.2.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown) (2.32.5)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown) (8.2.1)\n",
            "Collecting onnxruntime>=1.17.0 (from magika~=0.6.1->markitdown)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown) (1.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown) (2025.8.3)\n",
            "Collecting coloredlogs (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.13.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.17.0->magika~=0.6.1->markitdown)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.3.0)\n",
            "Downloading markitdown-0.1.3-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magika-0.6.2-py3-none-manylinux_2_28_x86_64.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-1.2.0-py3-none-any.whl (15 kB)\n",
            "Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, markdownify, coloredlogs, onnxruntime, magika, markitdown\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 magika-0.6.2 markdownify-1.2.0 markitdown-0.1.3 onnxruntime-1.22.1\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Get a free API key from [here](https://tavily.com/#api)\n",
        "\n",
        "- Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
      ],
      "metadata": {
        "id": "ory1TRS3gpTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')\n",
        "os.environ['WEATHER_API_KEY'] = userdata.get('WEATHER_API_KEY')"
      ],
      "metadata": {
        "id": "MxSMZ1Z5gMn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Built-in Tools"
      ],
      "metadata": {
        "id": "65C3PellZGYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the Wikipedia Tool\n",
        "\n",
        "Enables you to tap into the Wikipedia API to search wikipedia pages for information"
      ],
      "metadata": {
        "id": "howf-v0ARWbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "wiki_api_wrapper = WikipediaAPIWrapper(top_k_results=3,\n",
        "                                       doc_content_chars_max=8000)\n",
        "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api_wrapper, features=\"lxml\")"
      ],
      "metadata": {
        "id": "q2CMhK9Rjk2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_tool.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "t1Ce8wbYodYO",
        "outputId": "65832245-ae5f-4463-bc21-0063cfc4a10d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_tool.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2MSVAh2osSE",
        "outputId": "0cdb9cac-42b7-48bd-e353-e65e9588865b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': {'description': 'query to look up on wikipedia',\n",
              "  'title': 'Query',\n",
              "  'type': 'string'}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wiki_tool.invoke({\"query\": \"ISRO\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luhjlzeSkgUq",
        "outputId": "45a3932d-3190-4042-927d-2e8ae0a88a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: ISRO\n",
            "Summary: The Indian Space Research Organisation (ISRO ) is India's national space agency, headquartered in Bengaluru, Karnataka. It serves as the principal research and development arm of the Department of Space (DoS), overseen by the Prime Minister of India, with the Chairman of ISRO also serving as the chief executive of the DoS. It is primarily responsible for space-based operations, space exploration, international space cooperation and the development of related technologies. The agency maintains a constellation of imaging, communications and remote sensing satellites. It operates the GAGAN and IRNSS satellite navigation systems. It has sent three missions to the Moon and one mission to Mars.\n",
            "Formerly, ISRO was known as the Indian National Committee for Space Research (INCOSPAR), which was set up in 1962 by then-Prime Minister Jawaharlal Nehru on the recommendation of scientist Vikram Sarabhai. It was renamed as ISRO in 1969 and was subsumed into the Department of Atomic Energy (DAE). The establishment of ISRO institutionalised space research activities in India. In 1972, the Government set up a Space Commission and the DoS bringing ISRO under its purview. It has since then been managed by the DoS, which also governs various other institutions in the domain of astronomy and space technology.\n",
            "ISRO built India's first satellite Aryabhata which was launched by the Soviet space agency Interkosmos in 1975. In 1980, it launched the satellite RS-1 on board the indigenously built launch vehicle SLV-3, making India the seventh country to undertake orbital launches. It has subsequently developed various small-lift and medium-lift launch vehicles, enabling the agency to launch various satellites and deep space missions. It is one of the six government space agencies in the world that possess full launch capabilities with the ability to deploy cryogenic engines, launch extraterrestrial missions and artificial satellites. It is also the only one of the four governmental space agencies to have demonstrated unmanned soft landing capabilities.\n",
            "ISRO's programmes have played a significant role in socio-economic development. It has supported both civilian and military domains in various aspects such as disaster management, telemedicine, navigation and reconnaissance. ISRO's spin-off technologies have also aided in new innovations in engineering and other allied domains.\n",
            "\n",
            "\n",
            "\n",
            "Page: Chairperson of ISRO\n",
            "Summary: The Chairperson of the Indian Space Research Organisation is the statutory head of ISRO. The officeholder is a secretary to the Government of India and an executive of the Department of Space (DoS) which directly reports to the Prime Minister of India.\n",
            "The Indian National Committee for Space Research (INCOSPAR) was founded in 1962 under the Department of Atomic Energy (DAE) with Vikram Sarabhai as its chairperson which in 1969 became ISRO. In 1972, government of India had set up a space commission and DoS and brought ISRO under DoS.\n",
            "Since Sarabhai has assumed the position, there have been eleven chairmen of the ISRO, with Satish Dhawan serving the longest term of 12 years as the chairman.\n",
            "Recently on 8 January 2025, The Central Government has appointed Dr. V. Narayanan, currently the director of Liquid Propulsion Systems Centre (LPSC), Thiruvananthapuram, as the new chairperson of ISRO, and also as the secretary of the DoS.\n",
            "\n",
            "Page: List of ISRO missions\n",
            "Summary: This is a list of ISRO missions. ISRO has carried out 131 spacecraft missions, 101 launch missions and planned several missions including the Gaganyaan (crewed/robotic) and Interplanetary mission such as Lunar Polar Exploration Mission, Chandrayaan-4, Shukrayaan and Mars Lander Mission.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wiki_tool.invoke({\"query\": \"Make in India\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jglV7GRXjk5O",
        "outputId": "5d352682-3000-4849-fa85-0b0d8b8db4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: Make in India\n",
            "Summary: Make in India is an initiative by the Government of India to create and encourage companies to develop, manufacture and assemble products in India and incentivize dedicated investments into manufacturing. The policy approach was to create a conducive environment for investments, develop a modern and efficient infrastructure, and open up new sectors for foreign capital.\n",
            "Make in India has been unsuccessful at achieving its stated targets. Under this programme, the share of manufacturing in GDP was projected to reach 25% by 2022. However, the GDP share of manufacturing has actually fallen from 16.7% in 2013–2014 to 15.9% in 2023–2024.\n",
            "\n",
            "Page: India\n",
            "Summary: India, officially the Republic of India, is a country in South Asia.  It is the seventh-largest country by area; the most populous country since 2023; and, since its independence in 1947, the world's most populous democracy. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is near Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Myanmar, Thailand, and Indonesia.\n",
            "Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago. Their long occupation, predominantly in isolation as hunter-gatherers, has made the region highly diverse. Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE. By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest. Its hymns recorded the early dawnings of Hinduism in India. India's pre-existing Dravidian languages were supplanted in the northern regions. By 400 BCE, caste had emerged within Hinduism, and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity. Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires. Widespread creativity suffused this era, but the status of women declined, and untouchability became an organised belief. In South India, the Middle kingdoms exported Dravidian language scripts and religious cultures to the kingdoms of Southeast Asia.\n",
            "In the early medieval era, Christianity, Islam, Judaism, and Zoroastrianism became established on India's southern and western coasts. Muslim armies from Central Asia intermittently overran India's northern plains in the second millennium. The resulting Delhi Sultanate drew northern India into the cosmopolitan networks of medieval Islam. In south India, the Vijayanagara Empire created a long-lasting composite Hindu culture. In the Punjab, Sikhism emerged, rejecting institutionalised religion. The Mughal Empire ushered in two centuries of economic expansion and relative peace, leaving a rich architectural legacy. Gradually expanding rule of the British East India Company turned India into a colonial economy but consolidated its sovereignty. British Crown rule began in 1858. The rights promised to Indians were granted slowly, but technological changes were introduced, and modern ideas of education and the public life took root. A nationalist movement emerged in India, the first in the non-European British empire and an influence on other nationalist movements. Noted for nonviolent resistance after 1920, it became the primary factor in ending British rule. In 1947, the British Indian Empire was partitioned into two independent dominions, a Hindu-majority dominion of India and a Muslim-majority dominion of Pakistan. A large-scale loss of life and an unprecedented migration accompanied the partition.\n",
            "India has been a federal republic since 1950, governed through a democratic parliamentary system. It is a pluralistic, multilingual and multi-ethnic society. India's population grew from 361 million in 1951 to over 1.4 billion in 2023. During this time, its nominal per capita income increased from US$64 annually to US$2,601, and its literacy rate from 16.6% to 74%. A comparatively destitute country in 1951, India has become a fast-growing major economy and a hub for information technology services, with an expanding middle class. Indian movies and music increasingly influence global culture. India has reduced its poverty rate, though at the cost of increasing economic inequality. It is a nuclear-weapon state that ranks high in military expenditure. It has disputes over Kashmir with its neighbours, Pakistan and China, unresolved since the mid-20th century. Among the socio-economic challenges India faces are gender inequality, child malnutrition, and rising levels of air pollution. India's land is megadiverse with four biodiversity hotspots. India's wildlife, which has traditionally been viewed with tolerance in its culture, is supported in protected habitats.\n",
            "\n",
            "Page: Skill India\n",
            "Summary: Skill India or the National Skills Development Mission of India is a campaign launched by Prime Minister Narendra Modi. It is managed by the National Skills Development Corporation of India.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " You can customize the default tool with its own name, description and so on as follows"
      ],
      "metadata": {
        "id": "LnfMeoXJVn-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "wiki_tool_init = Tool(name=\"Wikipedia\",\n",
        "                      func=wiki_api_wrapper.run,\n",
        "                      description=\"useful when you need a detailed answer about general knowledge\")"
      ],
      "metadata": {
        "id": "1tO5g9Q1jk7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_tool_init.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZRTfVUuGo7ti",
        "outputId": "82dbd42d-bfa9-4899-8dec-0775178031ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'useful when you need a detailed answer about general knowledge'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_tool_init.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW0emMEIou-L",
        "outputId": "830941e4-800a-41df-8a77-6b02fa71e6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tool_input': {'type': 'string'}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wiki_tool_init.invoke({\"tool_input\": \"Generative AI\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgAwdPrBjk-x",
        "outputId": "c6e52506-3333-48b3-a210-bb8fd8d47bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: Generative AI pornography\n",
            "Summary: Generative AI pornography or simply AI pornography is a digitally created pornography produced through generative artificial intelligence (AI) technologies. Unlike traditional pornography, which involves real actors and cameras, this content is synthesized entirely by AI algorithms. These algorithms, including Generative adversarial network (GANs) and text-to-image models, generate lifelike images, videos, or animations from textual descriptions or datasets.\n",
            "\n",
            "Page: Generative artificial intelligence\n",
            "Summary: Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\n",
            "Generative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora. Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, DeepSeek, and Baidu. \n",
            "Generative AI is used across many industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling. \n",
            "Generative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.\n",
            "\n",
            "Page: Artificial intelligence\n",
            "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\n",
            "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
            "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as a human.\n",
            "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms, which has raised ethical concerns about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the Tavily Search Tool\n",
        "\n",
        "Tavily Search API is a search engine optimized for LLMs and RAG, aimed at efficient, quick and persistent search results"
      ],
      "metadata": {
        "id": "cnQfnkQeV7Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=8,\n",
        "                                search_depth='advanced',\n",
        "                                include_raw_content=True)"
      ],
      "metadata": {
        "id": "UjWM95p5pB4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cb5a44-6d55-48a1-a4ac-d1dd10ffa4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2367757474.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tavily_tool = TavilySearchResults(max_results=8,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tavily_tool.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmawzibmjlC6",
        "outputId": "2e6002bd-6bb9-4128-8943-7cf003c5081f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': {'description': 'search query to look up',\n",
              "  'title': 'Query',\n",
              "  'type': 'string'}}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tavily_tool.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "eERoFFoPjlGJ",
        "outputId": "1935865d-f29b-43be-bfa6-71d29ada7283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = tavily_tool.invoke(\"Tell me about Model Context Protocol\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khqWQVcvrnG9",
        "outputId": "4d1e1766-b047-438b-9662-c6bd2b1778b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'Model Context Protocol',\n",
              "  'url': 'https://en.wikipedia.org/wiki/Model_Context_Protocol',\n",
              "  'content': 'The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google [...] MCP defines a standardized framework for integrating AI systems with external data sources and tools. It includes specifications for data ingestion and transformation \"Data transformation (computing)\"), contextual metadata tagging \"Tag (metadata)\"), and AI interoperability across different platforms. The protocol also supports secure, bidirectional connections between data sources and AI-powered tools. [...] ## Background\\n\\n[edit]\\n\\nThe protocol was announced by Anthropic in November 2024 as an open standard for connecting AI assistants to data systems such as content repositories, business management tools, and development environments. It aims to address the challenge of information silos and legacy systems. Before MCP, developers often had to build custom connectors for each data source or tool, resulting in what Anthropic described as an \"N×M\" data integration problem.',\n",
              "  'score': 0.93309647,\n",
              "  'raw_content': '[Jump to content](#bodyContent)\\n\\n# Model Context Protocol\\n\\n* [Català](https://ca.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol – Catalan\")\\n* [Deutsch](https://de.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol – German\")\\n* [Español](https://es.wikipedia.org/wiki/Protocolo_de_Contexto_de_Modelo \"Protocolo de Contexto de Modelo – Spanish\")\\n* [فارسی](https://fa.wikipedia.org/wiki/%D9%BE%D8%B1%D9%88%D8%AA%DA%A9%D9%84_%D8%B2%D9%85%DB%8C%D9%86%D9%87_%D9%85%D8%AF%D9%84 \"پروتکل زمینه مدل – Persian\")\\n* [Français](https://fr.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol – French\")\\n* [한국어](https://ko.wikipedia.org/wiki/%EB%AA%A8%EB%8D%B8_%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8_%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C \"모델 컨텍스트 프로토콜 – Korean\")\\n* [Italiano](https://it.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol – Italian\")\\n* [עברית](https://he.wikipedia.org/wiki/%D7%A4%D7%A8%D7%95%D7%98%D7%95%D7%A7%D7%95%D7%9C_%D7%94%D7%A7%D7%A9%D7%A8_%D7%9E%D7%95%D7%93%D7%9C \"פרוטוקול הקשר מודל – Hebrew\")\\n* [Nederlands](https://nl.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol – Dutch\")\\n* [日本語](https://ja.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol – Japanese\")\\n* [Norsk bokmål](https://no.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol – Norwegian Bokmål\")\\n* [Polski](https://pl.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol – Polish\")\\n* [Русский](https://ru.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol – Russian\")\\n* [Tiếng Việt](https://vi.wikipedia.org/wiki/Model_Context_Protocol \"Model Context Protocol – Vietnamese\")\\n* [中文](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE \"模型上下文协议 – Chinese\")\\n* [ⵜⴰⵎⴰⵣⵉⵖⵜ ⵜⴰⵏⴰⵡⴰⵢⵜ](https://zgh.wikipedia.org/wiki/%E2%B4%B0%E2%B4%B1%E2%B5%94%E2%B5%93%E2%B5%9C%E2%B5%93%E2%B4%BD%E2%B5%93%E2%B5%8D_%E2%B5%8F_%E2%B5%93%E2%B5%8E%E2%B5%8F%E2%B4%B0%E2%B4%B9_%E2%B5%8F_%E2%B5%93%E2%B5%A3%E2%B5%93%E2%B5%94%E2%B5%9C \"ⴰⴱⵔⵓⵜⵓⴽⵓⵍ ⵏ ⵓⵎⵏⴰⴹ ⵏ ⵓⵣⵓⵔⵜ – Standard Moroccan Tamazight\")\\n\\n[Edit links](https://www.wikidata.org/wiki/Special:EntityPage/Q133436854#sitelinks-wikipedia \"Edit interlanguage links\")\\n\\nFrom Wikipedia, the free encyclopedia\\n\\nProtocol for communicating between LLMs and applications\\n\\nModel Context Protocol\\n\\n| Developed by | [Anthropic](/wiki/Anthropic \"Anthropic\") |\\n| Introduced | November\\xa025,\\xa02024\\xa0(2024-11-25) |\\n| Website | [modelcontextprotocol.io](https://modelcontextprotocol.io/) |\\n\\nThe **Model Context Protocol** (**MCP**) is an [open standard](/wiki/Open_standard \"Open standard\"), [open-source](/wiki/Open-source \"Open-source\") [framework](/wiki/Software_framework \"Software framework\") introduced by [Anthropic](/wiki/Anthropic \"Anthropic\") in November 2024 to standardize the way [artificial intelligence](/wiki/Artificial_intelligence \"Artificial intelligence\") (AI) systems like [large language models](/wiki/Large_language_model \"Large language model\") (LLMs) integrate and share data with external tools, systems, and data sources.[[1]](#cite_note-venturebeat-2024-11-25-1) MCP provides a universal interface for reading files, executing functions, and handling contextual prompts.[[2]](#cite_note-venturebeat_2025-03-27-2) Following its announcement, the protocol was adopted by major AI providers, including [OpenAI](/wiki/OpenAI \"OpenAI\") and [Google DeepMind](/wiki/Google_DeepMind \"Google DeepMind\").[[3]](#cite_note-TechCrunch_2025-03-25-3)[[4]](#cite_note-TechCrunch_2025-04-09-4)\\n\\n## Background\\n\\n[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=1 \"Edit section: Background\")]\\n\\nThe protocol was announced by [Anthropic](/wiki/Anthropic \"Anthropic\") in November 2024 as an open standard[[5]](#cite_note-verge_2024-11-25-5) for connecting AI assistants to data systems such as [content repositories](/wiki/Content_repository \"Content repository\"), [business management tools](/wiki/Business_management_tools \"Business management tools\"), and [development environments](/wiki/Deployment_environment#Development \"Deployment environment\").[[6]](#cite_note-anthropic_2024-11-6) It aims to address the challenge of [information silos](/wiki/Information_silo \"Information silo\") and [legacy systems](/wiki/Legacy_system \"Legacy system\").[[6]](#cite_note-anthropic_2024-11-6) Before MCP, developers often had to build custom connectors for each data source or tool, resulting in what Anthropic described as an \"N×M\" [data integration](/wiki/Data_integration \"Data integration\") problem.[[6]](#cite_note-anthropic_2024-11-6)\\n\\nEarlier stop-gap approaches—such as OpenAI’s 2023 “function-calling” [API](/wiki/API \"API\") and the [ChatGPT](/wiki/ChatGPT \"ChatGPT\") plug-in framework—solved similar problems but required vendor-specific connectors.[[7]](#cite_note-ars-usbc-7) MCP’s authors note that the protocol deliberately re-uses the message-flow ideas of the [Language Server Protocol](/wiki/Language_Server_Protocol \"Language Server Protocol\") (LSP) and is transported over [JSON-RPC](/wiki/JSON-RPC \"JSON-RPC\") 2.0.[[8]](#cite_note-:1-8). MCP formally specifies [stdio](/wiki/Standard_streams \"Standard streams\") and [HTTP](/wiki/HTTP \"HTTP\") (optionally with [SSE](/wiki/Server-sent_events \"Server-sent events\")) as its standard transport mechanisms.[[9]](#cite_note-9)\\n\\n## Features\\n\\n[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=2 \"Edit section: Features\")]\\n\\nMCP defines a standardized framework for integrating AI systems with external data sources and tools.[[2]](#cite_note-venturebeat_2025-03-27-2) It includes specifications for [data ingestion](/wiki/Data_preparation \"Data preparation\") and [transformation](/wiki/Data_transformation_(computing) \"Data transformation (computing)\"), contextual [metadata](/wiki/Metadata \"Metadata\") [tagging](/wiki/Tag_(metadata) \"Tag (metadata)\"), and AI interoperability across different platforms. The protocol also supports secure, bidirectional connections between data sources and AI-powered tools.[[6]](#cite_note-anthropic_2024-11-6)\\n\\nMCP enables developers to expose their data via MCP servers or to develop AI applications—referred to as MCP clients—that connect to these servers.[[6]](#cite_note-anthropic_2024-11-6) Key components of the protocol include a formal protocol specification and software development kits (SDKs), local MCP server support in [Claude](/wiki/Claude_(language_model) \"Claude (language model)\") Desktop applications, and an open-source [repository](/wiki/Repository_(version_control) \"Repository (version control)\") of MCP server implementations.[[6]](#cite_note-anthropic_2024-11-6)\\n\\n## Applications\\n\\n[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=3 \"Edit section: Applications\")]\\n\\nMCP has been applied in domains such as software development, business process automation, and natural language automation.\\n\\nOne prominent use case is in desktop assistants, where applications such as the Claude Desktop app deploy local MCP servers to enable secure access to system tools and user files. In enterprise settings, internal assistants are enhanced with MCP to retrieve data from proprietary documents, CRM systems, and internal knowledge bases—companies like Block have integrated MCP into their internal tooling for this purpose.[[6]](#cite_note-anthropic_2024-11-6)\\n\\nMCP also plays a critical role in multi-tool agent workflows, allowing agentic AI systems to coordinate multiple tools—for example, combining document lookup with messaging APIs—to support advanced, chain-of-thought reasoning across distributed resources.[[10]](#cite_note-10)\\n\\nIn the field of natural language data access, MCP enables applications such as AI2SQL to bridge language models with structured databases, allowing plain-language queries.[[8]](#cite_note-:1-8)\\n\\nMCP has been adopted for academic research workflows through integrations with reference management systems like [Zotero](/wiki/Zotero \"Zotero\"). Multiple server implementations allow researchers to perform semantic searches across their libraries, extract PDF annotations, and generate literature reviews through AI-assisted analysis.[[11]](#cite_note-11)[[12]](#cite_note-12)[[13]](#cite_note-13)\\n\\nThe protocol has become increasingly common in software development tools. [Integrated development environments](/wiki/Integrated_development_environment \"Integrated development environment\") (IDEs) like Zed, coding platforms such as [Replit](/wiki/Replit \"Replit\"), and code intelligence tools like [Sourcegraph](/wiki/Sourcegraph \"Sourcegraph\") have adopted MCP to grant AI coding assistants real-time access to project context. This integration is especially valuable for workflows like \"[vibe coding](/wiki/Vibe_coding \"Vibe coding\")\", where continuous, adaptive assistance is essential.[[5]](#cite_note-verge_2024-11-25-5)\\n\\nIn web application development, companies like Wix have embedded MCP servers into their platforms. This allows AI tools to interact with live website data, enabling dynamic content generation and on-the-fly edits. Such capabilities are central to Wix’s AI-driven development tools.[[14]](#cite_note-14)[[15]](#cite_note-15)\\n\\n## Implementation\\n\\n[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=4 \"Edit section: Implementation\")]\\n\\nThe protocol was released with [software development kits](/wiki/Software_development_kits \"Software development kits\") (SDKs) in [programming languages](/wiki/Programming_languages \"Programming languages\") including [Python](/wiki/Python_(programming_language) \"Python (programming language)\"), [TypeScript](/wiki/TypeScript \"TypeScript\"), [C#](/wiki/C_Sharp_(programming_language) \"C Sharp (programming language)\") and [Java](/wiki/Java_(programming_language) \"Java (programming language)\").[[8]](#cite_note-:1-8)[[16]](#cite_note-16) Anthropic maintains an open-source repository of reference MCP server implementations for popular enterprise systems including [Google Drive](/wiki/Google_Drive \"Google Drive\"), [Slack](/wiki/Slack_(software) \"Slack (software)\"), [GitHub](/wiki/GitHub \"GitHub\"), [Git](/wiki/Git \"Git\"), [Postgres](/wiki/PostgreSQL \"PostgreSQL\"), [Puppeteer](/wiki/Puppeteer_(software) \"Puppeteer (software)\") and [Stripe](/wiki/Stripe,_Inc. \"Stripe, Inc.\").[[17]](#cite_note-:0-17) Developers can create custom MCP servers to connect [proprietary systems](/wiki/Proprietary_software \"Proprietary software\") or specialized data sources to AI systems.[[17]](#cite_note-:0-17)\\n\\nThe protocol\\'s open standard allows organizations to build tailored connections while maintaining compatibility with the broader MCP ecosystem. AI systems can then leverage these custom connections to provide [domain](/wiki/Domain_(software_engineering) \"Domain (software engineering)\")-specific assistance while respecting data access permissions.[[6]](#cite_note-anthropic_2024-11-6)\\n\\n## Adoption\\n\\n[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=5 \"Edit section: Adoption\")]\\n\\nIn March 2025, [OpenAI](/wiki/OpenAI \"OpenAI\") officially adopted the MCP, following a decision to integrate the standard across its products, including the [ChatGPT](/wiki/ChatGPT \"ChatGPT\") desktop app, OpenAI\\'s Agents SDK, and the Responses API. [Sam Altman](/wiki/Sam_Altman \"Sam Altman\") described the adoption of MCP as a step toward standardizing AI tool connectivity. Prior to OpenAI\\'s adoption, the potential benefits of MCP had been discussed extensively within the developer community, particularly for simplifying development in multi-model environments.[[3]](#cite_note-TechCrunch_2025-03-25-3)[[2]](#cite_note-venturebeat_2025-03-27-2)\\n\\nBy adopting MCP, OpenAI joins other organizations such as Block, Replit, and Sourcegraph in incorporating the protocol into their platforms. This wide adoption highlights MCP\\'s potential to become a universal [open standard](/wiki/Open_standard \"Open standard\") for AI system connectivity and interoperability.[[3]](#cite_note-TechCrunch_2025-03-25-3) MCP can be integrated with [Microsoft](/wiki/Microsoft \"Microsoft\") Semantic Kernel,[[18]](#cite_note-18) and [Azure](/wiki/Microsoft_Azure \"Microsoft Azure\") OpenAI.[[19]](#cite_note-19) MCP servers can be deployed to [Cloudflare](/wiki/Cloudflare \"Cloudflare\").[[20]](#cite_note-20)\\n\\n[Demis Hassabis](/wiki/Demis_Hassabis \"Demis Hassabis\"), CEO of [Google DeepMind](/wiki/Google_DeepMind \"Google DeepMind\"), confirmed in April 2025 MCP support in the upcoming [Gemini](/wiki/Gemini_(chatbot) \"Gemini (chatbot)\") models and related infrastructure, describing the protocol as \"rapidly becoming an open standard for the AI agentic era\".[[4]](#cite_note-TechCrunch_2025-04-09-4)\\n\\nMicrosoft has made significant investments in the MCP to enhance AI integration across its ecosystem, including GitHub, Microsoft 365, and Azure. GitHub, alongside Microsoft, joined the MCP steering committee at Microsoft Build 2025, contributing a registry service for MCP server discovery and management. The Azure MCP Server, in public preview, connects AI agents to Azure services like storage, databases, and log analytics, while Microsoft 365 supports MCP for building AI agents and applications with Copilot integration. In May 2025, Microsoft released native MCP support in Copilot Studio, offering one-click links to any MCP server, new tool listings, streaming transport, and full tracing and analytics. The release positioned MCP as Copilot’s default bridge to external knowledge bases, APIs, and [Dataverse](/wiki/Dataverse \"Dataverse\").[[21]](#cite_note-21) Additionally, Microsoft partnered with Anthropic to develop an official [C#](/wiki/C_Sharp_(programming_language) \"C Sharp (programming language)\") SDK for MCP, available as an open-source [NuGet](/wiki/NuGet \"NuGet\") package (ModelContextProtocol), enabling seamless AI integration within the [.NET](/wiki/.NET \".NET\") ecosystem for building MCP servers and clients.[[22]](#cite_note-22)\\n\\nMany MCP servers have since been added, allowing integration of LLMs with diverse applications.[[23]](#cite_note-23)\\n\\n## Reception\\n\\n[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=6 \"Edit section: Reception\")]\\n\\n*[The Verge](/wiki/The_Verge \"The Verge\")* reported that MCP addresses a growing demand for AI agents that are contextually aware and capable of securely pulling from diverse sources.[[5]](#cite_note-verge_2024-11-25-5) The protocol\\'s rapid uptake by OpenAI, Google DeepMind, and toolmakers like Zed and Sourcegraph suggests growing consensus around its utility.[[3]](#cite_note-TechCrunch_2025-03-25-3)[[24]](#cite_note-beebom_mcp-24)\\n\\nIn April 2025, security researchers released analysis that there are multiple outstanding security issues with MCP, including [prompt injection](/wiki/Prompt_injection \"Prompt injection\"),[[25]](#cite_note-25) tool permissions where combining tools can exfiltrate files,[[26]](#cite_note-26) and lookalike tools can silently replace trusted ones.[[27]](#cite_note-27)\\n\\nIt has been likened to [OpenAPI](/wiki/OpenAPI_Specification \"OpenAPI Specification\"), a similar specification that aims to describe APIs.[[28]](#cite_note-28)[[29]](#cite_note-29)\\n\\n## See also\\n\\n[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=7 \"Edit section: See also\")]\\n\\n* [AI governance](/wiki/AI_governance \"AI governance\")\\xa0– Guidelines and laws to regulate AIPages displaying short descriptions of redirect targets\\n* [Application programming interface](/wiki/Application_programming_interface \"Application programming interface\")\\xa0– Connection between computers or programsPages displaying short descriptions of redirect targets\\n* [LangChain](/wiki/LangChain \"LangChain\")\\xa0– Language model application development framework\\n* [Machine learning](/wiki/Machine_learning \"Machine learning\")\\xa0– Study of algorithms that improve automatically through experience\\n* [Software agent](/wiki/Software_agent \"Software agent\")\\xa0– Computer program acting for a user\\n\\n## References\\n\\n[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=8 \"Edit section: References\")]\\n\\n1. **[^](#cite_ref-venturebeat-2024-11-25_1-0 \"Jump up\")** David, Emilia (November 25, 2024). [\"Anthropic releases Model Context Protocol to standardize AI-data integration\"](https://venturebeat.com/data-infrastructure/anthropic-releases-model-context-protocol-to-standardize-ai-data-integration/). [VentureBeat](/wiki/VentureBeat \"VentureBeat\"). Retrieved 2025-05-12.\\n2. ^ [Jump up to: ***a***](#cite_ref-venturebeat_2025-03-27_2-0) [***b***](#cite_ref-venturebeat_2025-03-27_2-1) [***c***](#cite_ref-venturebeat_2025-03-27_2-2) Kumar, Vinay (March 26, 2025). [\"The open source Model Context Protocol was just updated — here\\'s why it\\'s a big deal\"](https://venturebeat.com/ai/the-open-source-model-context-protocol-was-just-updated-heres-why-its-a-big-deal/). [VentureBeat](/wiki/VentureBeat \"VentureBeat\"). Retrieved 2025-05-12.\\n3. ^ [Jump up to: ***a***](#cite_ref-TechCrunch_2025-03-25_3-0) [***b***](#cite_ref-TechCrunch_2025-03-25_3-1) [***c***](#cite_ref-TechCrunch_2025-03-25_3-2) [***d***](#cite_ref-TechCrunch_2025-03-25_3-3) Wiggers, Kyle (March 25, 2025). [\"OpenAI adopts rival Anthropic\\'s standard for connecting AI models to data\"](https://techcrunch.com/2025/03/26/openai-adopts-rival-anthropics-standard-for-connecting-ai-models-to-data/). [TechCrunch](/wiki/TechCrunch \"TechCrunch\").\\n4. ^ [Jump up to: ***a***](#cite_ref-TechCrunch_2025-04-09_4-0) [***b***](#cite_ref-TechCrunch_2025-04-09_4-1) Wiggers, Kyle (April 9, 2025). [\"Google to embrace Anthropic\\'s standard for connecting AI models to data\"](https://techcrunch.com/2025/04/09/google-says-itll-embrace-anthropics-standard-for-connecting-ai-models-to-data/). TechCrunch. Retrieved 2025-05-12.\\n5. ^ [Jump up to: ***a***](#cite_ref-verge_2024-11-25_5-0) [***b***](#cite_ref-verge_2024-11-25_5-1) [***c***](#cite_ref-verge_2024-11-25_5-2) Roth, Emma (November 25, 2024). [\"Anthropic launches tool to connect AI systems directly to datasets\"](https://www.theverge.com/2024/11/25/24305774/anthropic-model-context-protocol-data-sources). [The Verge](/wiki/The_Verge \"The Verge\").\\n6. ^ [Jump up to: ***a***](#cite_ref-anthropic_2024-11_6-0) [***b***](#cite_ref-anthropic_2024-11_6-1) [***c***](#cite_ref-anthropic_2024-11_6-2) [***d***](#cite_ref-anthropic_2024-11_6-3) [***e***](#cite_ref-anthropic_2024-11_6-4) [***f***](#cite_ref-anthropic_2024-11_6-5) [***g***](#cite_ref-anthropic_2024-11_6-6) [***h***](#cite_ref-anthropic_2024-11_6-7) [\"Introducing the Model Context Protocol\"](https://www.anthropic.com/news/model-context-protocol). Anthropic. November 25, 2024. Retrieved 2025-05-12.[*[non-primary source needed](/wiki/Wikipedia:No_original_research#Primary,_secondary_and_tertiary_sources \"Wikipedia:No original research\")*]\\n7. **[^](#cite_ref-ars-usbc_7-0 \"Jump up\")** Edwards, Benj (1 April 2025). [\"MCP: The new \"USB-C for AI\" that\\'s bringing fierce rivals together\"](https://arstechnica.com/information-technology/2025/04/mcp-the-new-usb-c-for-ai-thats-bringing-fierce-rivals-together/). *Ars Technica*. Retrieved 2025-05-24.\\n8. ^ [Jump up to: ***a***](#cite_ref-:1_8-0) [***b***](#cite_ref-:1_8-1) [***c***](#cite_ref-:1_8-2) Ouellette, Michael (2025-05-09). [\"Model context protocol: the next big step in generating value from AI\"](https://www.engineering.com/model-context-protocol-the-next-big-step-in-generating-value-from-ai/). *Engineering.com*. Retrieved 2025-06-23.\\n9. **[^](#cite_ref-9 \"Jump up\")** [\"Transports – Model Context Protocol\"](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports). Retrieved 2025-08-07.\\n10. **[^](#cite_ref-10 \"Jump up\")** Gutowska, Anna (9 May 2025), [*What is Model Context Protocal?*](https://www.ibm.com/think/topics/model-context-protocol), retrieved 2025-08-27\\n11. **[^](#cite_ref-11 \"Jump up\")** Yu, Steven (2025-07-02), [*54yyyu/zotero-mcp*](https://github.com/54yyyu/zotero-mcp), retrieved 2025-07-03\\n12. **[^](#cite_ref-12 \"Jump up\")** Taylor, Aaron (2025-07-02), [*kujenga/zotero-mcp*](https://github.com/kujenga/zotero-mcp), retrieved 2025-07-03\\n13. **[^](#cite_ref-13 \"Jump up\")** Kalia, Abhishek (2025-07-02), [*kaliaboi/mcp-zotero*](https://github.com/kaliaboi/mcp-zotero), retrieved 2025-07-03\\n14. **[^](#cite_ref-14 \"Jump up\")** [\"Wix just opened the door to quicker and easier coding with new AI tool\"](https://www.techradar.com/pro/website-building/wix-just-opened-the-door-to-quicker-and-easier-coding-with-new-ai-tool). TechRadar Pro. March 27, 2025. Retrieved 2025-05-22.\\n15. **[^](#cite_ref-15 \"Jump up\")** [\"Wix Unveils the Wix Model Context Protocol Server for AI-Driven Web App Development\"](https://www.enterpriseaiworld.com/Articles/News/News/Wix-Unveils-the-Wix-Model-Context-Protocol-Server-for-AI-Driven-Web-App-Development). Enterprise AI World. March 27, 2024. Retrieved 2025-05-22.\\n16. **[^](#cite_ref-16 \"Jump up\")** [\"Model Context Protocol\"](https://github.com/modelcontextprotocol). *GitHub*. Retrieved 2025-06-20.\\n17. ^ [Jump up to: ***a***](#cite_ref-:0_17-0) [***b***](#cite_ref-:0_17-1) Bastian, Matthias (2024-11-25). [\"Anthropic\\'s new open protocol lets AI systems tap into any data source\"](https://the-decoder.com/anthropics-new-open-protocol-lets-ai-systems-tap-into-any-data-source/). *The Decoder*. Retrieved 2025-06-14.\\n18. **[^](#cite_ref-18 \"Jump up\")**  Wallace, Mark (March 5, 2025). [\"Integrating Model Context Protocol Tools with Semantic Kernel: A Step-by-Step Guide\"](https://devblogs.microsoft.com/semantic-kernel/integrating-model-context-protocol-tools-with-semantic-kernel-a-step-by-step-guide/). *Semantic Kernel Dev Blog, Microsoft*. Retrieved 2025-05-12.\\n19. **[^](#cite_ref-19 \"Jump up\")**  mrajguru (March 16, 2025). [\"Model Context Protocol (MCP): Integrating Azure OpenAI for Enhanced Tool Integration and Prompting\"](https://techcommunity.microsoft.com/blog/azure-ai-services-blog/model-context-protocol-mcp-integrating-azure-openai-for-enhanced-tool-integratio/4393788). *AI - Azure AI services Blog, Microsoft*. Retrieved 2025-05-12.\\n20. **[^](#cite_ref-20 \"Jump up\")** Brendan Irvine-Broque; Dina Kozlov; Glen Maddern (March 25, 2025). [\"Build and deploy Remote Model Context Protocol (MCP) servers to Cloudflare\"](https://blog.cloudflare.com/remote-model-context-protocol-servers-mcp/). [Cloudflare](/wiki/Cloudflare \"Cloudflare\"). Retrieved 2025-05-12.\\n21. **[^](#cite_ref-21 \"Jump up\")** Desai, Zankar (2025-05-29). [\"Model Context Protocol (MCP) is now generally available in Microsoft Copilot Studio\"](https://www.microsoft.com/en-us/microsoft-copilot/blog/copilot-studio/model-context-protocol-mcp-is-now-generally-available-in-microsoft-copilot-studio/). *Microsoft Copilot Blog*. Retrieved 2025-08-03.\\n22. **[^](#cite_ref-22 \"Jump up\")** Mike, Maria (2025-04-02). [\"Microsoft partners with Anthropic to create official C# SDK for Model Context Protocol\"](https://devblogs.microsoft.com/blog/microsoft-partners-with-anthropic-to-create-official-c-sdk-for-model-context-protocol). *Microsoft Developer Blog*. Retrieved 2025-08-01.\\n23. **[^](#cite_ref-23 \"Jump up\")** Awan, Abid Ali. [\"10 Awesome MCP Servers\"](https://www.kdnuggets.com/10-awesome-mcp-servers). *[KDnuggets](/wiki/KDnuggets \"KDnuggets\")*. Retrieved 2025-05-12.\\n24. **[^](#cite_ref-beebom_mcp_24-0 \"Jump up\")** Sha, Arjun (April 14, 2025). [\"What is Model Context Protocol (MCP) Explained\"](https://beebom.com/model-context-protocol-mcp-explained/). *Beebom.com*.\\n25. **[^](#cite_ref-25 \"Jump up\")** Lakshmanan, Ravie (30 April 2025). [\"Researchers Demonstrate How MCP Prompt Injection Can Be Used for Both Attack and Defense\"](https://thehackernews.com/2025/04/experts-uncover-critical-mcp-and-a2a.html). thehackernews.com.\\n26. **[^](#cite_ref-26 \"Jump up\")** Beurer-Kellner, Luca; Fischer, Marc (1 April 2025). [\"MCP Security Notification: Tool Poisoning Attacks\"](https://invariantlabs.ai/blog/mcp-security-notification-tool-poisoning-attacks). InvariantLabs.\\n27. **[^](#cite_ref-27 \"Jump up\")** Schulz, Kasimir; Martin, Jason; Kan, Marcus; Yeung, Kenneth; McCauley, Conor; Ring, Leo (10 April 2025). [\"MCP: Model Context Pitfalls in an Agentic World\"](https://hiddenlayer.com/innovation-hub/mcp-model-context-pitfalls-in-an-agentic-world/). hiddenlayer.com.\\n28. **[^](#cite_ref-28 \"Jump up\")** MacManus, Richard (13 March 2025). [\"MCP: The Missing Link Between AI Agents and APIs\"](https://thenewstack.io/mcp-the-missing-link-between-ai-agents-and-apis/). *The New Stack*. Retrieved 29 May 2025.\\n29. **[^](#cite_ref-29 \"Jump up\")** Fanelli, Alessio. [\"Why MCP Won\"](https://www.latent.space/p/why-mcp-won). *www.latent.space*. Retrieved 29 May 2025.\\n\\n## Further reading\\n\\n[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=9 \"Edit section: Further reading\")]\\n\\n* Hou, Xinyi; Zhao, Yanjie; Wang, Shenao; Wang, Haoyu (2025). \"Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions\". [arXiv](/wiki/ArXiv_(identifier) \"ArXiv (identifier)\"):[2503.23278](https://arxiv.org/abs/2503.23278) [[cs.CR](https://arxiv.org/archive/cs.CR)].\\n* Edwards, Benj (April 1, 2025). [\"MCP: The new \"USB-C for AI\" that\\'s bringing fierce rivals together\"](https://arstechnica.com/information-technology/2025/04/mcp-the-new-usb-c-for-ai-thats-bringing-fierce-rivals-together). [Ars Technica](/wiki/Ars_Technica \"Ars Technica\").\\n* Jackson, Fiona (March 28, 2025). [\"OpenAI Agents Now Support Rival Anthropic\\'s Protocol, Making Data Access \\'Simpler, More Reliable\\'\"](https://www.techrepublic.com/article/news-openai-anthropic-model-context-protocol/). [TechRepublic](/wiki/TechRepublic \"TechRepublic\").\\n* Masson, Colin (March 25, 2025). [\"Context Is the Missing Link: The Emergence of the Model Context Protocol in Industrial AI\"](https://www.arcweb.com/blog/context-missing-link-emergence-model-context-protocol-industrial-ai). ARC Advisory Group.\\n* Jimin Kim; Anita Lewis; Justin Lewis; Laith Al-Saadoon; Paul Vincent; Pranjali Bhandari (April 1, 2025). [\"Introducing AWS MCP Servers for code assistants (Part 1)\"](https://aws.amazon.com/blogs/machine-learning/introducing-aws-mcp-servers-for-code-assistants-part-1/). [Amazon AWS](/wiki/Amazon_AWS \"Amazon AWS\").\\n* Desai, Zankar (March 19, 2025). [\"Introducing Model Context Protocol (MCP) in Copilot Studio: Simplified Integration with AI Apps and Agents\"](https://www.microsoft.com/en-us/microsoft-copilot/blog/copilot-studio/introducing-model-context-protocol-mcp-in-copilot-studio-simplified-integration-with-ai-apps-and-agents/). Microsoft Copilot Studio Blog, [Microsoft](/wiki/Microsoft \"Microsoft\").\\n* Wagner, Tim (May 13, 2025). [\"Understanding Model Context Protocol (MCP)\"](https://www.vendia.com/blog/understanding-model-context-protocol-mcp/). *Vendia*.\\n\\n## External links\\n\\n[[edit](/w/index.php?title=Model_Context_Protocol&action=edit&section=10 \"Edit section: External links\")]\\n\\n* [Official website](https://modelcontextprotocol.io/)\\n* [modelcontextprotocol](https://github.com/modelcontextprotocol) on [GitHub](/wiki/GitHub \"GitHub\")\\n* [SDK documentation from OpenAI](https://openai.github.io/openai-agents-python/mcp/)\\n\\n| * [v](/wiki/Template:Generative_AI \"Template:Generative AI\") * [t](/wiki/Template_talk:Generative_AI \"Template talk:Generative AI\") * [e](/wiki/Special:EditPage/Template:Generative_AI \"Special:EditPage/Template:Generative AI\")  [Generative AI](/wiki/Generative_artificial_intelligence \"Generative artificial intelligence\") | |\\n| --- | --- |\\n| Concepts | * [Autoencoder](/wiki/Autoencoder \"Autoencoder\") * [Deep learning](/wiki/Deep_learning \"Deep learning\") * [Fine-tuning](/wiki/Fine-tuning_(deep_learning) \"Fine-tuning (deep learning)\") * [Foundation model](/wiki/Foundation_model \"Foundation model\") * [Generative adversarial network](/wiki/Generative_adversarial_network \"Generative adversarial network\") * [Generative pre-trained transformer](/wiki/Generative_pre-trained_transformer \"Generative pre-trained transformer\") * [Large language model](/wiki/Large_language_model \"Large language model\") * Model Context Protocol * [Neural network](/wiki/Neural_network_(machine_learning) \"Neural network (machine learning)\") * [Prompt engineering](/wiki/Prompt_engineering \"Prompt engineering\") * [Reinforcement learning from human feedback](/wiki/Reinforcement_learning_from_human_feedback \"Reinforcement learning from human feedback\") * [Retrieval-augmented generation](/wiki/Retrieval-augmented_generation \"Retrieval-augmented generation\") * [Self-supervised learning](/wiki/Self-supervised_learning \"Self-supervised learning\") * [Stochastic parrot](/wiki/Stochastic_parrot \"Stochastic parrot\") * [Synthetic data](/wiki/Synthetic_data \"Synthetic data\") * [Top-p sampling](/wiki/Top-p_sampling \"Top-p sampling\") * [Transformer](/wiki/Transformer_(deep_learning_architecture) \"Transformer (deep learning architecture)\") * [Variational autoencoder](/wiki/Variational_autoencoder \"Variational autoencoder\") * [Vibe coding](/wiki/Vibe_coding \"Vibe coding\") * [Vision transformer](/wiki/Vision_transformer \"Vision transformer\") * [Waluigi effect](/wiki/Waluigi_effect \"Waluigi effect\") * [Word embedding](/wiki/Word_embedding \"Word embedding\") |\\n| Chatbots | * [Character.ai](/wiki/Character.ai \"Character.ai\") * [ChatGPT](/wiki/ChatGPT \"ChatGPT\") * [DeepSeek](/wiki/DeepSeek_(chatbot) \"DeepSeek (chatbot)\") * [Ernie](/wiki/Ernie_Bot \"Ernie Bot\") * [Gemini](/wiki/Gemini_(chatbot) \"Gemini (chatbot)\") * [Grok](/wiki/Grok_(chatbot) \"Grok (chatbot)\") * [Copilot](/wiki/Microsoft_Copilot \"Microsoft Copilot\") |\\n| Models | |  |  | | --- | --- | | Text | * [Claude](/wiki/Claude_(language_model) \"Claude (language model)\") * [Gemini](/wiki/Gemini_(language_model) \"Gemini (language model)\") * [Gemma](/wiki/Gemma_(language_model) \"Gemma (language model)\") * [GPT](/wiki/Generative_pre-trained_transformer \"Generative pre-trained transformer\")   + [1](/wiki/GPT-1 \"GPT-1\")   + [2](/wiki/GPT-2 \"GPT-2\")   + [3](/wiki/GPT-3 \"GPT-3\")   + [J](/wiki/GPT-J \"GPT-J\")   + [4](/wiki/GPT-4 \"GPT-4\")   + [4o](/wiki/GPT-4o \"GPT-4o\")   + [4.5](/wiki/GPT-4.5 \"GPT-4.5\")   + [4.1](/wiki/GPT-4.1 \"GPT-4.1\")   + [OSS](/wiki/GPT-OSS \"GPT-OSS\")   + [5](/wiki/GPT-5 \"GPT-5\") * [Llama](/wiki/Llama_(language_model) \"Llama (language model)\") * [o1](/wiki/OpenAI_o1 \"OpenAI o1\") * [o3](/wiki/OpenAI_o3 \"OpenAI o3\") * [o4-mini](/wiki/OpenAI_o4-mini \"OpenAI o4-mini\") * [Qwen](/wiki/Qwen \"Qwen\") | | Coding | * [Base44](/wiki/Base44 \"Base44\") * [Claude Code](/wiki/Claude_Code \"Claude Code\") * [Cursor](/wiki/Cursor_(code_editor) \"Cursor (code editor)\") * [Devstral](/wiki/Mistral_AI \"Mistral AI\") * [GitHub Copilot](/wiki/GitHub_Copilot \"GitHub Copilot\") * [Kimi-Dev](/wiki/Moonshot_AI \"Moonshot AI\") * [Qwen3-Coder](/wiki/Qwen \"Qwen\") * [Replit](/wiki/Replit \"Replit\") * [Xcode](/wiki/Xcode \"Xcode\") | | [Image](/wiki/Text-to-image_model \"Text-to-image model\") | * [Aurora](/wiki/Aurora_(text-to-image_model) \"Aurora (text-to-image model)\") * [Firefly](/wiki/Adobe_Firefly \"Adobe Firefly\") * [Flux](/wiki/Flux_(text-to-image_model) \"Flux (text-to-image model)\") * [GPT Image 1](/wiki/GPT-4o#GPT_Image_1 \"GPT-4o\") * [Ideogram](/wiki/Ideogram_(text-to-image_model) \"Ideogram (text-to-image model)\") * [Imagen](/wiki/Imagen_(text-to-image_model) \"Imagen (text-to-image model)\") * [Midjourney](/wiki/Midjourney \"Midjourney\") * [Qwen-Image](/wiki/Qwen \"Qwen\") * [Recraft](/wiki/Recraft \"Recraft\") * [Seedream](/wiki/ByteDance \"ByteDance\") * [Stable Diffusion](/wiki/Stable_Diffusion \"Stable Diffusion\") | | [Video](/wiki/Text-to-video_model \"Text-to-video model\") | * [Dream Machine](/wiki/Dream_Machine_(text-to-video_model) \"Dream Machine (text-to-video model)\") * [Hailuo AI](/wiki/MiniMax_(company)#Hailuo_AI \"MiniMax (company)\") * [Kling](/wiki/Kling_(text-to-video_model) \"Kling (text-to-video model)\") * [Midjourney Video](/wiki/Midjourney \"Midjourney\") * [Runway Gen](/wiki/Runway_(company)#Services_and_technologies \"Runway (company)\") * [Seedance](/wiki/ByteDance \"ByteDance\") * [Sora](/wiki/Sora_(text-to-video_model) \"Sora (text-to-video model)\") * [Veo](/wiki/Veo_(text-to-video_model) \"Veo (text-to-video model)\") * [Wan](/wiki/Alibaba_Group#Cloud_computing_and_artificial_intelligence_technology \"Alibaba Group\") | | [Speech](/wiki/Speech_synthesis#Text-to-speech_systems \"Speech synthesis\") | * [15.ai](/wiki/15.ai \"15.ai\") * [Eleven](/wiki/ElevenLabs#Products \"ElevenLabs\") * [MiniMax Speech 2.5](/wiki/MiniMax_(company) \"MiniMax (company)\") * [WaveNet](/wiki/WaveNet \"WaveNet\") | | Music | * [Eleven Music](/wiki/ElevenLabs#Products \"ElevenLabs\") * [Endel](/wiki/Endel_(app) \"Endel (app)\") * [Lyria](/wiki/Google_DeepMind#Music_generation \"Google DeepMind\") * [Riffusion](/wiki/Riffusion \"Riffusion\") * [Suno AI](/wiki/Suno_AI \"Suno AI\") * [Udio](/wiki/Udio \"Udio\") | |\\n| [Agents](/wiki/Intelligent_agent \"Intelligent agent\") | * [Agentforce](/wiki/Salesforce#Artificial_intelligence \"Salesforce\") * [AutoGLM](/wiki/Zhipu_AI#AutoGLM \"Zhipu AI\") * [AutoGPT](/wiki/AutoGPT \"AutoGPT\") * [ChatGPT Agent](/wiki/ChatGPT#Agents \"ChatGPT\") * [Devin AI](/wiki/Devin_AI \"Devin AI\") * [Manus](/wiki/Manus_(AI_agent) \"Manus (AI agent)\") * [OpenAI Codex](/wiki/OpenAI_Codex \"OpenAI Codex\") * [Operator](/wiki/OpenAI_Operator \"OpenAI Operator\") * [Replit Agent](/wiki/Replit \"Replit\") |\\n| [Companies](/wiki/List_of_artificial_intelligence_companies \"List of artificial intelligence companies\") | * [01.AI](/wiki/01.AI \"01.AI\") * [Aleph Alpha](/wiki/Aleph_Alpha \"Aleph Alpha\") * [Anthropic](/wiki/Anthropic \"Anthropic\") * [Baichuan](/wiki/Baichuan \"Baichuan\") * [Canva](/wiki/Canva \"Canva\") * [Cognition AI](/wiki/Cognition_AI \"Cognition AI\") * [Cohere](/wiki/Cohere \"Cohere\") * [Contextual AI](/wiki/Contextual_AI \"Contextual AI\") * [DeepSeek](/wiki/DeepSeek \"DeepSeek\") * [ElevenLabs](/wiki/ElevenLabs \"ElevenLabs\") * [Google DeepMind](/wiki/Google_DeepMind \"Google DeepMind\") * [HeyGen](/wiki/HeyGen \"HeyGen\") * [Hugging Face](/wiki/Hugging_Face \"Hugging Face\") * [Inflection AI](/wiki/Inflection_AI \"Inflection AI\") * [Krikey AI](/wiki/Krikey_AI \"Krikey AI\") * [Kuaishou](/wiki/Kuaishou \"Kuaishou\") * [Luma Labs](/wiki/Luma_Labs \"Luma Labs\") * [Meta AI](/wiki/Meta_AI \"Meta AI\") * [MiniMax](/wiki/MiniMax_(company) \"MiniMax (company)\") * [Mistral AI](/wiki/Mistral_AI \"Mistral AI\") * [Moonshot AI](/wiki/Moonshot_AI \"Moonshot AI\") * [OpenAI](/wiki/OpenAI \"OpenAI\") * [Perplexity AI](/wiki/Perplexity_AI \"Perplexity AI\") * [Runway](/wiki/Runway_(company) \"Runway (company)\") * [Safe Superintelligence](/wiki/Safe_Superintelligence_Inc. \"Safe Superintelligence Inc.\") * [Salesforce](/wiki/Salesforce \"Salesforce\") * [Scale AI](/wiki/Scale_AI \"Scale AI\") * [SoundHound](/wiki/SoundHound \"SoundHound\") * [Stability AI](/wiki/Stability_AI \"Stability AI\") * [Synthesia](/wiki/Synthesia_(company) \"Synthesia (company)\") * [Thinking Machines Lab](/wiki/Thinking_Machines_Lab \"Thinking Machines Lab\") * [Upstage](/wiki/Upstage_(company) \"Upstage (company)\") * [xAI](/wiki/XAI_(company) \"XAI (company)\") * [Z.ai](/wiki/Z.ai \"Z.ai\") |\\n|  | |\\n\\n| * [v](/wiki/Template:Artificial_intelligence_navbox \"Template:Artificial intelligence navbox\") * [t](/wiki/Template_talk:Artificial_intelligence_navbox \"Template talk:Artificial intelligence navbox\") * [e](/wiki/Special:EditPage/Template:Artificial_intelligence_navbox \"Special:EditPage/Template:Artificial intelligence navbox\")  [Artificial intelligence](/wiki/Artificial_intelligence \"Artificial intelligence\") (AI) | |\\n| --- | --- |\\n| * [History](/wiki/History_of_artificial_intelligence \"History of artificial intelligence\")   + [timeline](/wiki/Timeline_of_artificial_intelligence \"Timeline of artificial intelligence\") * [Companies](/wiki/List_of_artificial_intelligence_companies \"List of artificial intelligence companies\") * [Projects](/wiki/List_of_artificial_intelligence_projects \"List of artificial intelligence projects\") | |\\n| Concepts | * [Parameter](/wiki/Parameter \"Parameter\")   + [Hyperparameter](/wiki/Hyperparameter_(machine_learning) \"Hyperparameter (machine learning)\") * [Loss functions](/wiki/Loss_functions_for_classification \"Loss functions for classification\") * [Regression](/wiki/Regression_analysis \"Regression analysis\")   + [Bias–variance tradeoff](/wiki/Bias%E2%80%93variance_tradeoff \"Bias–variance tradeoff\")   + [Double descent](/wiki/Double_descent \"Double descent\")   + [Overfitting](/wiki/Overfitting \"Overfitting\") * [Clustering](/wiki/Cluster_analysis \"Cluster analysis\") * [Gradient descent](/wiki/Gradient_descent \"Gradient descent\")   + [SGD](/wiki/Stochastic_gradient_descent \"Stochastic gradient descent\")   + [Quasi-Newton method](/wiki/Quasi-Newton_method \"Quasi-Newton method\")   + [Conjugate gradient method](/wiki/Conjugate_gradient_method \"Conjugate gradient method\") * [Backpropagation](/wiki/Backpropagation \"Backpropagation\") * [Attention](/wiki/Attention_(machine_learning) \"Attention (machine learning)\") * [Convolution](/wiki/Convolution \"Convolution\") * [Normalization](/wiki/Normalization_(machine_learning) \"Normalization (machine learning)\")   + [Batchnorm](/wiki/Batch_normalization \"Batch normalization\") * [Activation](/wiki/Activation_function \"Activation function\")   + [Softmax](/wiki/Softmax_function \"Softmax function\")   + [Sigmoid](/wiki/Sigmoid_function \"Sigmoid function\")   + [Rectifier](/wiki/Rectifier_(neural_networks) \"Rectifier (neural networks)\") * [Gating](/wiki/Gating_mechanism \"Gating mechanism\") * [Weight initialization](/wiki/Weight_initialization \"Weight initialization\") * [Regularization](/wiki/Regularization_(mathematics) \"Regularization (mathematics)\") * [Datasets](/wiki/Training,_validation,_and_test_data_sets \"Training, validation, and test data sets\")   + [Augmentation](/wiki/Data_augmentation \"Data augmentation\") * [Prompt engineering](/wiki/Prompt_engineering \"Prompt engineering\") * [Reinforcement learning](/wiki/Reinforcement_learning \"Reinforcement learning\")   + [Q-learning](/wiki/Q-learning \"Q-learning\")   + [SARSA](/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action \"State–action–reward–state–action\")   + [Imitation](/wiki/Imitation_learning \"Imitation learning\")   + [Policy gradient](/wiki/Policy_gradient_method \"Policy gradient method\") * [Diffusion](/wiki/Diffusion_process \"Diffusion process\") * [Latent diffusion model](/wiki/Latent_diffusion_model \"Latent diffusion model\") * [Autoregression](/wiki/Autoregressive_model \"Autoregressive model\") * [Adversary](/wiki/Adversarial_machine_learning \"Adversarial machine learning\") * [RAG](/wiki/Retrieval-augmented_generation \"Retrieval-augmented generation\") * [Uncanny valley](/wiki/Uncanny_valley \"Uncanny valley\") * [RLHF](/wiki/Reinforcement_learning_from_human_feedback \"Reinforcement learning from human feedback\") * [Self-supervised learning](/wiki/Self-supervised_learning \"Self-supervised learning\") * [Reflection](/wiki/Reflection_(artificial_intelligence) \"Reflection (artificial intelligence)\") * [Recursive self-improvement](/wiki/Recursive_self-improvement \"Recursive self-improvement\") * [Hallucination](/wiki/Hallucination_(artificial_intelligence) \"Hallucination (artificial intelligence)\") * [Word embedding](/wiki/Word_embedding \"Word embedding\") * [Vibe coding](/wiki/Vibe_coding \"Vibe coding\") |\\n| Applications | * [Machine learning](/wiki/Machine_learning \"Machine learning\")   + [In-context learning](/wiki/Prompt_engineering#In-context_learning \"Prompt engineering\") * [Artificial neural network](/wiki/Neural_network_(machine_learning) \"Neural network (machine learning)\")   + [Deep learning](/wiki/Deep_learning \"Deep learning\") * [Language model](/wiki/Language_model \"Language model\")   + [Large language model](/wiki/Large_language_model \"Large language model\")   + [NMT](/wiki/Neural_machine_translation \"Neural machine translation\") * [Reasoning language model](/wiki/Reasoning_language_model \"Reasoning language model\") * Model Context Protocol * [Intelligent agent](/wiki/Intelligent_agent \"Intelligent agent\") * [Artificial human companion](/wiki/Artificial_human_companion \"Artificial human companion\") * [Humanity\\'s Last Exam](/wiki/Humanity%27s_Last_Exam \"Humanity\\'s Last Exam\") * [Artificial general intelligence (AGI)](/wiki/Artificial_general_intelligence \"Artificial general intelligence\") |\\n| Implementations | |  |  | | --- | --- | | Audio–visual | * [AlexNet](/wiki/AlexNet \"AlexNet\") * [WaveNet](/wiki/WaveNet \"WaveNet\") * [Human image synthesis](/wiki/Human_image_synthesis \"Human image synthesis\") * [HWR](/wiki/Handwriting_recognition \"Handwriting recognition\") * [OCR](/wiki/Optical_character_recognition \"Optical character recognition\") * [Computer vision](/wiki/Computer_vision \"Computer vision\") * [Speech synthesis](/wiki/Deep_learning_speech_synthesis \"Deep learning speech synthesis\")   + [15.ai](/wiki/15.ai \"15.ai\")   + [ElevenLabs](/wiki/ElevenLabs \"ElevenLabs\") * [Speech recognition](/wiki/Speech_recognition \"Speech recognition\")   + [Whisper](/wiki/Whisper_(speech_recognition_system) \"Whisper (speech recognition system)\") * [Facial recognition](/wiki/Facial_recognition_system \"Facial recognition system\") * [AlphaFold](/wiki/AlphaFold \"AlphaFold\") * [Text-to-image models](/wiki/Text-to-image_model \"Text-to-image model\")   + [Aurora](/wiki/Aurora_(text-to-image_model) \"Aurora (text-to-image model)\")   + [DALL-E](/wiki/DALL-E \"DALL-E\")   + [Firefly](/wiki/Adobe_Firefly \"Adobe Firefly\")   + [Flux](/wiki/Flux_(text-to-image_model) \"Flux (text-to-image model)\")   + [Ideogram](/wiki/Ideogram_(text-to-image_model) \"Ideogram (text-to-image model)\")   + [Imagen](/wiki/Imagen_(text-to-image_model) \"Imagen (text-to-image model)\")   + [Midjourney](/wiki/Midjourney \"Midjourney\")   + [Recraft](/wiki/Recraft \"Recraft\")   + [Stable Diffusion](/wiki/Stable_Diffusion \"Stable Diffusion\") * [Text-to-video models](/wiki/Text-to-video_model \"Text-to-video model\")   + [Dream Machine](/wiki/Dream_Machine_(text-to-video_model) \"Dream Machine (text-to-video model)\")   + [Runway Gen](/wiki/Runway_(company)#Services_and_technologies \"Runway (company)\")   + [Hailuo AI](/wiki/MiniMax_(company)#Hailuo_AI \"MiniMax (company)\")   + [Kling](/wiki/Kling_(text-to-video_model) \"Kling (text-to-video model)\")   + [Sora](/wiki/Sora_(text-to-video_model) \"Sora (text-to-video model)\")   + [Veo](/wiki/Veo_(text-to-video_model) \"Veo (text-to-video model)\") * [Music generation](/wiki/Music_and_artificial_intelligence \"Music and artificial intelligence\")   + [Riffusion](/wiki/Riffusion \"Riffusion\")   + [Suno AI](/wiki/Suno_AI \"Suno AI\")   + [Udio](/wiki/Udio \"Udio\") | | Text | * [Word2vec](/wiki/Word2vec \"Word2vec\") * [Seq2seq](/wiki/Seq2seq \"Seq2seq\") * [GloVe](/wiki/GloVe \"GloVe\") * [BERT](/wiki/BERT_(language_model) \"BERT (language model)\") * [T5](/wiki/T5_(language_model) \"T5 (language model)\") * [Llama](/wiki/Llama_(language_model) \"Llama (language model)\") * [Chinchilla AI](/wiki/Chinchilla_(language_model) \"Chinchilla (language model)\") * [PaLM](/wiki/PaLM \"PaLM\") * [GPT](/wiki/Generative_pre-trained_transformer \"Generative pre-trained transformer\")   + [1](/wiki/GPT-1 \"GPT-1\")   + [2](/wiki/GPT-2 \"GPT-2\")   + [3](/wiki/GPT-3 \"GPT-3\")   + [J](/wiki/GPT-J \"GPT-J\")   + [ChatGPT](/wiki/ChatGPT \"ChatGPT\")   + [4](/wiki/GPT-4 \"GPT-4\")   + [4o](/wiki/GPT-4o \"GPT-4o\")   + [o1](/wiki/OpenAI_o1 \"OpenAI o1\")   + [o3](/wiki/OpenAI_o3 \"OpenAI o3\")   + [4.5](/wiki/GPT-4.5 \"GPT-4.5\")   + [4.1](/wiki/GPT-4.1 \"GPT-4.1\")   + [o4-mini](/wiki/OpenAI_o4-mini \"OpenAI o4-mini\")   + [5](/wiki/GPT-5 \"GPT-5\") * [Claude](/wiki/Claude_(language_model) \"Claude (language model)\") * [Gemini](/wiki/Gemini_(chatbot) \"Gemini (chatbot)\")   + [Gemini (language model)](/wiki/Gemini_(language_model) \"Gemini (language model)\")   + [Gemma](/wiki/Gemma_(language_model) \"Gemma (language model)\") * [Grok](/wiki/Grok_(chatbot) \"Grok (chatbot)\") * [LaMDA](/wiki/LaMDA \"LaMDA\") * [BLOOM](/wiki/BLOOM_(language_model) \"BLOOM (language model)\") * [DBRX](/wiki/DBRX \"DBRX\") * [Project Debater](/wiki/Project_Debater \"Project Debater\") * [IBM Watson](/wiki/IBM_Watson \"IBM Watson\") * [IBM Watsonx](/wiki/IBM_Watsonx \"IBM Watsonx\") * [Granite](/wiki/IBM_Granite \"IBM Granite\") * [PanGu-Σ](/wiki/Huawei_PanGu \"Huawei PanGu\") * [DeepSeek](/wiki/DeepSeek_(chatbot) \"DeepSeek (chatbot)\") * [Qwen](/wiki/Qwen \"Qwen\") | | Decisional | * [AlphaGo](/wiki/AlphaGo \"AlphaGo\") * [AlphaZero](/wiki/AlphaZero \"AlphaZero\") * [OpenAI Five](/wiki/OpenAI_Five \"OpenAI Five\") * [Self-driving car](/wiki/Self-driving_car \"Self-driving car\") * [MuZero](/wiki/MuZero \"MuZero\") * [Action selection](/wiki/Action_selection \"Action selection\")   + [AutoGPT](/wiki/AutoGPT \"AutoGPT\") * [Robot control](/wiki/Robot_control \"Robot control\") | |\\n| People | * [Alan Turing](/wiki/Alan_Turing \"Alan Turing\") * [Warren Sturgis McCulloch](/wiki/Warren_Sturgis_McCulloch \"Warren Sturgis McCulloch\") * [Walter Pitts](/wiki/Walter_Pitts \"Walter Pitts\") * [John von Neumann](/wiki/John_von_Neumann \"John von Neumann\") * [Claude Shannon](/wiki/Claude_Shannon \"Claude Shannon\") * [Shun\\'ichi Amari](/wiki/Shun%27ichi_Amari \"Shun\\'ichi Amari\") * [Kunihiko Fukushima](/wiki/Kunihiko_Fukushima \"Kunihiko Fukushima\") * [Takeo Kanade](/wiki/Takeo_Kanade \"Takeo Kanade\") * [Marvin Minsky](/wiki/Marvin_Minsky \"Marvin Minsky\") * [John McCarthy](/wiki/John_McCarthy_(computer_scientist) \"John McCarthy (computer scientist)\") * [Nathaniel Rochester](/wiki/Nathaniel_Rochester_(computer_scientist) \"Nathaniel Rochester (computer scientist)\") * [Allen Newell](/wiki/Allen_Newell \"Allen Newell\") * [Cliff Shaw](/wiki/Cliff_Shaw \"Cliff Shaw\") * [Herbert A. Simon](/wiki/Herbert_A._Simon \"Herbert A. Simon\") * [Oliver Selfridge](/wiki/Oliver_Selfridge \"Oliver Selfridge\") * [Frank Rosenblatt](/wiki/Frank_Rosenblatt \"Frank Rosenblatt\") * [Bernard Widrow](/wiki/Bernard_Widrow \"Bernard Widrow\") * [Joseph Weizenbaum](/wiki/Joseph_Weizenbaum \"Joseph Weizenbaum\") * [Seymour Papert](/wiki/Seymour_Papert \"Seymour Papert\") * [Seppo Linnainmaa](/wiki/Seppo_Linnainmaa \"Seppo Linnainmaa\") * [Paul Werbos](/wiki/Paul_Werbos \"Paul Werbos\") * [Geoffrey Hinton](/wiki/Geoffrey_Hinton \"Geoffrey Hinton\") * [John Hopfield](/wiki/John_Hopfield \"John Hopfield\") * [Jürgen Schmidhuber](/wiki/J%C3%BCrgen_Schmidhuber \"Jürgen Schmidhuber\") * [Yann LeCun](/wiki/Yann_LeCun \"Yann LeCun\") * [Yoshua Bengio](/wiki/Yoshua_Bengio \"Yoshua Bengio\") * [Lotfi A. Zadeh](/wiki/Lotfi_A._Zadeh \"Lotfi A. Zadeh\") * [Stephen Grossberg](/wiki/Stephen_Grossberg \"Stephen Grossberg\") * [Alex Graves](/wiki/Alex_Graves_(computer_scientist) \"Alex Graves (computer scientist)\") * [James Goodnight](/wiki/James_Goodnight \"James Goodnight\") * [Andrew Ng](/wiki/Andrew_Ng \"Andrew Ng\") * [Fei-Fei Li](/wiki/Fei-Fei_Li \"Fei-Fei Li\") * [Alex Krizhevsky](/wiki/Alex_Krizhevsky \"Alex Krizhevsky\") * [Ilya Sutskever](/wiki/Ilya_Sutskever \"Ilya Sutskever\") * [Oriol Vinyals](/wiki/Oriol_Vinyals \"Oriol Vinyals\") * [Quoc V. Le](/wiki/Quoc_V._Le \"Quoc V. Le\") * [Ian Goodfellow](/wiki/Ian_Goodfellow \"Ian Goodfellow\") * [Demis Hassabis](/wiki/Demis_Hassabis \"Demis Hassabis\") * [David Silver](/wiki/David_Silver_(computer_scientist) \"David Silver (computer scientist)\") * [Andrej Karpathy](/wiki/Andrej_Karpathy \"Andrej Karpathy\") * [Ashish Vaswani](/wiki/Ashish_Vaswani \"Ashish Vaswani\") * [Noam Shazeer](/wiki/Noam_Shazeer \"Noam Shazeer\") * [Aidan Gomez](/wiki/Aidan_Gomez \"Aidan Gomez\") * [John Schulman](/wiki/John_Schulman \"John Schulman\") * [Mustafa Suleyman](/wiki/Mustafa_Suleyman \"Mustafa Suleyman\") * [Jan Leike](/wiki/Jan_Leike \"Jan Leike\") * [Daniel Kokotajlo](/wiki/Daniel_Kokotajlo_(researcher) \"Daniel Kokotajlo (researcher)\") * [François Chollet](/wiki/Fran%C3%A7ois_Chollet \"François Chollet\") |\\n| Architectures | * [Neural Turing machine](/wiki/Neural_Turing_machine \"Neural Turing machine\") * [Differentiable neural computer](/wiki/Differentiable_neural_computer \"Differentiable neural computer\") * [Transformer](/wiki/Transformer_(deep_learning_architecture) \"Transformer (deep learning architecture)\")   + [Vision transformer (ViT)](/wiki/Vision_transformer \"Vision transformer\") * [Recurrent neural network (RNN)](/wiki/Recurrent_neural_network \"Recurrent neural network\") * [Long short-term memory (LSTM)](/wiki/Long_short-term_memory \"Long short-term memory\") * [Gated recurrent unit (GRU)](/wiki/Gated_recurrent_unit \"Gated recurrent unit\") * [Echo state network](/wiki/Echo_state_network \"Echo state network\") * [Multilayer perceptron (MLP)](/wiki/Multilayer_perceptron \"Multilayer perceptron\") * [Convolutional neural network (CNN)](/wiki/Convolutional_neural_network \"Convolutional neural network\") * [Residual neural network (RNN)](/wiki/Residual_neural_network \"Residual neural network\") * [Highway network](/wiki/Highway_network \"Highway network\") * [Mamba](/wiki/Mamba_(deep_learning_architecture) \"Mamba (deep learning architecture)\") * [Autoencoder](/wiki/Autoencoder \"Autoencoder\") * [Variational autoencoder (VAE)](/wiki/Variational_autoencoder \"Variational autoencoder\") * [Generative adversarial network (GAN)](/wiki/Generative_adversarial_network \"Generative adversarial network\") * [Graph neural network (GNN)](/wiki/Graph_neural_network \"Graph neural network\") |\\n| * [Category](/wiki/Category:Artificial_intelligence \"Category:Artificial intelligence\") | |\\n\\nRetrieved from \"<https://en.wikipedia.org/w/index.php?title=Model_Context_Protocol&oldid=1309852297>\"\\n\\n[Categories](/wiki/Help:Category \"Help:Category\"):\\n\\n* [Application layer protocols](/wiki/Category:Application_layer_protocols \"Category:Application layer protocols\")\\n* [Generative artificial intelligence](/wiki/Category:Generative_artificial_intelligence \"Category:Generative artificial intelligence\")\\n* [Open standards](/wiki/Category:Open_standards \"Category:Open standards\")\\n\\nHidden categories:\\n\\n* [All pages needing factual verification](/wiki/Category:All_pages_needing_factual_verification \"Category:All pages needing factual verification\")\\n* [Wikipedia articles needing factual verification from May 2025](/wiki/Category:Wikipedia_articles_needing_factual_verification_from_May_2025 \"Category:Wikipedia articles needing factual verification from May 2025\")\\n* [Articles with short description](/wiki/Category:Articles_with_short_description \"Category:Articles with short description\")\\n* [Short description is different from Wikidata](/wiki/Category:Short_description_is_different_from_Wikidata \"Category:Short description is different from Wikidata\")\\n* [Pages displaying short descriptions of redirect targets via Module:Annotated link](/wiki/Category:Pages_displaying_short_descriptions_of_redirect_targets_via_Module:Annotated_link \"Category:Pages displaying short descriptions of redirect targets via Module:Annotated link\")'},\n",
              " {'title': 'What is Model Context Protocol and how to leverage it in the fintech ...',\n",
              "  'url': 'https://prometeoapi.com/en/blog/model-context-protocol-fintech',\n",
              "  'content': 'What is Model Context Protocol (MCP)?\\n\\nThe Model Context Protocol (MCP) is an open and standard protocol designed to facilitate interoperability between large language models (LLMs) and external data sources or services. Its primary purpose is to standardize how artificial intelligence (AI) agents access, read, and write information across multiple systems, eliminating the need for custom integrations for each interaction.\\n\\nDefinition and purpose of MCP [...] The Model Context Protocol (MCP) is emerging as a key standard for connecting artificial intelligence with financial systems in a structured, secure, and scalable way. By allowing language models to interact with APIs, databases, and external services without custom integrations, MCP enables new levels of automation and interoperability. [...] This compatibility makes the protocol a key component for building intelligent financial ecosystems where autonomous agents operate seamlessly across multiple services using a common language.\\n\\nIn simple words: The Model Context Protocol represents a new layer to achieve effective interoperability between advanced artificial intelligence and the diverse technological infrastructures of the financial sector.\\n\\nBenefits of MCP in the fintech industry',\n",
              "  'score': 0.91936076,\n",
              "  'raw_content': 'Products\\n\\nOur Products\\n\\nUse Cases\\n\\nUse Cases\\n\\nResources\\n\\nAbout Prometeo\\n\\nBlog\\n\\nLogin\\n\\nSpanish\\n\\nPortuguese\\n\\nWhat is Model Context Protocol and how to leverage it in the fintech industry?\\n\\nThe Model Context Protocol (MCP) in Fintech emerges as a key innovation to transform how financial institutions integrate artificial intelligence (AI) into their daily operations.\\n\\nContents\\n\\nThe Model Context Protocol (MCP) in Fintech emerges as a key innovation to transform how financial institutions integrate artificial intelligence (AI) into their daily operations.\\n\\nThis open protocol standardizes communication between large language models (LLMs) and various external data sources, tools, and services, enabling unprecedented interoperability in the financial sector.\\n\\nThe significance of MCP in financial services lies in its ability to connect intelligent agents with complex systems, from payment platforms to risk management and customer service solutions. This connectivity facilitates advanced automation, enhances security, and optimizes regulatory compliance.\\n\\nThis article will cover:\\n\\n\\n\\nThe analysis will delve into how MCP is laying the groundwork for a new generation of intelligent, modular, and scalable financial services.\\n\\nWhat is Model Context Protocol (MCP)?\\n\\nThe Model Context Protocol (MCP) is an open and standard protocol designed to facilitate interoperability between large language models (LLMs) and external data sources or services. Its primary purpose is to standardize how artificial intelligence (AI) agents access, read, and write information across multiple systems, eliminating the need for custom integrations for each interaction.\\n\\nDefinition and purpose of MCP\\n\\nMCP acts as a universal bridge connecting AI models with tools, databases, and external APIs. This connection is achieved through a common schema defining how messages, requests, and responses are exchanged between AI agents and data sources. The standardization MCP offers allows different financial platforms and services to interoperate without technical friction or incompatibilities.\\n\\nTechnical operation: MCP clients and servers\\n\\nThe MCP protocol is based on a client-server architecture:\\n\\n\\n\\nCommunication is bidirectional, secure, and structured. Clients send queries or commands to the MCP server, which responds with precise data or confirms task completion. This mechanism supports both reading and writing information, enabling dynamic and adaptive flows in automated processes.\\n\\nImportance of standardization in connecting AI agents and external tools\\n\\nWithout a standardized protocol like MCP, each integration would require specific development, generating high operational costs and limiting scalability. MCP ensures:\\n\\n\\n\\nThis structured approach is especially critical in fintech environments where accuracy, security, and regulatory compliance are priorities.\\n\\nRelation to current technology ecosystems\\n\\nMCP is designed for easy integration with existing technologies:\\n\\n\\n\\nThis compatibility makes the protocol a key component for building intelligent financial ecosystems where autonomous agents operate seamlessly across multiple services using a common language.\\n\\nIn simple words: The Model Context Protocol represents a new layer to achieve effective interoperability between advanced artificial intelligence and the diverse technological infrastructures of the financial sector.\\n\\nBenefits of MCP in the fintech industry\\n\\nThe benefits of the Model Context Protocol (MCP) in the fintech industry are significant and deliver value across several key aspects:\\n\\nCombined, these benefits highlight the positive impact the Model Context Protocol can have in fintech, driving innovation, efficiency, and security in AI-driven financial operations.\\n\\nUse cases of MCP in fintech\\n\\nThe Model Context Protocol (MCP) has begun transforming various processes within the fintech sector, demonstrating its potential through concrete use cases illustrating its applicability and benefits.\\n\\nEmbedded finance\\n\\nGlobal fintech companies have started integrating MCP to enhance their Embedded Finance services, allowing AI models to communicate directly with payment and financial management platforms without needing specific developments for each case. This integration enables automatic execution of transactions, reconciliations, and financial validations in real-time, improving user experience and operational efficiency.\\n\\nVirtual sssistants and digital payments\\n\\nThe protocol enables intelligent virtual assistants capable of interacting simultaneously with multiple financial services. For instance, AI agents can process digital payment requests, verify balances, or even negotiate credit conditions via standardized connections to banks, billing systems, and SaaS platforms. This reduces time and errors associated with manual processes, facilitating quick and precise customer responses.\\n\\nIntelligent automation in orders, invoicing, and disputes\\n\\nIn financial administrative management, MCP allows automation of complex workflows such as:\\n\\n\\n\\nThese AI agents interact with internal databases, ERP systems, or external services without additional middleware, enhancing productivity and reducing operational costs.\\n\\nCRM system integration\\n\\nCRM platforms leverage MCP to enhance customer interactions through integrated AI. Agents can access financial histories, user preferences, and behaviors stored internally or externally to personalize financial recommendations, increasing loyalty by offering tailored solutions based on updated, precise information obtained via standardized protocols.\\n\\nThese use cases illustrate how the Model Context Protocol is emerging as a fundamental tool for redefining fintech processes through advanced interoperability between AI models and external services.\\n\\nImplementation of MCP in fintech platforms\\n\\nImplementing the Model Context Protocol (MCP) in fintech platforms does not require reinventing existing technological architectures but does demand adopting new integration logic between artificial intelligence (AI) agents and financial systems.\\n\\nAs previously mentioned, MCP operates under a client-server model. On the server side, a layer is built to expose tools, resources, and interaction prompts that language models (LLMs) can invoke. These tools can range from connectors to databases and services to actions on files or cloud-hosted services.\\n\\nOn the client side, the AI agent connects to one or more MCP servers and can query data, execute operations, or enrich its context without needing customized integration. The logic of when and how to use each tool resides within the model or the application orchestrating it.\\n\\nKey elements fintech platforms must consider when implementing MCP include:\\n\\nWith these tools, fintech platforms can construct modular artificial intelligence ecosystems that integrate standardly with internal and external services, facilitating smarter, more flexible, and secure financial products. MCP is not merely a new protocol; it represents a new mindset for connectivity between AI models and financial infrastructure.\\n\\nChallenges and considerations when adopting MCP in fintech\\n\\nWhile the Model Context Protocol (MCP) offers a powerful proposition to standardize interactions between language models and financial systems, its adoption in fintech environments comes with specific challenges that must be carefully managed:\\n\\nPermission Management and Sensitive Data\\n\\nFinancial data management demands high standards for security, privacy, and regulatory compliance (KYC, AML, GDPR, etc.). MCP introduces a new vector: AI agents accessing, processing, and acting on this data. Fintech companies must implement robust authentication controls (such as OAuth 2.0), define clear scopes, and limit model access strictly to necessary resources.\\n\\nTechnical Complexity in Orchestration\\n\\nAlthough MCP standardizes communication, integrating multiple servers (databases, CRMs, internal APIs) under a unified model requires rethinking technical architecture. Defining functions exposed by each server, how they are invoked, versioned, and monitored, requires coordination among AI, DevOps, and compliance teams.\\n\\nGovernance and Traceability of Autonomous Decisions\\n\\nModels operating with MCP can autonomously make context-based decisions. This raises accountability questions: who is responsible if an agent makes an error executing a financial action? How is that action audited? Fintech companies must design logging, reversibility, and clear auditing mechanisms to maintain agent control.\\n\\nVersioning, Testing, and Regression Risks\\n\\nAs MCP servers may be built and maintained by third parties or different internal teams, controlling changes is critical. Updating a server without proper testing could disrupt entire workflows. Mature practices for versioning, automated testing, and evaluation frameworks specific to MCP agents are required.\\n\\nEcosystem Stills in Evolution\\n\\nMCP remains an emerging technology. There is a lack of maturity in tools, documentation, and best practices. Additionally, the discovery and management of servers (registries, .well-known, etc.) are still under construction. Adopting it implies accepting uncertainty and being ready to experiment and contribute to the ecosystem.\\n\\nTraining and Cultural Change\\n\\nIntegrating MCP is not just a technical decision but also cultural. Teams must understand how to design workflows with intelligent agents, structure useful tools for models, and adapt internal processes to this new plug-and-play logic between AI and legacy systems.\\n\\nRisks related to MCP integration\\n\\nUsing MCP in financial environments opens new possibilities for automation and interoperability but introduces operational and cybersecurity risks that must be considered from the design stage:\\n\\nIncreased Attack Surface\\n\\nMCP enables dynamic connections between language models and internal or external services (databases, CRMs, APIs), multiplying entry points potentially exploited by attackers without robust protection measures.\\n\\n\\n\\nUnauthorized Access and Privilege Escalation\\n\\nIf permissions are not managed accurately, models might access data or execute actions beyond intended scopes, leading to confidential data leaks or alterations in payment and accounting systems.\\n\\n\\n\\nRegression Risks and Silent Failures\\n\\nUncontrolled changes in MCP servers (by third parties or internal teams) can introduce silent failures in automated workflows, difficult to detect until significant impact occurs.\\n\\n\\n\\nGovernance Challenges with Community Servers\\n\\nMany MCP servers are built and shared by the community. Although this accelerates innovation, it also raises concerns about the reliability, maintenance, and security of these components.\\n\\n\\n\\nAbsence of Mature Monitoring and Response Tools\\n\\nThe MCP ecosystem is still in formation. Many tools for monitoring, logging, traceability, and incident response are not yet fully developed or standardized.\\n\\n\\n\\nFuture of MCP in fintech\\n\\nThe Model Context Protocol is still in an early stage of adoption, but all indications suggest that it will play a key role in the next generation of financial infrastructure. Its ability to orchestrate intelligent interactions between AI models and complex systems positions it as a natural catalyst for automation, operational efficiency, and personalization at scale.\\n\\nIn the short term, we will see growing adoption in cases such as financial assistants, embedded payments, automated reconciliations, and smarter onboarding flows. As the ecosystem matures, specialized frameworks, verified servers, public registries, and best governance practices will emerge to facilitate its mass integration.\\n\\nIn the medium term, MCP could become the de facto standard for building autonomous financial agents—capable of operating securely, audibly, and in compliance with regulations—within banks, fintechs, insurers, and technology platforms.\\n\\nBut for this potential to materialize, it will be key for the fintech industry to:\\n\\n\\n\\nThe future of MCP is not just about the technology itself, but about how institutions leverage it to transform their operational logic. If implemented with vision and care, it can become the foundation of a new financial infrastructure that is more open, modular, and user-centered.\\n\\nConclusion\\n\\nThe Model Context Protocol (MCP) is emerging as a key standard for connecting artificial intelligence with financial systems in a structured, secure, and scalable way. By allowing language models to interact with APIs, databases, and external services without custom integrations, MCP enables new levels of automation and interoperability.\\n\\nFor fintechs, it represents an opportunity to design smarter agents, reduce integration times, and adapt their processes to dynamic, regulated environments. However, it also presents technical, cultural, and governance challenges that must be managed rigorously.\\n\\nSuccess in its implementation will depend on adopting best practices in authentication, access control, versioning, and monitoring, as well as fostering teams capable of designing these new architectures. MCP is not just a technical innovation—it is a new operational logic. Those who understand it early will be able to lead the evolution of the financial ecosystem.\\n\\nAuthor\\n\\nGonzalo Sanchez\\n\\nSenior Content Creator\\n\\nContents\\n\\nShare\\n\\nSchedule a call\\n\\nDiscover how our API can optimize your services.\\n\\nAuthor\\n\\nGonzalo Sanchez\\n\\nSenior Content Creator\\n\\nShare\\n\\nRelated posts\\n\\n10 may 2024\\n\\n/\\n\\nRosario Flores Vidal\\n\\nWhat is Treasury Management and what is it for?\\n\\nProduct\\n\\n22 feb 2022\\n\\n/\\n\\nIvan Wortman\\n\\nDigital or electronic payments: What are they? Methods and advantages\\n\\nProduct\\n\\n03 jul 2023\\n\\n/\\n\\nLia Garayalde\\n\\nValidate bank accounts with Prometeo\\n\\nProduct\\n\\nOne API → Infinite Possibilities\\n\\n'},\n",
              " {'title': 'Model Context Protocol',\n",
              "  'url': 'https://modelcontextprotocol.io/',\n",
              "  'content': 'MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems.Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)—enabling them to access key information and perform tasks.Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a',\n",
              "  'score': 0.9125066,\n",
              "  'raw_content': 'What is the Model Context Protocol (MCP)? - Model Context Protocol\\n\\n===============\\n\\n[Model Context Protocol home page![Image 1: light logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/light.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=4498cb8a57d574005f3dca62bdd49c95)![Image 2: dark logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/dark.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=c0687c003f8f2cbdb24772ab4c8a522c)](https://modelcontextprotocol.io/)\\n\\nSearch...\\n\\n⌘K\\n\\n*   [Blog](https://blog.modelcontextprotocol.io/)\\n*   [GitHub](https://github.com/modelcontextprotocol)\\n\\nSearch...\\n\\nNavigation\\n\\nGet started\\n\\nWhat is the Model Context Protocol (MCP)?\\n\\n[Documentation](https://modelcontextprotocol.io/docs/getting-started/intro)[Specification](https://modelcontextprotocol.io/specification/2025-06-18)[Community](https://modelcontextprotocol.io/community/communication)[About MCP](https://modelcontextprotocol.io/about)\\n\\n##### Get started\\n\\n*   [What is MCP?](https://modelcontextprotocol.io/docs/getting-started/intro)\\n\\n##### About MCP\\n\\n*   [Architecture](https://modelcontextprotocol.io/docs/learn/architecture)\\n*   [Servers](https://modelcontextprotocol.io/docs/learn/server-concepts)\\n*   [Clients](https://modelcontextprotocol.io/docs/learn/client-concepts)\\n*   [Versioning](https://modelcontextprotocol.io/specification/versioning)\\n\\n##### Develop with MCP\\n\\n*   [Connect to local MCP servers](https://modelcontextprotocol.io/docs/develop/connect-local-servers)\\n*   [Connect to remote MCP Servers](https://modelcontextprotocol.io/docs/develop/connect-remote-servers)\\n*   [Build an MCP server](https://modelcontextprotocol.io/docs/develop/build-server)\\n*   [Build an MCP client](https://modelcontextprotocol.io/docs/develop/build-client)\\n*   [SDKs](https://modelcontextprotocol.io/docs/sdk)\\n\\n##### Developer tools\\n\\n*   [MCP Inspector](https://modelcontextprotocol.io/legacy/tools/inspector)\\n\\nOn this page\\n\\n*   [What can MCP enable?](https://modelcontextprotocol.io/#what-can-mcp-enable%3F)\\n*   [Why does MCP matter?](https://modelcontextprotocol.io/#why-does-mcp-matter%3F)\\n*   [Start Building](https://modelcontextprotocol.io/#start-building)\\n*   [Learn more](https://modelcontextprotocol.io/#learn-more)\\n\\nGet started\\n\\nWhat is the Model Context Protocol (MCP)?\\n=========================================\\n\\nCopy page\\n\\nCopy page\\n\\nMCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems.Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)—enabling them to access key information and perform tasks.Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems.\\n\\n![Image 3](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/mcp-simple-diagram.png?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=9337f8096debc55621adcaf8ca563695)\\n\\n[\\u200b](https://modelcontextprotocol.io/#what-can-mcp-enable%3F)\\n\\nWhat can MCP enable?\\n----------------------------------------------------------------------------------\\n\\n*   Agents can access your Google Calendar and Notion, acting as a more personalized AI assistant.\\n*   Claude Code can generate an entire web app using a Figma design.\\n*   Enterprise chatbots can connect to multiple databases across an organization, empowering users to analyze data using chat.\\n*   AI models can create 3D designs on Blender and print them out using a 3D printer.\\n\\n[\\u200b](https://modelcontextprotocol.io/#why-does-mcp-matter%3F)\\n\\nWhy does MCP matter?\\n----------------------------------------------------------------------------------\\n\\nDepending on where you sit in the ecosystem, MCP can have a range of benefits.\\n*   **Developers**: MCP reduces development time and complexity when building, or integrating with, an AI application or agent.\\n*   **AI applications or agents**: MCP provides access to an ecosystem of data sources, tools and apps which will enhance capabilities and improve the end-user experience.\\n*   **End-users**: MCP results in more capable AI applications or agents which can access your data and take actions on your behalf when necessary.\\n\\n[\\u200b](https://modelcontextprotocol.io/#start-building)\\n\\nStart Building\\n--------------------------------------------------------------------\\n\\n[Build servers ------------- Create MCP servers to expose your data and tools](https://modelcontextprotocol.io/docs/develop/build-server)[Build clients ------------- Develop applications that connect to MCP servers](https://modelcontextprotocol.io/docs/develop/build-client)\\n\\n[\\u200b](https://modelcontextprotocol.io/#learn-more)\\n\\nLearn more\\n------------------------------------------------------------\\n\\n[Understand concepts ------------------- Learn the core concepts and architecture of MCP](https://modelcontextprotocol.io/docs/learn/architecture)\\n\\nWas this page helpful?\\n\\nYes No\\n\\n[Architecture](https://modelcontextprotocol.io/docs/learn/architecture)\\n\\n[github](https://github.com/modelcontextprotocol)\\n\\nAssistant\\n\\nResponses are generated using AI and may contain mistakes.\\n'},\n",
              " {'title': 'Why Your Company Should Know About Model Context Protocol',\n",
              "  'url': 'https://www.nasuni.com/blog/why-your-company-should-know-about-model-context-protocol/',\n",
              "  'content': \"Virtual Session | 9.23 | Where Your AI Budget Should (and Shouldn't) Go with Frost and Sullivan | Register now!\\n\\nThe Model Context Protocol (MCP) is an open standard developed by Anthropic that enables secure, two-way connections between AI models and an organization’s data sources. Think of it as a universal adapter that allows AI systems and agents to safely access and interact with your business data, tools, and systems. [...] MCP can be thought of as the bridge that enables companies to evolve from simple AI implementations to sophisticated, agentic systems that can transform how work gets done.\\n\\n## The Future Is Agentic\\n\\nAs agentic AI becomes the backbone of modern business operations, the difference between success and stagnation lies in how well your systems connect, collaborate and provide standardized access to the data required. [...] MCP addresses a critical limitation in current AI agent implementations: the isolation of AI models from the systems where a company’s data lives. Without MCP, every new data source requires its own custom integration, making truly connected, agentic systems difficult to scale. You can think of MCP as the “nervous system” that allows AI agents to perceive and act upon your business environment.\\n\\n## Why Should Your Business Care About Model Context Protocol?\\n\\n### 1. Build Effective AI Agents\",\n",
              "  'score': 0.9106172,\n",
              "  'raw_content': \"Virtual Session | 9.23 | Where Your AI Budget Should (and Shouldn't) Go with Frost and Sullivan |\\xa0[Register now!](https://registration.nasuni.com/unify-episode-5/?utm_source=website&utm_medium=homepage-banner&utm_content=unify-5&utm_campaign=701RQ00000PzWj3YAF&utm_term=nasuni\\n\\n)\\n\\nThe Model Context Protocol (MCP) is an open standard developed by Anthropic that enables secure, two-way connections between AI models and an organization’s data sources. Think of it as a universal adapter that allows AI systems and agents to safely access and interact with your business data, tools, and systems.\\n\\nMCP addresses a critical limitation in current AI agent implementations: the isolation of AI models from the systems where a company’s data lives. Without MCP, every new data source requires its own custom integration, making truly connected, agentic systems difficult to scale. You can think of MCP as the “nervous system” that allows AI agents to perceive and act upon your business environment.\\n\\n## Why Should Your Business Care About Model Context Protocol?\\n\\n### 1. Build Effective AI Agents\\n\\nMCP provides the foundation for building effective AI agent frameworks — systems that can operate autonomously to accomplish complex tasks (the autonomous piece is what differentiates them from copilot or chat agents). As Anthropic [notes](https://www.anthropic.com/engineering/building-effective-agents) in their research on building effective agents, the most successful agentic systems aren’t built with complex frameworks but with “simple, composable patterns.” MCP delivers exactly this kind of composable architecture.\\n\\nWith MCP, you can build agents that:\\n\\n* Plan and execute multi-step tasks\\n* Use tools and APIs to take actions\\n* Access and reason over your organization’s data\\n* Adapt to changing information and requirements\\n\\n### 2. Unlock the Full Potential of Your AI Investments\\n\\nYour AI agents are only as good as the data they can access and the actions they can take. With MCP, you can connect your agents to:\\n\\n* Nasuni managed files and data\\n* Customer relationship management systems\\n* Project management tools\\n* Development environments and code repositories\\n* And virtually any other data source your company relies on\\n\\nInstead of AI agent systems that operate in isolation, MCP allows them to draw on your organization’s collective knowledge and act on its behalf, which ultimately leads to more accurate, contextual, and valuable outputs.\\n\\n### 3. Simplify Integration, Reduce Development Costs\\n\\nBefore MCP, connecting AI Agents to your data required custom implementations for every integration point. This approach is:\\n\\n* Resource-intensive\\n* Difficult to maintain\\n* Hard to scale\\n* Prone to security vulnerabilities\\n\\nMCP replaces fragmented integrations with a single, standardized protocol. This means your development team can build once and connect to many data sources, significantly reducing implementation time and costs.\\n\\n### 4. Enhance Security and Control\\n\\nMCP was designed with security as a foundational principle. It provides:\\n\\n* Explicit user consent requirements\\n* Clear permission models\\n* Granular access controls\\n* Transparent tool usage\\n\\nThis means your organization can connect AI systems to sensitive business data while still maintaining appropriate security boundaries and controls.\\n\\n### 5. Future-Proof Your AI Strategy\\n\\nAs an open standard, MCP is rapidly being adopted across the AI ecosystem. Companies such as Google, Microsoft, OpenAI, Replit, and Zapier have already announced MCP support. By implementing MCP, your organization positions can benefit from this large and growing ecosystem of compatible tools and services.\\n\\n## Real-World Applications of AI Agents with Model Context Protocol\\n\\nMCP enables the creation of powerful agentic systems that can transform how your business operates. As noted in Anthropic’s research, the most promising applications for AI agents are those that combine conversation with action, have clear success criteria, enable feedback loops, and integrate meaningful human oversight.\\n\\n### Example 1: Intelligent Document Processing\\n\\nA legal firm could implement an MCP-enabled agent connected to their Nasuni file system that:\\n\\n* Automatically processes contract documents that land in a particular share path\\n* Extracts key terms, deadlines, and obligations\\n* Cross-references with previous contracts in the system\\n* Flags inconsistencies or potential issues for review\\n* Updates their contract management database\\n* Generates executive summaries for the legal team\\n\\nBy connecting the agent directly to their secure Nasuni managed storage, the firm could reduce contract review time by up to 70% while increasing accuracy.\\n\\n### Example 2: Research Knowledge Synthesis\\n\\nA pharmaceutical research company could build an MCP agent that:\\n\\n* Scans their Nasuni stored files for research documents, lab reports, and study results\\n* Identifies connections between separate research initiatives\\n* Generates comprehensive literature reviews across their data\\n* Creates structured metadata for improved searchability\\n* Compiles custom research briefs based on specific queries\\n* Alerts researchers when new internal documents on a share relate to their areas of interest\\n\\nThis agent effectively turns their Nasuni file system into an intelligent knowledge base that actively supports research efforts rather than just storing information.\\n\\n### Example 3: Architecture, Engineering and Construction (AEC) Project Coordination\\n\\nAn AEC firm could implement an MCP-enabled agent that leverages their Nasuni file systems to:\\n\\n* Monitor their BIM (Building Information Modeling) files, CAD drawings, specifications, and regulatory documents across projects\\n* Flag regulatory compliance concerns by comparing designs against building codes stored in their knowledge base\\n* Generates daily coordination reports highlighting critical issues requiring resolution\\n* Links RFIs (Requests for Information) to relevant drawings and specifications\\n* Tracks version history of all project documents and summarizes changes between iterations\\n* Alerts project teams when updated documents might impact their work\\n* Prepares documentation packages for client and regulatory submissions\\n\\nBy integrating with Nasuni, the agent could reduce coordination errors, shorten review cycles, and help deliver projects on time and within budget. Most importantly, the system provided continuity and knowledge transfer between different project phases and teams – a critical advantage in an industry where information silos often lead to costly mistakes.\\n\\n## Getting Started with Model Context Protocol\\n\\nImplementing MCP within your organization is remarkably straightforward:\\n\\n1. **Start with pre-built servers**: Anthropic provides reference implementations for a File System, as well as Slack, GitHub, Git, Postgres, and more.\\n2. **Pilot with Claude for Desktop**: Your team can begin experimenting with local MCP servers connected to Claude Desktop to test capabilities.\\n3. **Develop custom connectors**: As your needs grow, your development team can leverage the growing ecosystem of MCP servers or build custom MCP servers for organization’s specific systems.\\n\\n## The Business Case for AI Agents\\n\\nThe business value of MCP and the agents it enables comes down to several key benefits:\\n\\n1. **Autonomous execution**: Agents can complete complex tasks with minimal human intervention, freeing your team to focus on higher-value work.\\n2. **Enhanced productivity**: By connecting AI agents to your systems, employees can accomplish more with less effort and delegate routine tasks.\\n3. **Cost reduction**: Standardized integration means lower development and maintenance costs for your AI infrastructure.\\n4. **Better outcomes**: Agents with access to relevant context and appropriate tools produce higher quality results.\\n5. **Scalable AI operations**: As your AI needs grow, MCP provides a consistent framework for adding new capabilities.\\n\\n## From Simple AI to Sophisticated Agents\\n\\nThe evolution of AI in business is following a clear progression:\\n\\n1. **Basic AI**: Simple question-answering systems with limited context.\\n2. **Augmented AI**: Systems enhanced with retrieval capabilities for specific use cases.\\n3. **Workflow AI**: AI integrated into predefined business processes.\\n4. **Agentic AI**: Systems that can plan, reason, and take action independently.\\n\\nMCP can be thought of as the bridge that enables companies to evolve from simple AI implementations to sophisticated, agentic systems that can transform how work gets done.\\n\\n## The Future Is Agentic\\n\\nAs agentic AI becomes the backbone of modern business operations, the difference between success and stagnation lies in how well your systems connect, collaborate and provide standardized access to the data required.\\n\\nThe Model Context Protocol isn’t just another technical standard — it’s shaping up to be the catalyst for the interoperable agentic enterprise. By leveraging MCP with Nasuni’s hybrid cloud platform, your organization can unlock the full potential of its data. Don’t just keep pace with the future, build it.\\n\\n## Related resources\\n\\nReport\\n\\n##### [The Era of Hybrid Cloud Storage](https://www.nasuni.com/?resource=the-era-of-hybrid-cloud-storage)\\n\\nResearch into the impact of digital transformation, AI, and security on storage strategies.\\n\\nLearn more\\n\\n##### [Backup and disaster recovery services](https://www.nasuni.com/solutions/backup-and-disaster-recovery-services/)\\n\\nWith the Nasuni File Data Platform’s disaster recovery services, your business will be back up and running in seconds, not days.\\n\\nLearn more\\n\\n##### [Ransomware protection](https://www.nasuni.com/product/ransomware-protection/)\\n\\nGet better ransomware risk mitigation. Our platform collects hundreds of immutable data snapshots daily and detects malicious activity at the edge.\\n\\nLearn more\\n\\n##### [Data foundation for AI](https://www.nasuni.com/solutions/data-foundation-for-ai/)\\n\\nNasuni’s hybrid cloud platform capabilities enhance your AI data strategy through consolidating, understanding, and leveraging your data.\\n\\nLearn more\\n\\nApril 09, 2025 | Jim Liddle\\n\\n##### [Is Your Enterprise Organization Vibe Coding?](https://www.nasuni.com/blog/is-your-enterprise-organization-vibe-coding/)\\n\\nNasuni’s Jim Liddle discusses the trend of vibe coding, and how enterprises can leverage it in their AI strategy.\\n\\nRead more\\n\\nMarch 19, 2025 | Nick Burling\\n\\n##### [Nasuni’s Role in Driving Enterprise AI Innovation](https://www.nasuni.com/blog/nasunis-role-in-driving-enterprise-ai-innovation/)\\n\\nSenior Vice President of Product Nick Burling shares how Nasuni plays a critical role in driving enterprise AI innovation.\\n\\nRead more\\n\\nReport\\n\\n##### [The Era of Hybrid Cloud Storage](https://www.nasuni.com/?resource=the-era-of-hybrid-cloud-storage)\\n\\nResearch into the impact of digital transformation, AI, and security on storage strategies.\\n\\nLearn more\\n\\n##### [Backup and disaster recovery services](https://www.nasuni.com/solutions/backup-and-disaster-recovery-services/)\\n\\nWith the Nasuni File Data Platform’s disaster recovery services, your business will be back up and running in seconds, not days.\\n\\nLearn more\\n\\n##### [Ransomware protection](https://www.nasuni.com/product/ransomware-protection/)\\n\\nGet better ransomware risk mitigation. Our platform collects hundreds of immutable data snapshots daily and detects malicious activity at the edge.\\n\\nLearn more\\n\\n##### [Data foundation for AI](https://www.nasuni.com/solutions/data-foundation-for-ai/)\\n\\nNasuni’s hybrid cloud platform capabilities enhance your AI data strategy through consolidating, understanding, and leveraging your data.\\n\\nLearn more\\n\\nApril 09, 2025 | Jim Liddle\\n\\n##### [Is Your Enterprise Organization Vibe Coding?](https://www.nasuni.com/blog/is-your-enterprise-organization-vibe-coding/)\\n\\nNasuni’s Jim Liddle discusses the trend of vibe coding, and how enterprises can leverage it in their AI strategy.\\n\\nRead more\\n\\nMarch 19, 2025 | Nick Burling\\n\\n##### [Nasuni’s Role in Driving Enterprise AI Innovation](https://www.nasuni.com/blog/nasunis-role-in-driving-enterprise-ai-innovation/)\\n\\nSenior Vice President of Product Nick Burling shares how Nasuni plays a critical role in driving enterprise AI innovation.\\n\\nRead more\\n\\nReport\\n\\n##### [The Era of Hybrid Cloud Storage](https://www.nasuni.com/?resource=the-era-of-hybrid-cloud-storage)\\n\\nResearch into the impact of digital transformation, AI, and security on storage strategies.\\n\\nLearn more\\n\\n##### [Backup and disaster recovery services](https://www.nasuni.com/solutions/backup-and-disaster-recovery-services/)\\n\\nWith the Nasuni File Data Platform’s disaster recovery services, your business will be back up and running in seconds, not days.\\n\\nLearn more\\n\\n##### [Ransomware protection](https://www.nasuni.com/product/ransomware-protection/)\\n\\nGet better ransomware risk mitigation. Our platform collects hundreds of immutable data snapshots daily and detects malicious activity at the edge.\\n\\nLearn more\\n\\n##### [Data foundation for AI](https://www.nasuni.com/solutions/data-foundation-for-ai/)\\n\\nNasuni’s hybrid cloud platform capabilities enhance your AI data strategy through consolidating, understanding, and leveraging your data.\\n\\nLearn more\\n\\nApril 09, 2025 | Jim Liddle\\n\\n##### [Is Your Enterprise Organization Vibe Coding?](https://www.nasuni.com/blog/is-your-enterprise-organization-vibe-coding/)\\n\\nNasuni’s Jim Liddle discusses the trend of vibe coding, and how enterprises can leverage it in their AI strategy.\\n\\nRead more\\n\\nMarch 19, 2025 | Nick Burling\\n\\n##### [Nasuni’s Role in Driving Enterprise AI Innovation](https://www.nasuni.com/blog/nasunis-role-in-driving-enterprise-ai-innovation/)\\n\\nSenior Vice President of Product Nick Burling shares how Nasuni plays a critical role in driving enterprise AI innovation.\\n\\nRead more\\n\\n123456\\n\\n\\n\\n\\n\\nSearch\"},\n",
              " {'title': 'What is the Model Context Protocol (MCP)?',\n",
              "  'url': 'https://www.cloudflare.com/learning/ai/what-is-model-context-protocol-mcp/',\n",
              "  'content': 'The Model Context Protocol is a standard way to make information available to large language models (LLMs). Somewhat similar to the way an application programming interface (API) works, MCP offers a documented, standardized way for a computer program to integrate services from an external source. It supports agentic AI: intelligent programs that can autonomously pursue goals and take action. [...] Sign upSales: +1 (888) 99 FLARE\\n\\n# What is the Model Context Protocol (MCP)?\\n\\nThe Model Context Protocol (MCP) enables AI agents to access external tools and data sources so that they can more effectively take action.\\n\\n#### Learning Objectives\\n\\nAfter reading this article you will be able to:\\n\\n Understand the role of the Model Context Protocol (MCP) in agentic AI\\n Explain how MCP works\\n Identify security challenges in MCP\\n\\nRelated Content [...] MCP is a protocol — an agreed-upon set of steps and instructions for use between diverse, network-connected computing devices. MCP presumes a client-server architecture, in which one entity, the client (the AI agent or a subsidiary program) sends requests to servers, which respond.',\n",
              "  'score': 0.902687,\n",
              "  'raw_content': '[Sign up](https://dash.cloudflare.com/sign-up)[Sales: +1 (888) 99 FLARE](tel:+18889935273)\\n\\n# What is the Model Context Protocol (MCP)?\\n\\nThe Model Context Protocol (MCP) enables AI agents to access external tools and data sources so that they can more effectively take action.\\n\\n#### Learning Objectives\\n\\nAfter reading this article you will be able to:\\n\\n* Understand the role of the Model Context Protocol (MCP) in agentic AI\\n* Explain how MCP works\\n* Identify security challenges in MCP\\n\\nRelated Content\\n\\n---\\n\\n[What is agentic AI?](/learning/ai/what-is-agentic-ai/)[What is a large language model (LLM)?](/learning/ai/what-is-large-language-model/)[What is generative AI?](/learning/ai/what-is-generative-ai/)[Vector database](/learning/ai/what-is-vector-database/)[What is artificial intelligence (AI)?](/learning/ai/what-is-artificial-intelligence/)\\n\\nCopy article link\\n\\n## What is the Model Context Protocol (MCP)?\\n\\nThe Model Context Protocol is a standard way to make information available to [large language models (LLMs)](/learning/ai/what-is-large-language-model/). Somewhat similar to the way an application programming interface (API) works, MCP offers a documented, standardized way for a computer program to integrate services from an external source. It supports [agentic AI](/learning/ai/what-is-agentic-ai/): intelligent programs that can autonomously pursue goals and take action.\\n\\nMCP, essentially, allows [AI](/learning/ai/what-is-artificial-intelligence/) programs to exceed their training. It enables them to incorporate new sources of information into their decision-making and content generation, and helps them connect to external tools.\\n\\nImagine an assistant who needs to make reservations for his boss at a restaurant. The assistant will call the restaurant\\'s phone number, ask what times they have available, and request a table. MCP is a way to provide a \"phone number\" to AI agents so that they can get the information they need in order to carry out tasks.\\n\\nMCP was developed by AI company Anthropic and later open-sourced. Since becoming open source in late 2024, MCP has rapidly become an industry standard, enabling more widespread use of AI agents.\\n\\n## What are AI agents?\\n\\nAI agents are AI programs built on top of LLMs. They use LLM information-processing capabilities to obtain data, make decisions, and take actions on behalf of human users.\\n\\nMCP is one way for AI agents to find the information they need and to take actions. It helps connect AI agents to the \"outside world,\" so to speak — the world beyond the LLM\\'s training data. (Other methods include [API](/learning/security/api/what-is-an-api/) integrations and headless browsing.)\\n\\n## How does MCP work?\\n\\nMCP is a [protocol](/learning/network-layer/what-is-a-protocol/) — an agreed-upon set of steps and instructions for use between diverse, network-connected computing devices. MCP presumes a client-server architecture, in which one entity, the client (the AI agent or a subsidiary program) sends requests to servers, which respond.\\n\\nMCP clients operate within MCP hosts. Clients maintain a one-to-one connection with MCP servers, but multiple clients can run from the same MCP host. Therefore MCP hosts can draw data from multiple MCP servers simultaneously. MCP servers, in turn, can use API integrations to obtain data from additional sources.\\n\\nWhat this means is that an AI agent can use MCP to connect to multiple servers at once — however, each connection takes place independently of every other connection. Think of a team of reporters at a newspaper, all contacting sources individually but then putting their information together to produce a news item.\\n\\n#### MCP messages\\n\\nThere are four types of messages used in MCP:\\n\\n* **Requests:** The client (contained within the host) asks for information from an MCP server.\\n* **Results:** The MCP server replies with the desired information.\\n* **Errors:** These are sent when the server cannot give a reply.\\n* **Notifications:** One-way messages that need no response (like a public service announcement). These can be sent by either client or server.\\n\\n#### Remote and local MCP connections\\n\\nMCP connections can be either remote or local. Remote connections take place between AI agents and MCP servers over the Internet. Local connections take place within the same machine (MCP clients and MCP servers are software programs running separately from each other).\\n\\n#### Steps in an MCP connection\\n\\nThere are three phases in MCP network communications:\\n\\n1. **Initialization:** The client sends the first message, and in the short series of messages that follows, client and server agree on protocol versions\\n2. **Message exchange:** Requests, results, and notifications are exchanged\\n3. **Termination:** Either the client or the server ends the connection with a \"close()\" message\\n\\nTo make MCP more secure, additional steps for [authentication](/learning/access-management/what-is-authentication/) and [authorization](/learning/access-management/authn-vs-authz/) may take place prior to these three phases.\\n\\n## What is an MCP server?\\n\\nAn MCP server is a program hosted on a server or in the cloud that exposes capabilities for AI agents to use via MCP. MCP servers can provide AI agents with access to new data sets or other tools that they need. For instance, an MCP server might allow an AI agent to use an email service, so that the agent can send emails on behalf of the human user it is assisting.\\n\\n## Is MCP secure?\\n\\nMCP does not have authentication, authorization, or [encryption](/learning/ssl/what-is-encryption/) natively built in, so developers have to implement that themselves or use a service that assists with implementation.\\n\\nMCP does not require the use of [HTTPS](/learning/ssl/what-is-https/) — instead running over [HTTP](/learning/ddos/glossary/hypertext-transfer-protocol-http/) in many implementations. It therefore can lack encryption and authentication unless developers proactively implement [Transport Layer Security (TLS)](/learning/ssl/transport-layer-security-tls/) usage. MCP, like any networking protocol, can be vulnerable to impersonation or to [on-path attacks](/learning/security/threats/on-path-attack/) if TLS is not used.\\n\\nBecause MCP offers similar functionality to an API (external parties requesting data and services), many of the [major API security considerations](/learning/security/api/owasp-api-security-top-10/) also apply to MCP implementations. Organizations making MCP servers available must ensure that confidential data is not exposed, that resources are protected, that excessive requests are stopped by [rate limiting](/learning/bots/what-is-rate-limiting/), that AI agents do not have too many permissions, and that inputs are validated and sanitized.\\n\\nSome MCP servers offer libraries to make OAuth implementation easier. Cloudflare provides an OAuth Provider Library that implements the provider side of the OAuth 2.1 protocol, allowing you to easily add authorization to your MCP server.\\n\\nDevelopers can use this OAuth Provider Library in three ways:\\n\\n* Integrating directly with a third-party OAuth provider\\n* Integrate with their own OAuth provider, including authorization-as-a-service providers\\n* A [Cloudflare Worker](https://workers.cloudflare.com/) ([serverless function](/learning/serverless/what-is-serverless/) deployed on the Cloudflare network) handles authorization, while an MCP server running on Cloudflare handles the complete OAuth flow\\n\\nCloudflare makes several MCP servers available for use by developers building agentic AI. Cloudflare also enables developers to build and deploy their own MCP servers to support AI agents. [Learn how to get started with MCP on Cloudflare](https://developers.cloudflare.com/agents/model-context-protocol/authorization/).\\n\\nGETTING STARTED\\n\\n* [Free plans](/plans/free/)\\n* [Small business plans](/small-business/)\\n* [For enterprises](/enterprise/)\\n* [Get a recommendation](/about-your-website/)\\n* [Request a demo](/plans/enterprise/demo/)\\n* [Contact sales](/plans/enterprise/contact/)\\n\\nArtificial intelligence\\n\\n* [What is artificial intelligence (AI)?](/learning/ai/what-is-artificial-intelligence/)\\n* [AI inference vs. training](/learning/ai/inference-vs-training/)\\n* [History of AI](/learning/ai/history-of-ai/)\\n\\nMachine learning\\n\\n* [What is machine learning?](/learning/ai/what-is-machine-learning/)\\n* [What is deep learning?](/learning/ai/what-is-deep-learning/)\\n* [What is a large language model (LLM)?](/learning/ai/what-is-large-language-model/)\\n* [Low-rank adaptation (LoRA)](/learning/ai/what-is-lora/)\\n* [AI image generation](/learning/ai/ai-image-generation/)\\n\\nBig data\\n\\n* [What are embeddings?](/learning/ai/what-are-embeddings/)\\n* [What is big data?](/learning/ai/big-data/)\\n\\n* [Vector database](/learning/ai/what-is-vector-database/)\\n* [Predictive AI](/learning/ai/what-is-predictive-ai/)\\n* [ChatGPT plugins](/learning/ai/chatgpt-plugins/)\\n* [Neural networks](/learning/ai/what-is-neural-network/)\\n* [What is generative AI?](/learning/ai/what-is-generative-ai/)\\n* [What is natural language processing (NLP)?](/learning/ai/natural-language-processing-nlp/)\\n* [AI hallucinations](/learning/ai/what-are-ai-hallucinations/)\\n* [AI quantization](/learning/ai/what-is-quantization/)\\n* [OWASP Top 10 for LLMs](/learning/ai/owasp-top-10-risks-for-llms/)\\n* [AI data poisoning](/learning/ai/data-poisoning/)\\n* [Retrieval augmented generation (RAG)](/learning/ai/retrieval-augmented-generation-rag/)\\n* [What is agentic AI?](/learning/ai/what-is-agentic-ai/)\\n* [Third wave of AI](/learning/ai/evolution-of-ai/)\\n* [What is vibe coding?](/learning/ai/ai-vibe-coding/)\\n* [Model Context Protocol (MCP)](/learning/ai/what-is-model-context-protocol-mcp/)\\n* [AI for cybersecurity](/learning/ai/ai-for-cybersecurity/)\\n\\nLearning Center\\n\\n* [Security Learning Center](/learning/security/what-is-web-application-security/)\\n* [CDN Learning Center](/learning/cdn/what-is-a-cdn/)\\n* [DDoS Learning Center](/learning/ddos/what-is-a-ddos-attack/)\\n* [DNS Learning Center](/learning/dns/what-is-dns/)\\n* [Performance Learning Center](/learning/performance/why-site-speed-matters/)\\n* [Serverless Learning Center](/learning/serverless/what-is-serverless/)\\n* [SSL Learning Center](/learning/ssl/what-is-ssl/)\\n* [Bots Learning Center](/learning/bots/what-is-a-bot/)\\n* [Cloud Learning Center](/learning/cloud/what-is-the-cloud/)\\n* [Access Management Learning Center](/learning/access-management/what-is-identity-and-access-management/)\\n* [Network Layer Learning Center](/learning/network-layer/what-is-the-network-layer/)\\n* [Privacy Learning Center](/learning/privacy/what-is-data-privacy/)\\n* [Video Streaming Learning Center](/learning/video/what-is-streaming/)\\n* [Email Security Learning Center](/learning/email-security/what-is-email-security/)\\n* [Learning Center Home](/learning/)\\n\\n© 2025 Cloudflare, Inc.[Privacy Policy](/privacypolicy/)[Terms of Use](/website-terms/)[Report Security Issues](/disclosure/)[Trademark](/trademark/)'},\n",
              " {'title': 'Introducing the Model Context Protocol - Anthropic',\n",
              "  'url': 'https://www.anthropic.com/news/model-context-protocol',\n",
              "  'content': 'The Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools. The architecture is straightforward: developers can either expose their data through MCP servers or build AI applications (MCP clients) that connect to these servers.\\n\\nToday, we\\'re introducing three major components of the Model Context Protocol for developers: [...] MCP addresses this challenge. It provides a universal, open standard for connecting AI systems with data sources, replacing fragmented integrations with a single protocol. The result is a simpler, more reliable way to give AI systems access to the data they need.\\n\\nModel Context Protocol [...] \"At Block, open source is more than a development model—it’s the foundation of our work and a commitment to creating technology that drives meaningful change and serves as a public good for all,” said Dhanji R. Prasanna, Chief Technology Officer at Block. “Open technologies like the Model Context Protocol are the bridges that connect AI to real-world applications, ensuring innovation is accessible, transparent, and rooted in collaboration. We are excited to partner on a protocol and use it to',\n",
              "  'score': 0.89997756,\n",
              "  'raw_content': 'Introducing the Model Context Protocol \\\\ Anthropic\\n\\n===============\\n\\n[Skip to main content](https://www.anthropic.com/news/model-context-protocol#main-content)[Skip to footer](https://www.anthropic.com/news/model-context-protocol#footer)\\n\\n[](https://www.anthropic.com/)\\n\\n*   Claude\\n*   API\\n*   Solutions\\n*   Research\\n*   Commitments\\n*   Learn\\n[News](https://www.anthropic.com/news)\\n[Try Claude](https://claude.ai/)\\n\\nAnnouncements\\n\\nIntroducing the Model Context Protocol\\n======================================\\n\\nNov 25, 2024●3 min read\\n\\n![Image 1: An abstract illustration of critical context connecting to a central hub](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F3aabd8804251c0364cbde9d2e4be6dc8e8c2faec-2880x1620.png&w=3840&q=75)\\n\\nToday, we\\'re open-sourcing the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), a new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. Its aim is to help frontier models produce better, more relevant responses.\\n\\nAs AI assistants gain mainstream adoption, the industry has invested heavily in model capabilities, achieving rapid advances in reasoning and quality. Yet even the most sophisticated models are constrained by their isolation from data—trapped behind information silos and legacy systems. Every new data source requires its own custom implementation, making truly connected systems difficult to scale.\\n\\nMCP addresses this challenge. It provides a universal, open standard for connecting AI systems with data sources, replacing fragmented integrations with a single protocol. The result is a simpler, more reliable way to give AI systems access to the data they need.\\n\\nModel Context Protocol\\n----------------------\\n\\nThe Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools. The architecture is straightforward: developers can either expose their data through MCP servers or build AI applications (MCP clients) that connect to these servers.\\n\\nToday, we\\'re introducing three major components of the Model Context Protocol for developers:\\n\\n*   The Model Context Protocol [specification and SDKs](https://github.com/modelcontextprotocol)\\n*   Local MCP server support in the [Claude Desktop apps](https://claude.ai/redirect/website.v1.066fab79-34d3-40c7-9190-377a5f18a467/download)\\n*   An [open-source repository](https://github.com/modelcontextprotocol/servers) of MCP servers\\n\\nClaude 3.5 Sonnet is adept at quickly building MCP server implementations, making it easy for organizations and individuals to rapidly connect their most important datasets with a range of AI-powered tools. To help developers start exploring, we’re sharing pre-built MCP servers for popular enterprise systems like Google Drive, Slack, GitHub, Git, Postgres, and Puppeteer.\\n\\nEarly adopters like Block and Apollo have integrated MCP into their systems, while development tools companies including Zed, Replit, Codeium, and Sourcegraph are working with MCP to enhance their platforms—enabling AI agents to better retrieve relevant information to further understand the context around a coding task and produce more nuanced and functional code with fewer attempts.\\n\\n\"At Block, open source is more than a development model—it’s the foundation of our work and a commitment to creating technology that drives meaningful change and serves as a public good for all,” said Dhanji R. Prasanna, Chief Technology Officer at Block. “Open technologies like the Model Context Protocol are the bridges that connect AI to real-world applications, ensuring innovation is accessible, transparent, and rooted in collaboration. We are excited to partner on a protocol and use it to build agentic systems, which remove the burden of the mechanical so people can focus on the creative.”\\n\\nInstead of maintaining separate connectors for each data source, developers can now build against a standard protocol. As the ecosystem matures, AI systems will maintain context as they move between different tools and datasets, replacing today\\'s fragmented integrations with a more sustainable architecture.\\n\\nGetting started\\n---------------\\n\\nDevelopers can start building and testing MCP connectors today. All [Claude.ai](http://claude.ai/redirect/website.v1.066fab79-34d3-40c7-9190-377a5f18a467) plans support connecting MCP servers to the Claude Desktop app.\\n\\nClaude for Work customers can begin testing MCP servers locally, connecting Claude to internal systems and datasets. We\\'ll soon provide developer toolkits for deploying remote production MCP servers that can serve your entire Claude for Work organization.\\n\\nTo start building:\\n\\n*   Install pre-built MCP servers through the [Claude Desktop app](https://claude.ai/redirect/website.v1.066fab79-34d3-40c7-9190-377a5f18a467/download)\\n*   Follow our [quickstart guide](https://modelcontextprotocol.io/quickstart) to build your first MCP server\\n*   Contribute to our [open-source repositories](https://github.com/modelcontextprotocol) of connectors and implementations\\n\\nAn open community\\n-----------------\\n\\nWe’re committed to building MCP as a collaborative, open-source project and ecosystem, and we’re eager to hear your feedback. Whether you’re an AI tool developer, an enterprise looking to leverage existing data, or an early adopter exploring the frontier, we invite you to build the future of context-aware AI together.\\n\\n[](https://twitter.com/intent/tweet?text=https://www.anthropic.com/news/model-context-protocol)[](https://www.linkedin.com/shareArticle?mini=true&url=https://www.anthropic.com/news/model-context-protocol)\\n\\n[News ### Strengthening our safeguards through collaboration with US CAISI and UK AISI Sep 12, 2025](https://www.anthropic.com/news/strengthening-our-safeguards-through-collaboration-with-us-caisi-and-uk-aisi)[News ### Bringing memory to teams at work Sep 11, 2025](https://www.anthropic.com/news/memory)[News ### Claude can now create and edit files Sep 09, 2025](https://www.anthropic.com/news/create-files)\\n\\n[](https://www.anthropic.com/)\\n\\n### Product\\n\\n*   [Claude overview](https://www.anthropic.com/claude)\\n*   [Claude Code](https://www.anthropic.com/claude-code)\\n*   [Max plan](https://www.anthropic.com/max)\\n*   [Team plan](https://www.anthropic.com/team)\\n*   [Enterprise plan](https://www.anthropic.com/enterprise)\\n*   [Download Claude apps](https://claude.ai/download)\\n*   [Claude.ai pricing plans](https://www.anthropic.com/pricing)\\n*   [Claude.ai login](http://claude.ai/login)\\n\\n### API Platform\\n\\n*   [API overview](https://www.anthropic.com/api)\\n*   [Developer docs](https://docs.anthropic.com/)\\n*   [Claude in Amazon Bedrock](https://www.anthropic.com/amazon-bedrock)\\n*   [Claude on Google Cloud\\'s Vertex AI](https://www.anthropic.com/google-cloud-vertex-ai)\\n*   [Pricing](https://www.anthropic.com/pricing#api)\\n*   [Console login](https://console.anthropic.com/)\\n\\n### Research\\n\\n*   [Research overview](https://www.anthropic.com/research)\\n*   [Economic Index](https://www.anthropic.com/economic-index)\\n\\n### Claude models\\n\\n*   [Claude Opus 4.1](https://www.anthropic.com/claude/opus)\\n*   [Claude Sonnet 4](https://www.anthropic.com/claude/sonnet)\\n*   [Claude Haiku 3.5](https://www.anthropic.com/claude/haiku)\\n\\n### Commitments\\n\\n*   [Transparency](https://www.anthropic.com/transparency)\\n*   [Responsible scaling policy](https://www.anthropic.com/responsible-scaling-policy)\\n*   [Security and compliance](https://trust.anthropic.com/)\\n\\n### Solutions\\n\\n*   [AI agents](https://www.anthropic.com/solutions/agents)\\n*   [Coding](https://www.anthropic.com/solutions/coding)\\n*   [Code modernization](https://www.anthropic.com/solutions/code-modernization)\\n*   [Customer support](https://www.anthropic.com/solutions/customer-support)\\n*   [Education](https://www.anthropic.com/solutions/education)\\n*   [Financial services](https://www.anthropic.com/solutions/financial-services)\\n*   [Government](https://www.anthropic.com/solutions/government)\\n\\n### Learn\\n\\n*   [Anthropic Academy](https://www.anthropic.com/learn)\\n*   [Customer stories](https://www.anthropic.com/customers)\\n*   [Engineering at Anthropic](https://www.anthropic.com/engineering)\\n*   [MCP Integrations](https://www.anthropic.com/partners/mcp)\\n*   [Partner Directory](https://www.anthropic.com/partners/powered-by-claude)\\n\\n### Explore\\n\\n*   [About us](https://www.anthropic.com/company)\\n*   [Careers](https://www.anthropic.com/careers)\\n*   [Events](https://www.anthropic.com/events)\\n*   [News](https://www.anthropic.com/news)\\n*   [Startups program](https://www.anthropic.com/startups)\\n\\n### Help and security\\n\\n*   [Status](https://status.anthropic.com/)\\n*   [Availability](https://www.anthropic.com/supported-countries)\\n*   [Support center](https://support.anthropic.com/)\\n\\n### Terms and policies\\n\\n*   [Privacy policy](https://www.anthropic.com/legal/privacy)\\n*   [Responsible disclosure policy](https://www.anthropic.com/responsible-disclosure-policy)\\n*   [Terms of service - consumer](https://www.anthropic.com/legal/consumer-terms)\\n*   [Terms of service - commercial](https://www.anthropic.com/legal/commercial-terms)\\n*   [Usage policy](https://www.anthropic.com/legal/aup)\\n\\n© 2025 Anthropic PBC\\n*   [](https://www.youtube.com/@anthropic-ai)\\n*   [](https://www.linkedin.com/company/anthropicresearch)\\n*   [](https://x.com/AnthropicAI)\\n'},\n",
              " {'title': 'MCP Explained: The New Standard Connecting AI to Everything',\n",
              "  'url': 'https://medium.com/@elisowski/mcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288',\n",
              "  'content': 'Model Context Protocol (MCP) is an open standard developed by Anthropic, the company behind Claude. While it may sound technical, but the core idea is simple: give AI agents a consistent way to connect with tools, services, and data — no matter where they live or how they’re built.',\n",
              "  'score': 0.8896154,\n",
              "  'raw_content': 'Published Time: 2025-04-15T11:26:04Z\\n\\nMCP Explained: The New Standard Connecting AI to Everything | by Edwin Lisowski | Medium\\n\\n===============\\n\\n[Sitemap](https://medium.com/sitemap/sitemap.xml)\\n\\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F79c5a1c98288&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fmcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\\n\\n[](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\nSign up\\n\\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fmcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n![Image 1](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)\\n\\n![Image 2](https://miro.medium.com/v2/da:true/92cfe795cfd308c048a6fbeb60faaa515aba89f12bee45f1d96fffc6af10f974)![Image 3](https://medium.com/@elisowski/mcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288)\\n\\nWriting is for everyone.[Register for Medium Day](https://events.zoom.us/ev/Av7REBItl8l_9abuYg_Iyhrgx4cwt8FEGYhzPou4dCMBDIhOV8ZQ~AmiyQniI6sZwr3sSvUHXWMpdX5wpciIv0a3EWsjOm0kEgiush-6TTsavY_EhDomBRAK8a2foXpncjXcEQADVKgkbMA?source=---medium_day_banner-----------------------------------------)\\n\\nTop highlight\\n\\nModel Context Protocol | MCP Servers | MCP Ecosystem\\n----------------------------------------------------\\n\\nMCP Explained: The New Standard Connecting AI to Everything\\n===========================================================\\n\\nHow Model Context Protocol is making AI agents actually do things\\n-----------------------------------------------------------------\\n\\n[![Image 4: Edwin Lisowski](https://miro.medium.com/v2/resize:fill:32:32/1*kfhhNvpxp7Xpq_W6Pds0Iw.png)](https://medium.com/@elisowski?source=post_page---byline--79c5a1c98288---------------------------------------)\\n\\n[Edwin Lisowski](https://medium.com/@elisowski?source=post_page---byline--79c5a1c98288---------------------------------------)\\n\\nFollow\\n\\n5 min read\\n\\n·\\n\\nApr 15, 2025\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F79c5a1c98288&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fmcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288&user=Edwin+Lisowski&userId=b030368246cc&source=---header_actions--79c5a1c98288---------------------clap_footer------------------)\\n\\n1.5K\\n\\n27\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79c5a1c98288&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fmcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288&source=---header_actions--79c5a1c98288---------------------bookmark_footer------------------)\\n\\n[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D79c5a1c98288&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fmcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288&source=---header_actions--79c5a1c98288---------------------post_audio_button------------------)\\n\\nShare\\n\\nPress enter or click to view image in full size\\n\\n![Image 5](https://miro.medium.com/v2/resize:fit:700/1*LtZYdQvtDLzN4CwmlHvfFA.png)\\n\\n[https://modelcontextprotocol.io/introduction](https://modelcontextprotocol.io/introduction)\\n\\nAI agents can write code, summarize reports, even chat like humans — but when it’s time to actually _do_ something in the real world, they stall.\\n\\nWhy? Because most tools still need clunky, one-off integrations.\\n\\n**MCP (Model Context Protocol)** changes that. It gives AI agents a simple, standardized way to plug into tools, data, and services — no hacks, no hand-coding.\\n\\nWith MCP, AI goes from _smart… to actually useful._\\n\\nWhat Is MCP, Really?\\n--------------------\\n\\nModel Context Protocol (MCP) is an open standard developed by Anthropic, the company behind Claude. While it may sound technical, but the core idea is simple: give AI agents a consistent way to connect with tools, services, and data — no matter where they live or how they’re built.\\n\\nAs highlighted in [Forbes](https://www.forbes.com/sites/janakirammsv/2024/11/30/why-anthropics-model-context-protocol-is-a-big-step-in-the-evolution-of-ai-agents/), MCP is a big leap forward in how AI agents operate. Instead of just answering questions, agents can now perform useful, multi-step tasks — like retrieving data, summarizing documents, or saving content to a file.\\n\\nBefore MCP, each of those actions required a unique API, custom logic, and developer time to glue it all together.\\n\\nPress enter or click to view image in full size\\n\\n![Image 6](https://miro.medium.com/v2/resize:fit:700/1*H_JLRXU8COGQJ4qTw6m0kw.png)\\n\\nWith MCP, it’s plug-and-play. Agents can send structured requests to any MCP-compatible tool, get results back in real time, and even chain multiple tools together — without needing to know the specifics ahead of time.\\n\\n> In short: **MCP replaces one-off hacks with a unified, real-time protocol built for autonomous agents.**\\n\\nThe Architecture of MCP\\n-----------------------\\n\\nPress enter or click to view image in full size\\n\\n![Image 7](https://miro.medium.com/v2/resize:fit:700/1*LtZYdQvtDLzN4CwmlHvfFA.png)\\n\\nHere is a look at how MCP works under the hood:\\n\\n*   MCP Host (on the left) is the AI-powered app — for example, Claude Desktop, an IDE, or another tool acting as an agent.\\n*   The host connects to multiple MCP Servers, each one exposing a different tool or resource.\\n*   Some servers access local resources (like a file system or database on your computer).\\n*   Others can reach out to remote resources (like APIs or cloud services on the internet).\\n\\n> **All communication between host and servers happens over the standardized MCP Protocol, which ensures compatibility and structured responses.**\\n\\n### MCP Servers\\n\\nAn MCP server is like a smart adapter for a tool or app. It knows how to take a request from an AI (like “Get today’s sales report”) and translate it into the commands that tool understands.\\n\\nFor example:\\n\\n*   A GitHub MCP server might turn “list my open pull requests” into a GitHub API call.\\n*   A File MCP server might take “save this summary as a text file” and write it to your desktop.\\n*   A YouTube MCP server could transcribe video links on demand.\\n\\nMCP servers also:\\n\\n*   Tell the AI what they can do (tool discovery)\\n*   Interpret and run commands\\n*   Format results the AI can understand\\n*   Handle errors and give meaningful feedback\\n\\n### MCP **Clients**\\n\\nOn the other side, an MCP client lives inside the AI assistant or app (like Claude or Cursor). When the AI wants to use a tool, it goes through this client to talk to the matching server.\\n\\nGet Edwin Lisowski’s stories in your inbox\\n------------------------------------------\\n\\nJoin Medium for free to get updates from this writer.\\n\\nSubscribe\\n\\nSubscribe\\n\\nFor example:\\n\\n*   Cursor can use a client to interact with your local development environment.\\n*   Claude might use it to access files or read from a spreadsheet.\\n\\nThe client handles all the back-and-forth — sending requests, receiving results, and passing them to the AI.\\n\\n### **The MCP Protocol**\\n\\nThe MCP protocol is what keeps everything in sync. It defines how the client and server communicate — what the messages look like, how actions are described, and how results are returned.\\n\\nIt’s super flexible:\\n\\n*   Can run locally (e.g., between your AI and your computer’s apps)\\n*   Can run over the internet (e.g., between your AI and an online tool)\\n*   Uses structured formats like JSON so everything stays clean and consistent\\n\\nThanks to this shared protocol, an AI agent can connect with a new tool — even one it’s never seen before — and still understand how to use it.\\n\\n### Services = Real Apps and Data\\n\\nThe last part of the puzzle is the services — the actual tools or data sources the AI wants to use.\\n\\nThese could be:\\n\\n**Local:**files on your device, a folder, an app running locally\\n\\n**Remote:**cloud databases, SaaS tools, web APIs\\n\\nMCP servers are the gateway to these services, handling access securely and reliably.\\n\\n**The MCP Ecosystem Is Taking Off**\\n-----------------------------------\\n\\nMCP is becoming a movement. What started as a developer tool is quickly turning into the backbone of how AI agents connect to the real world.\\n\\nWe’re seeing more tools, more companies, and even entire marketplaces pop up around it. Here’s what’s happening.\\n\\n### Who’s Already Using MCP?\\n\\n➊ Block is using MCP to hook up internal tools and knowledge sources to AI agents.\\n\\n❷ Replit integrated MCP so agents can read and write code across files, terminals, and projects.\\n\\n❸ Apollo is using MCP to let AI pull from structured data sources.\\n\\n❹ Sourcegraph and Codeium are plugging it into dev workflows for smarter code assistance.\\n\\n❺ Microsoft Copilot Studio now supports MCP too — making it easier for non-developers to connect AI to data and tools, no coding required.\\n\\n### Marketplaces Are Here\\n\\nHere are the ones to watch:\\n\\n[mcpmarket.com](https://mcpmarket.com/)— A plug-and-play directory of MCP servers for tools like GitHub, Figma, Notion, Databricks, and more.\\n\\n[mcp.so](https://mcp.so/)— A growing open repo of community-built MCP servers. Discover one. Fork it. Build your own.\\n\\n[Cline’s MCP Marketplace](https://github.com/cline/mcp-marketplace)— A GitHub-powered hub for open-source MCP connectors anyone can use.\\n\\n> **This is the new app store — for AI agents.**\\n\\n### Infra Tools Are Making MCP Even Easier\\n\\nBehind the scenes, a bunch of companies are helping developers build, host, and manage MCP servers with way less effort:\\n\\n**Mintlify**, **Stainless**, **Speakeasy** → auto-generate servers with just a few clicks\\n\\n**Cloudflare**, **Smithery** → make hosting and scaling production-grade servers simple\\n\\n**Toolbase** → handles key management and routing for local-first setups\\n\\nWant to Go Deeper?\\n------------------\\n\\nHere are some great places to explore MCP further:\\n\\n*   [Introducing the Model Context Protocol](https://www.anthropic.com/news/model-context-protocol) by Anthropic\\n*   [Model Context Protocol](https://github.com/modelcontextprotocol) on GitHub\\n\\nIf you’re exploring how to integrate AI agents into your workflows — [Addepto](https://addepto.com/) can support you.\\n\\n[Mcp Protocol](https://medium.com/tag/mcp-protocol?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Mcp Server](https://medium.com/tag/mcp-server?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Model Context Protocol](https://medium.com/tag/model-context-protocol?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Mcp Client](https://medium.com/tag/mcp-client?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Ai Agent](https://medium.com/tag/ai-agent?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F79c5a1c98288&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fmcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288&user=Edwin+Lisowski&userId=b030368246cc&source=---footer_actions--79c5a1c98288---------------------clap_footer------------------)\\n\\n1.5K\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F79c5a1c98288&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fmcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288&user=Edwin+Lisowski&userId=b030368246cc&source=---footer_actions--79c5a1c98288---------------------clap_footer------------------)\\n\\n1.5K\\n\\n27\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79c5a1c98288&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fmcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288&source=---footer_actions--79c5a1c98288---------------------bookmark_footer------------------)\\n\\n[![Image 8: Edwin Lisowski](https://miro.medium.com/v2/resize:fill:48:48/1*kfhhNvpxp7Xpq_W6Pds0Iw.png)](https://medium.com/@elisowski?source=post_page---post_author_info--79c5a1c98288---------------------------------------)\\n\\n[![Image 9: Edwin Lisowski](https://miro.medium.com/v2/resize:fill:64:64/1*kfhhNvpxp7Xpq_W6Pds0Iw.png)](https://medium.com/@elisowski?source=post_page---post_author_info--79c5a1c98288---------------------------------------)\\n\\nFollow\\n\\n[Written by Edwin Lisowski -------------------------](https://medium.com/@elisowski?source=post_page---post_author_info--79c5a1c98288---------------------------------------)\\n\\n[2.2K followers](https://medium.com/@elisowski/followers?source=post_page---post_author_info--79c5a1c98288---------------------------------------)\\n\\n·[47 following](https://medium.com/@elisowski/following?source=post_page---post_author_info--79c5a1c98288---------------------------------------)\\n\\nCo-Founder @Addepto ([https://addepto.com](https://addepto.com/)) | Technology Expert | AI-Driven Knowledge Management for Industrial Engineering: [https://context-clue.com/](https://context-clue.com/)\\n\\nFollow\\n\\nResponses (27)\\n--------------\\n\\n[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--79c5a1c98288---------------------------------------)\\n\\n![Image 10](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)\\n\\nWrite a response\\n\\n[What are your thoughts?](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fmcp-explained-the-new-standard-connecting-ai-to-everything-79c5a1c98288&source=---post_responses--79c5a1c98288---------------------respond_sidebar------------------)\\n\\nCancel\\n\\nRespond\\n\\n[![Image 11: Rajamanickam Antonimuthu](https://miro.medium.com/v2/resize:fill:32:32/1*YZDxlroomsN7YxlTbgai7Q.jpeg)](https://medium.com/@rajamanickamantonimuthu?source=post_page---post_responses--79c5a1c98288----0-----------------------------------)\\n\\n[Rajamanickam Antonimuthu](https://medium.com/@rajamanickamantonimuthu?source=post_page---post_responses--79c5a1c98288----0-----------------------------------)\\n\\n[Apr 19](https://medium.com/@rajamanickamantonimuthu/thanks-for-explaining-mcp-in-an-easy-to-understand-way-1cff451bed0c?source=post_page---post_responses--79c5a1c98288----0-----------------------------------)\\n\\nThanks for explaining MCP in an easy-to-understand way.\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1cff451bed0c&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40rajamanickamantonimuthu%2Fthanks-for-explaining-mcp-in-an-easy-to-understand-way-1cff451bed0c&user=Rajamanickam+Antonimuthu&userId=2114bc7d81c9&source=---post_responses--1cff451bed0c----0-----------------respond_sidebar------------------)\\n\\n39\\n\\n1 reply\\n\\nReply\\n\\n[![Image 12: Ajay Kakade](https://miro.medium.com/v2/resize:fill:32:32/0*szAgyjYrLV59y8Z6.)](https://medium.com/@ajay.kakade?source=post_page---post_responses--79c5a1c98288----1-----------------------------------)\\n\\n[Ajay Kakade](https://medium.com/@ajay.kakade?source=post_page---post_responses--79c5a1c98288----1-----------------------------------)\\n\\n[May 8](https://medium.com/@ajay.kakade/very-good-explanation-thanks-26f24b943b7c?source=post_page---post_responses--79c5a1c98288----1-----------------------------------)\\n\\nVery good explanation . Thanks !\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F26f24b943b7c&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40ajay.kakade%2Fvery-good-explanation-thanks-26f24b943b7c&user=Ajay+Kakade&userId=1b0ccb19f838&source=---post_responses--26f24b943b7c----1-----------------respond_sidebar------------------)\\n\\n18\\n\\nReply\\n\\n[![Image 13: Mohammad Faisal Khatri](https://miro.medium.com/v2/resize:fill:32:32/1*D_xMmUc2WqF2iL_Q_3GIDg.jpeg)](https://medium.com/@iamfaisalkhatri?source=post_page---post_responses--79c5a1c98288----2-----------------------------------)\\n\\n[Mohammad Faisal Khatri her/him](https://medium.com/@iamfaisalkhatri?source=post_page---post_responses--79c5a1c98288----2-----------------------------------)\\n\\n[May 20](https://medium.com/@iamfaisalkhatri/awesome-read-thanks-for-the-explanation-1dce39018783?source=post_page---post_responses--79c5a1c98288----2-----------------------------------)\\n\\nAwesome read.. Thanks for the explanation\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1dce39018783&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40iamfaisalkhatri%2Fawesome-read-thanks-for-the-explanation-1dce39018783&user=Mohammad+Faisal+Khatri&userId=d56167afca7d&source=---post_responses--1dce39018783----2-----------------respond_sidebar------------------)\\n\\n6\\n\\nReply\\n\\nSee all responses\\n\\nMore from Edwin Lisowski\\n------------------------\\n\\n![Image 14: AI Agents vs Agentic AI: What’s the Difference and Why Does It Matter?](https://miro.medium.com/v2/resize:fit:679/format:webp/1*TfAUSCHGXLt9WWFo_lxP8w.png)\\n\\n[![Image 15: Edwin Lisowski](https://miro.medium.com/v2/resize:fill:20:20/1*kfhhNvpxp7Xpq_W6Pds0Iw.png)](https://medium.com/@elisowski?source=post_page---author_recirc--79c5a1c98288----0---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[Edwin Lisowski](https://medium.com/@elisowski?source=post_page---author_recirc--79c5a1c98288----0---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[AI Agents vs Agentic AI: What’s the Difference and Why Does It Matter? ---------------------------------------------------------------------- ### If you’ve been keeping an eye on artificial intelligence (AI) lately, you’ve probably heard the terms AI Agents and Agentic AI thrown…](https://medium.com/@elisowski/ai-agents-vs-agentic-ai-whats-the-difference-and-why-does-it-matter-03159ee8c2b4?source=post_page---author_recirc--79c5a1c98288----0---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\nDec 18, 2024\\n\\n[1.6K 52](https://medium.com/@elisowski/ai-agents-vs-agentic-ai-whats-the-difference-and-why-does-it-matter-03159ee8c2b4?source=post_page---author_recirc--79c5a1c98288----0---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F03159ee8c2b4&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fai-agents-vs-agentic-ai-whats-the-difference-and-why-does-it-matter-03159ee8c2b4&source=---author_recirc--79c5a1c98288----0-----------------bookmark_preview----62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n![Image 16: 7 All-In-One AI Platforms That Let You Talk to Multiple Models](https://miro.medium.com/v2/resize:fit:679/format:webp/1*mwaYWrop3mVHMT0PQH5VoQ.png)\\n\\n[![Image 17: Edwin Lisowski](https://miro.medium.com/v2/resize:fill:20:20/1*kfhhNvpxp7Xpq_W6Pds0Iw.png)](https://medium.com/@elisowski?source=post_page---author_recirc--79c5a1c98288----1---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[Edwin Lisowski](https://medium.com/@elisowski?source=post_page---author_recirc--79c5a1c98288----1---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[7 All-In-One AI Platforms That Let You Talk to Multiple Models -------------------------------------------------------------- ### No need to switch tabs or open five different apps just to compare answers.](https://medium.com/@elisowski/7-all-in-one-ai-platforms-that-let-you-talk-to-multiple-models-612d4890dd95?source=post_page---author_recirc--79c5a1c98288----1---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\nMay 13\\n\\n[154 11](https://medium.com/@elisowski/7-all-in-one-ai-platforms-that-let-you-talk-to-multiple-models-612d4890dd95?source=post_page---author_recirc--79c5a1c98288----1---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F612d4890dd95&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2F7-all-in-one-ai-platforms-that-let-you-talk-to-multiple-models-612d4890dd95&source=---author_recirc--79c5a1c98288----1-----------------bookmark_preview----62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n![Image 18: What Every AI Engineer Should Know About A2A, MCP & ACP](https://miro.medium.com/v2/resize:fit:679/format:webp/1*bWg9FT2_smxDuWwntjFWVg.png)\\n\\n[![Image 19: Dev Stash](https://miro.medium.com/v2/resize:fill:20:20/1*QmI_h1Fp-Zw8-G-zFM6Oxg.png)](https://medium.com/bottutorials?source=post_page---author_recirc--79c5a1c98288----2---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\nIn\\n\\n[Dev Stash](https://medium.com/bottutorials?source=post_page---author_recirc--79c5a1c98288----2---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\nby\\n\\n[Edwin Lisowski](https://medium.com/@elisowski?source=post_page---author_recirc--79c5a1c98288----2---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[What Every AI Engineer Should Know About A2A, MCP & ACP ------------------------------------------------------- ### How today’s top AI protocols help agents talk, think, and work together](https://medium.com/bottutorials/what-every-ai-engineer-should-know-about-a2a-mcp-acp-8335a210a742?source=post_page---author_recirc--79c5a1c98288----2---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\nApr 24\\n\\n[1.7K 35](https://medium.com/bottutorials/what-every-ai-engineer-should-know-about-a2a-mcp-acp-8335a210a742?source=post_page---author_recirc--79c5a1c98288----2---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8335a210a742&operation=register&redirect=https%3A%2F%2Ftutorials.botsfloor.com%2Fwhat-every-ai-engineer-should-know-about-a2a-mcp-acp-8335a210a742&source=---author_recirc--79c5a1c98288----2-----------------bookmark_preview----62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n![Image 20: The Top 20 MCP Servers for Developers (According to Reddit’s Users)](https://miro.medium.com/v2/resize:fit:679/format:webp/1*3UwE0Fln-F9C0kTiPEeU5w.png)\\n\\n[![Image 21: Edwin Lisowski](https://miro.medium.com/v2/resize:fill:20:20/1*kfhhNvpxp7Xpq_W6Pds0Iw.png)](https://medium.com/@elisowski?source=post_page---author_recirc--79c5a1c98288----3---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[Edwin Lisowski](https://medium.com/@elisowski?source=post_page---author_recirc--79c5a1c98288----3---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[The Top 20 MCP Servers for Developers (According to Reddit’s Users) ------------------------------------------------------------------- ### Based on real-world feedback from the ClaudeAI, Cursor, and CLine Reddit communities.](https://medium.com/@elisowski/the-top-20-mcp-servers-for-developers-according-to-reddits-users-bab333886336?source=post_page---author_recirc--79c5a1c98288----3---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\nJun 25\\n\\n[84 1](https://medium.com/@elisowski/the-top-20-mcp-servers-for-developers-according-to-reddits-users-bab333886336?source=post_page---author_recirc--79c5a1c98288----3---------------------62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbab333886336&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40elisowski%2Fthe-top-20-mcp-servers-for-developers-according-to-reddits-users-bab333886336&source=---author_recirc--79c5a1c98288----3-----------------bookmark_preview----62e0e4d0_713a_4f43_a696_5d0d84fc319c--------------)\\n\\n[See all from Edwin Lisowski](https://medium.com/@elisowski?source=post_page---author_recirc--79c5a1c98288---------------------------------------)\\n\\nRecommended from Medium\\n-----------------------\\n\\n![Image 22: What Every AI Engineer Should Know About A2A, MCP & ACP](https://miro.medium.com/v2/resize:fit:679/format:webp/1*bWg9FT2_smxDuWwntjFWVg.png)\\n\\n[![Image 23: Dev Stash](https://miro.medium.com/v2/resize:fill:20:20/1*QmI_h1Fp-Zw8-G-zFM6Oxg.png)](https://medium.com/bottutorials?source=post_page---read_next_recirc--79c5a1c98288----0---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nIn\\n\\n[Dev Stash](https://medium.com/bottutorials?source=post_page---read_next_recirc--79c5a1c98288----0---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nby\\n\\n[Edwin Lisowski](https://medium.com/@elisowski?source=post_page---read_next_recirc--79c5a1c98288----0---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[What Every AI Engineer Should Know About A2A, MCP & ACP ------------------------------------------------------- ### How today’s top AI protocols help agents talk, think, and work together](https://medium.com/bottutorials/what-every-ai-engineer-should-know-about-a2a-mcp-acp-8335a210a742?source=post_page---read_next_recirc--79c5a1c98288----0---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nApr 24\\n\\n[1.7K 35](https://medium.com/bottutorials/what-every-ai-engineer-should-know-about-a2a-mcp-acp-8335a210a742?source=post_page---read_next_recirc--79c5a1c98288----0---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8335a210a742&operation=register&redirect=https%3A%2F%2Ftutorials.botsfloor.com%2Fwhat-every-ai-engineer-should-know-about-a2a-mcp-acp-8335a210a742&source=---read_next_recirc--79c5a1c98288----0-----------------bookmark_preview----8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n![Image 24: I have built around 300 agents, worked at 5 startups. Here’s what I learnt about AI Agent](https://miro.medium.com/v2/resize:fit:679/format:webp/1*XdhspB1zG5ByRO2NlzIreg.png)\\n\\n[![Image 25: Yashwanth Sai](https://miro.medium.com/v2/resize:fill:20:20/1*jfchJrVkhmPwG3sAlM9DNg.jpeg)](https://medium.com/@theyashwanthsai?source=post_page---read_next_recirc--79c5a1c98288----1---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[Yashwanth Sai](https://medium.com/@theyashwanthsai?source=post_page---read_next_recirc--79c5a1c98288----1---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[I have built around 300 agents, worked at 5 startups. Here’s what I learnt about AI Agent ----------------------------------------------------------------------------------------- ### Lessons learnt after working with agents for over an year.](https://medium.com/@theyashwanthsai/i-have-built-around-300-agents-worked-at-5-startups-heres-what-i-learnt-about-ai-agent-e911ffa62682?source=post_page---read_next_recirc--79c5a1c98288----1---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nAug 24\\n\\n[2.7K 87](https://medium.com/@theyashwanthsai/i-have-built-around-300-agents-worked-at-5-startups-heres-what-i-learnt-about-ai-agent-e911ffa62682?source=post_page---read_next_recirc--79c5a1c98288----1---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe911ffa62682&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40theyashwanthsai%2Fi-have-built-around-300-agents-worked-at-5-startups-heres-what-i-learnt-about-ai-agent-e911ffa62682&source=---read_next_recirc--79c5a1c98288----1-----------------bookmark_preview----8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n![Image 26: Stop watching random AI courses: Complete Guide to AI Engineering](https://miro.medium.com/v2/resize:fit:679/format:webp/1*nOWJfXZbZ66I6eVreOB_tw.png)\\n\\n[![Image 27: Android Alchemy](https://miro.medium.com/v2/resize:fill:20:20/1*cCoqn0GfI9adlVj-aPGeAQ.png)](https://medium.com/android-alchemy?source=post_page---read_next_recirc--79c5a1c98288----0---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nIn\\n\\n[Android Alchemy](https://medium.com/android-alchemy?source=post_page---read_next_recirc--79c5a1c98288----0---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nby\\n\\n[Prakash Sharma](https://medium.com/@trricho?source=post_page---read_next_recirc--79c5a1c98288----0---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[Stop watching random AI courses: Complete Guide to AI Engineering ----------------------------------------------------------------- ### Ultimate guide for AI Engineering preparation, Six months preparation guide —](https://medium.com/android-alchemy/stop-watching-random-ai-courses-complete-guide-to-ai-engineering-919e3d05f970?source=post_page---read_next_recirc--79c5a1c98288----0---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nJul 30\\n\\n[829 20](https://medium.com/android-alchemy/stop-watching-random-ai-courses-complete-guide-to-ai-engineering-919e3d05f970?source=post_page---read_next_recirc--79c5a1c98288----0---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F919e3d05f970&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fandroid-alchemy%2Fstop-watching-random-ai-courses-complete-guide-to-ai-engineering-919e3d05f970&source=---read_next_recirc--79c5a1c98288----0-----------------bookmark_preview----8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n![Image 28: Agentic AI: Comparing New Open-Source Frameworks](https://miro.medium.com/v2/resize:fit:679/format:webp/1*tS-ZNc1-EjLz92wTw5y_lg.jpeg)\\n\\n[![Image 29: Data Science Collective](https://miro.medium.com/v2/resize:fill:20:20/1*0nV0Q-FBHj94Kggq00pG2Q.jpeg)](https://medium.com/data-science-collective?source=post_page---read_next_recirc--79c5a1c98288----1---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nIn\\n\\n[Data Science Collective](https://medium.com/data-science-collective?source=post_page---read_next_recirc--79c5a1c98288----1---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nby\\n\\n[Ida Silfverskiöld](https://medium.com/@ilsilfverskiold?source=post_page---read_next_recirc--79c5a1c98288----1---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[Agentic AI: Comparing New Open-Source Frameworks ------------------------------------------------ ### By looking at functionality and learning curves](https://medium.com/data-science-collective/agentic-ai-comparing-new-open-source-frameworks-21ec676732df?source=post_page---read_next_recirc--79c5a1c98288----1---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nApr 15\\n\\n[2K 66](https://medium.com/data-science-collective/agentic-ai-comparing-new-open-source-frameworks-21ec676732df?source=post_page---read_next_recirc--79c5a1c98288----1---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F21ec676732df&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-collective%2Fagentic-ai-comparing-new-open-source-frameworks-21ec676732df&source=---read_next_recirc--79c5a1c98288----1-----------------bookmark_preview----8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n![Image 30: 6 MCP Servers Every Developer Needs to Try](https://miro.medium.com/v2/resize:fit:679/format:webp/0*slq56o9fxD6IpR8M)\\n\\n[![Image 31: Coding Nexus](https://miro.medium.com/v2/resize:fill:20:20/1*KCZtO6-wFqmTaMmbTMicbw.png)](https://medium.com/coding-nexus?source=post_page---read_next_recirc--79c5a1c98288----2---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nIn\\n\\n[Coding Nexus](https://medium.com/coding-nexus?source=post_page---read_next_recirc--79c5a1c98288----2---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nby\\n\\n[Code Coup](https://medium.com/@CodeCoup?source=post_page---read_next_recirc--79c5a1c98288----2---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[6 MCP Servers Every Developer Needs to Try ------------------------------------------ ### I’ve spent the last two months around with over 100 MCP servers, and let me tell you, some of these are straight-up awesome.](https://medium.com/coding-nexus/6-mcp-servers-every-developer-needs-to-try-622b3e639403?source=post_page---read_next_recirc--79c5a1c98288----2---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nMay 27\\n\\n[2.5K 24](https://medium.com/coding-nexus/6-mcp-servers-every-developer-needs-to-try-622b3e639403?source=post_page---read_next_recirc--79c5a1c98288----2---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F622b3e639403&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoding-nexus%2F6-mcp-servers-every-developer-needs-to-try-622b3e639403&source=---read_next_recirc--79c5a1c98288----2-----------------bookmark_preview----8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n![Image 32: I’ll Instantly Know You Used Chat Gpt If I See This](https://miro.medium.com/v2/resize:fit:679/format:webp/1*dRtGFgNbdBRFp5DOOWB2sw@2x.jpeg)\\n\\n[![Image 33: Long. Sweet. Valuable.](https://miro.medium.com/v2/resize:fill:20:20/1*8-CMNGG1bFXJByHYeDNKvw.jpeg)](https://medium.com/long-sweet-valuable?source=post_page---read_next_recirc--79c5a1c98288----3---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nIn\\n\\n[Long. Sweet. Valuable.](https://medium.com/long-sweet-valuable?source=post_page---read_next_recirc--79c5a1c98288----3---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nby\\n\\n[Ossai Chinedum](https://medium.com/@ossaichinedum?source=post_page---read_next_recirc--79c5a1c98288----3---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[I’ll Instantly Know You Used Chat Gpt If I See This --------------------------------------------------- ### Trust me you’re not as slick as you think](https://medium.com/long-sweet-valuable/ill-instantly-know-you-used-chat-gpt-if-i-see-this-d0a635bc0a00?source=post_page---read_next_recirc--79c5a1c98288----3---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\nMay 16\\n\\n[22K 1351](https://medium.com/long-sweet-valuable/ill-instantly-know-you-used-chat-gpt-if-i-see-this-d0a635bc0a00?source=post_page---read_next_recirc--79c5a1c98288----3---------------------8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd0a635bc0a00&operation=register&redirect=https%3A%2F%2Flong.sweet.pub%2Fill-instantly-know-you-used-chat-gpt-if-i-see-this-d0a635bc0a00&source=---read_next_recirc--79c5a1c98288----3-----------------bookmark_preview----8e002a0c_18ca_46b0_9d88_c1813882dc98--------------)\\n\\n[See more recommendations](https://medium.com/?source=post_page---read_next_recirc--79c5a1c98288---------------------------------------)\\n\\n[Help](https://help.medium.com/hc/en-us?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Status](https://status.medium.com/?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[About](https://medium.com/about?autoplay=1&source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Press](mailto:pressinquiries@medium.com)\\n\\n[Blog](https://blog.medium.com/?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----79c5a1c98288---------------------------------------)\\n\\n[Text to speech](https://speechify.com/medium?source=post_page-----79c5a1c98288---------------------------------------)\\n'},\n",
              " {'title': 'Unlocking the power of Model Context Protocol (MCP) on AWS',\n",
              "  'url': 'https://aws.amazon.com/blogs/machine-learning/unlocking-the-power-of-model-context-protocol-mcp-on-aws/',\n",
              "  'content': 'As we’ve explored throughout this post, the Model Context Protocol provides a powerful framework for connecting language models to your enterprise data and tools on AWS. But this is just the beginning of the journey.\\n\\nThe MCP landscape is rapidly evolving, with new capabilities and implementations emerging regularly. In future posts in this series, we’ll dive deeper into advanced MCP architectures and use cases, with a particular focus on remote MCP implementation. [...] As language models continue to transform how we interact with technology, the ability to connect these models to enterprise data and systems becomes increasingly critical. The Model Context Protocol (MCP) offers a standardized, secure, and scalable approach to integration.\\n\\nThrough MCP, AWS customers can:',\n",
              "  'score': 0.85008353,\n",
              "  'raw_content': '## Select your cookie preferences\\n\\nWe use essential cookies and similar tools that are necessary to provide our site and services. We use performance cookies to collect anonymous statistics, so we can understand how customers use our site and make improvements. Essential cookies cannot be deactivated, but you can choose “Customize” or “Decline” to decline performance cookies.   \\n  \\n If you agree, AWS and approved third parties will also use cookies to provide useful site features, remember your preferences, and display relevant content, including relevant advertising. To accept or decline all non-essential cookies, choose “Accept” or “Decline.” To make more detailed choices, choose “Customize.”\\n\\nWe use cookies and similar tools (collectively, \"cookies\") for the following purposes.\\n\\n### Essential\\n\\nEssential cookies are necessary to provide our site and services and cannot be deactivated. They are usually set in response to your actions on the site, such as setting your privacy preferences, signing in, or filling in forms.\\n\\n### Performance\\n\\nPerformance cookies provide anonymous statistics about how customers navigate our site so we can improve site experience and performance. Approved third parties may perform analytics on our behalf, but they cannot use the data for their own purposes.\\n\\n### Functional\\n\\nFunctional cookies help us provide useful site features, remember your preferences, and display relevant content. Approved third parties may set these cookies to provide certain site features. If you do not allow these cookies, then some or all of these services may not function properly.\\n\\nAllowed\\n\\n### Advertising\\n\\nAdvertising cookies may be set through our site by us or our advertising partners and help us deliver relevant marketing content. If you do not allow these cookies, you will experience less relevant advertising.\\n\\nAllowed\\n\\nBlocking some types of cookies may impact your experience of our sites. You may review and change your choices at any time by selecting Cookie preferences in the footer of this site. We and selected third-parties use cookies or similar technologies as specified in the\\xa0[AWS Cookie Notice](https://aws.amazon.com/legal/cookies/).\\n\\n## Unable to save cookie preferences\\n\\nWe will only store essential cookies at this time, because we were unable to save your cookie preferences.  \\n  \\nIf you want to change your cookie preferences, try again later using the link in the AWS console footer, or contact support if the problem persists.\\n\\n [Skip to Main Content](#aws-page-content-main)\\n\\n\\nAWS Blogs\\n\\n* [Home](https://aws.amazon.com/blogs/)\\n\\n## [Artificial Intelligence](https://aws.amazon.com/blogs/machine-learning/)\\n\\n# Unlocking the power of Model Context Protocol (MCP) on AWS\\n\\nWe’ve witnessed remarkable advances in model capabilities as [generative AI](https://aws.amazon.com/generative-ai/) companies have invested in developing their offerings. Language models such as [Anthropic’s Claude Opus 4 & Sonnet 4](https://aws.amazon.com/bedrock/claude/) and [Amazon Nova](https://aws.amazon.com/ai/generative-ai/nova/) on [Amazon Bedrock](https://aws.amazon.com/bedrock/) can reason, write, and generate responses with increasing sophistication. But even as these models grow more powerful, they can only work with the information available to them.\\n\\nNo matter how impressive a model might be, it’s confined to the data it was trained on or what’s manually provided in its context window. It’s like having the world’s best analyst locked in a room with incomplete files—brilliant, but isolated from your organization’s most current and relevant information.\\n\\nThis isolation creates three critical challenges for enterprises using [generative AI](https://aws.amazon.com/generative-ai/):\\n\\n1. **Information silos** trap valuable data behind custom APIs and proprietary interfaces\\n2. **Integration complexity** requires building and maintaining bespoke connectors and glue code for every data source or tool provided to the language model for every data source\\n3. **Scalability bottlenecks** appear as organizations attempt to connect more models to more systems and tools\\n\\nSound familiar? If you’re an AI-focused developer, technical decision-maker, or solution architect working with [Amazon Web Services](https://aws.amazon.com/) (AWS) and language models, you’ve likely encountered these obstacles firsthand. Let’s explore how the [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) offers a path forward.\\n\\n## What is the MCP?\\n\\nThe MCP is an open standard that creates a universal language for AI systems to communicate with external data sources, tools, and services. Conceptually, MCP functions as a universal translator, enabling seamless dialogue between language models and the diverse systems where your valuable information resides.\\n\\nDeveloped by Anthropic and released as an open source project, MCP addresses a fundamental challenge: how to provide AI models with consistent, secure access to the information they need, when they need it, regardless of where that information lives.\\n\\nAt its core, MCP implements a client-server architecture:\\n\\n* **MCP clients** are AI applications like Anthropic’s Claude Desktop or custom solutions built on Amazon Bedrock that need access to external data\\n* **MCP servers** provide standardized access to specific data sources, whether that’s a GitHub repository, Slack workspace, or AWS service\\n* **Communication flow** between clients and servers follows a well-defined protocol that can run locally or remotely\\n\\nThis architecture supports three essential primitives that form the foundation of MCP:\\n\\n1. **Tools** – Functions that models can call to retrieve information or perform actions\\n2. **Resources** – Data that can be included in the model’s context such as database records, images, or file contents\\n3. **Prompts** – Templates that guide how models interact with specific tools or resources\\n\\nWhat makes MCP especially powerful is its ability to work across both local and remote implementations. You can run MCP servers directly on your development machine for testing or deploy them as distributed services across your AWS infrastructure for enterprise-scale applications.\\n\\n## Solving the M×N integration problem\\n\\nBefore diving deeper into the AWS specific implementation details, it’s worth understanding the fundamental integration challenge MCP solves.\\n\\nImagine you’re building AI applications that need to access multiple data sources in your organization. Without a standardized protocol, you face what we call the “M×N problem”: for M different AI applications connecting to N different data sources, you need to build and maintain M×N custom integrations.\\n\\nThis creates an integration matrix that quickly becomes unmanageable as your organization adds more AI applications and data sources. Each new system requires multiple custom integrations, with development teams duplicating efforts across projects. MCP transforms this M×N problem into a simpler M+N equation: with MCP, you build M clients and N servers, requiring only M+N implementations. These solutions to the MCP problem are shown in the following diagram.\\n\\nThis approach draws inspiration from other successful protocols that solved similar challenges:\\n\\n* **APIs** standardized how web applications interact with the backend\\n* **Language Server Protocol (LSP)** standardizes how [integrated development environments](https://aws.amazon.com/what-is/ide/) (IDEs) interact with language-specific tools for coding\\n\\nIn the same way that these protocols revolutionized their domains, MCP is poised to transform how AI applications interact with the diverse landscape of data sources in modern enterprises.\\n\\n## Why MCP matters for AWS users\\n\\nFor AWS customers, MCP represents a particularly compelling opportunity. AWS offers hundreds of services, each with its own APIs and data formats. By adopting MCP as a standardized protocol for AI interactions, you can:\\n\\n1. **Streamline integration** between Amazon Bedrock language models and AWS data services\\n2. **Use existing AWS security mechanisms** such as [AWS Identity and Access Management](https://aws.amazon.com/iam/) (IAM) for consistent access control\\n3. **Build composable, scalable AI solutions** that align with AWS architectural best practices\\n\\n## MCP and the AWS service landscape\\n\\nWhat makes MCP particularly powerful in the AWS context is how it can interface with the broader AWS service landscape. Imagine AI applications that can seamlessly access information from:\\n\\n* **[Amazon Simple Storage](https://aws.amazon.com/s3/) (Amazon S3) buckets** containing documents, images, and unstructured data\\n* **[Amazon DynamoDB](https://aws.amazon.com/dynamodb/) tables** storing structured business information\\n* **[Amazon Relational Database Service](https://aws.amazon.com/rds/) (Amazon RDS) databases** with historical transaction records\\n* **[Amazon CloudWatch](https://aws.amazon.com/cloudwatch/) logs** for operational intelligence\\n* **[Amazon Bedrock Knowledge Bases](https://aws.amazon.com/bedrock/knowledge-bases/)** for semantic search capabilities\\n\\nMCP servers act as consistent interfaces to these diverse data sources, providing language models with a unified access pattern regardless of the underlying AWS service architecture. This alleviates the need for custom integration code for each service and enables AI systems to work with your AWS resources in a way that respects your existing security boundaries and access controls.\\n\\nIn the remaining sections of this post, we explore how MCP works with AWS services, examine specific implementation examples, and provide guidance for technical decision-makers considering adopt MCP in their organizations.\\n\\n## How MCP works with AWS services, particularly Amazon Bedrock\\n\\nNow that we’ve shown the fundamental value proposition of MCP, we dive into how it integrates with AWS services, with a special focus on Amazon Bedrock. This integration creates a powerful foundation for building context-aware AI applications that can securely access your organization’s data and tools.\\n\\n### Amazon Bedrock and language models\\n\\nAmazon Bedrock represents the strategic commitment by AWS to make [foundation models](https://aws.amazon.com/what-is/foundation-models/) (FMs) accessible, secure, and enterprise-ready. It’s a fully managed service that provides a unified API across multiple leading language models, including:\\n\\n* Anthropic’s Claude\\n* Meta’s Llama\\n* Amazon Titan and Amazon Nova\\n\\nWhat makes Amazon Bedrock particularly compelling for enterprise deployments is its integration with the broader AWS landscape. You can run FMs with the same security, compliance, and operational tools you already use for your AWS workloads. This includes IAM for access control and CloudWatch for monitoring.\\n\\nAt the heart of the versatility of Amazon Bedrock is the [Converse API](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-call.html)—the interface that enables multiturn conversations with language models. The Converse API includes built-in support for what AWS calls “tool use,” allowing models to:\\n\\n1. Recognize when they need information outside their training data\\n2. Request that information from external systems using well-defined function calls\\n3. Incorporate the returned data into their responses\\n\\nThis tool use capability in the Amazon Bedrock Converse API dovetails perfectly with MCP’s design, creating a natural integration point.\\n\\n### MCP and Amazon Bedrock integration architecture\\n\\nIntegrating MCP with Amazon Bedrock involves creating a bridge between the model’s ability to request information (through the Converse API) and MCP’s standardized protocol for accessing external systems.\\n\\n### Integration flow walkthrough\\n\\nTo help you understand how MCP and Amazon Bedrock work together in practice, we walk through a typical interaction flow, step-by-step:\\n\\n1. The user initiates a query through your application interface:\\n\\n`\"What were our Q1 sales figures for the Northwest region?\"`\\n\\n2. Your application forwards the query to Amazon Bedrock through the Converse API:\\n\\n```\\n   # Initialize the Bedrock runtime client with your AWS credentials\\n   bedrock = boto3.client(service_name=\\'bedrock-runtime\\', region_name=\\'us-east-1\\')\\n   \\n   # Define the query from the user\\n   user_query = \"What were our Q1 sales figures for the Northwest region?\"\\n   \\n   # available_tools contains tool definitions that match MCP server capabilities\\n   # These will be exposed to the model through the Converse API\\n   \\n   # Call the Converse API with the user\\'s query and available tools\\n   response = bedrock.converse(\\n       modelId=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",  # Specify which language model to use\\n       messages=[{\"role\": \"user\", \"content\": [{\"text\": user_query}]}],  # Format the user\\'s message\\n       toolConfig={\"tools\": available_tools}  # Pass the tool definitions to the model\\n   )\\n```\\n\\nPython\\n\\n3. Amazon Bedrock processes the query and determines that it needs financial data that isn’t in its training data\\n4. Amazon Bedrock returns a `toolUse` message, requesting access to a specific tool:\\n\\n```\\n   {\\n     \"role\": \"assistant\",  // Indicates this message is from the model\\n     \"content\": [{\\n       \"toolUse\": {  // The model is requesting to use a tool\\n         \"toolUseId\": \"tu_01234567\",  // Unique identifier for this tool use request\\n         \"name\": \"query_sales_data\",  // Name of the tool the model wants to use\\n         \"input\": {  // Parameters for the tool call\\n           \"quarter\": \"Q1\",  // The model extracted this parameter from the user query\\n           \"region\": \"Northwest\"  // Another parameter extracted from the user query\\n         }\\n       }\\n     }]\\n   }\\n```\\n\\nJSON\\n\\n5. Your MCP client application receives this `toolUse` message and translates it into an MCP protocol  \\n    tool call\\n6. The MCP client routes the request to the appropriate MCP server (in this case, a server connected to your  \\n    financial database)\\n7. The MCP server executes the tool, retrieving the requested data from your systems:\\n\\n```\\n   # Call the tool through the MCP protocol\\n   # session is the MCP client session established earlier\\n   result = await session.call_tool(\\n       \"query_sales_data\",  # The tool name from the toolUse message\\n       {\\n           \"quarter\": \"Q1\",  # Pass through the parameters from the toolUse message\\n           \"region\": \"Northwest\"\\n       }\\n   )\\n   # The MCP server handles authentication, data access, and result formatting\\n   # This abstracts away the complexity of accessing different data sources\\n```\\n\\nPython\\n\\n8. The tool results are returned through the MCP protocol to your client application\\n9. Your application sends the results back to Amazon Bedrock as a `toolResult` message:\\n\\n```\\n   {\\n     \"role\": \"user\",  // This is sent as if from the user, but contains tool results\\n     \"content\": [{\\n       \"toolResult\": {  // Indicates this is a result from a tool\\n         \"toolUseId\": \"tu_01234567\",  // Must match the ID from the original toolUse\\n         \"content\": [{\\n           \"json\": {  // Results are formatted as JSON\\n             \"total_sales\": 12450000,  // Numerical data accessible to the model\\n             \"growth\": 0.12,  // Percentage growth for analysis\\n             \"top_products\": [\"Product A\", \"Product B\", \"Product C\"]  // List data\\n           }\\n         }]\\n       }\\n     }]\\n   }\\n```\\n\\nJSON\\n\\n10. Amazon Bedrock generates a final response incorporating the tool results:\\n\\n```\\n“Based on the data I\\'ve retrieved, our Q1 sales figures for the Northwest region were $12.45 million, \\nrepresenting a 12% growth compared to the previous quarter. \\nThe top-performing products were Product A, Product B, and Product C.”\\n```\\n\\nCode\\n\\n11. Your application returns the final response to the user\\n\\nThis entire process, illustrated in the following diagram, happens in seconds, giving users the impression of a seamless conversation with an AI that has direct access to their organization’s data. Behind the scenes, MCP is handling the complex work of securely routing requests to the right tools and data sources.\\n\\nIn the next section, we explore a practical implementation example that shows how to connect an MCP server to Amazon Bedrock Knowledge Bases, providing a blueprint for your own implementations.\\n\\n## Practical implementation example: Amazon Bedrock Knowledge Bases integration\\n\\nAs you might recall from our earlier discussion of strategic use cases, enterprise knowledge bases represent one of the most valuable applications of MCP on AWS. Now, we explore a concrete implementation of MCP that connects language models to Amazon Bedrock Knowledge Bases. The code for the MCP server can be found in the [AWS Labs MCP code repository](https://github.com/awslabs/mcp/blob/main/src/bedrock-kb-retrieval-mcp-server/awslabs/bedrock_kb_retrieval_mcp_server/server.py) and for the client in the same [AWS Labs MCP samples directory](https://github.com/awslabs/mcp/tree/main/samples/mcp-integration-with-kb) on GitHub. This example brings to life the “universal translator” concept we introduced earlier, demonstrating how MCP can transform the way AI systems interact with enterprise knowledge repositories.\\n\\n### Understanding the challenge\\n\\nEnterprise knowledge bases contain vast repositories of information—from documentation and policies to technical guides and product specifications. Traditional search approaches are often inadequate when users ask natural language questions, failing to understand context or identify the most relevant content.\\n\\nAmazon Bedrock Knowledge Bases provide vector search capabilities that improve upon traditional keyword search, but even this approach has limitations:\\n\\n1. **Manual filter configuration** requires predefined knowledge of metadata structures\\n2. **Query-result mismatch** occurs when users don’t use the exact terminology in the knowledge base\\n3. **Relevance challenges** arise when similar documents compete for attention\\n4. **Context switching** between searching and reasoning disrupts user experience\\n\\nThe MCP server we explore addresses these challenges by creating an intelligent layer between language models and knowledge bases.\\n\\n### Architecture overview\\n\\nAt a high level, our MCP server for Amazon Bedrock Knowledge Bases follows a clean, well-organized architecture that builds upon the client-server pattern we outlined previously. The server exposes two key interfaces to language models:\\n\\n1. A knowledge bases resource that provides discovery capabilities for available knowledge bases\\n2. A query tool that enables dynamic searching across these knowledge bases\\n\\nRemember the M×N integration problem we discussed earlier? This implementation provides a tangible example of how MCP solves it – creating a standardized interface between a large language model and your Amazon Bedrock Knowledge Base repositories.\\n\\n#### Knowledge base discovery resource\\n\\nThe server begins with a resource that enables language models to discover available knowledge bases:\\n\\n```\\n@mcp.resource(uri=\\'resource://knowledgebases\\', name=\\'KnowledgeBases\\', mime_type=\\'application/json\\')\\nasync def knowledgebases_resource() -> str:\\n    \"\"\"List all available Amazon Bedrock Knowledge Bases and their data sources.\\n \\n    This resource returns a mapping of knowledge base IDs to their details, including:\\n    - name: The human-readable name of the knowledge base\\n    - data_sources: A list of data sources within the knowledge base, each with:\\n      - id: The unique identifier of the data source\\n      - name: The human-readable name of the data source\\n \\n    ## Example response structure:\\n    ```json\\n    {\\n        \"kb-12345\": {\\n            \"name\": \"Customer Support KB\",\\n            \"data_sources\": [\\n                {\"id\": \"ds-abc123\", \"name\": \"Technical Documentation\"},\\n                {\"id\": \"ds-def456\", \"name\": \"FAQs\"}\\n            ]\\n        },\\n        \"kb-67890\": {\\n            \"name\": \"Product Information KB\",\\n            \"data_sources\": [\\n                {\"id\": \"ds-ghi789\", \"name\": \"Product Specifications\"}\\n            ]\\n        }\\n    }\\n    ```\\n \\n    ## How to use this information:\\n    1. Extract the knowledge base IDs (like \"kb-12345\") for use with the QueryKnowledgeBases tool\\n    2. Note the data source IDs if you want to filter queries to specific data sources\\n    3. Use the names to determine which knowledge base and data source(s) are most relevant to the user\\'s query\\n    \"\"\"\\n    return json.dumps(await discover_knowledge_bases(kb_agent_mgmt_client, kb_inclusion_tag_key)) \\n```\\n\\nPython\\n\\nThis resource serves as both documentation and a discovery mechanism that language models can use to identify available knowledge bases before querying them.\\n\\n#### Querying knowledge bases with the MCP tool\\n\\nThe core functionality of this MCP server resides in its `QueryKnowledgeBases` tool:\\n\\n```\\n@mcp.tool(name=\\'QueryKnowledgeBases\\')\\nasync def query_knowledge_bases_tool(\\n    query: str = Field(\\n        ..., description=\\'A natural language query to search the knowledge base with\\'\\n    ),\\n    knowledge_base_id: str = Field(\\n        ...,\\n        description=\\'The knowledge base ID to query. It must be a valid ID from the resource://knowledgebases MCP resource\\',\\n    ),\\n    number_of_results: int = Field(\\n        10,\\n        description=\\'The number of results to return. Use smaller values for focused results and larger values for broader coverage.\\',\\n    ),\\n    reranking: bool = Field(\\n        kb_reranking_enabled,\\n        description=\\'Whether to rerank the results. Useful for improving relevance and sorting. Can be globally configured with BEDROCK_KB_RERANKING_ENABLED environment variable.\\',\\n    ),\\n    reranking_model_name: Literal[\\'COHERE\\', \\'AMAZON\\'] = Field(\\n        \\'AMAZON\\',\\n        description=\"The name of the reranking model to use. Options: \\'COHERE\\', \\'AMAZON\\'\",\\n    ),\\n    data_source_ids: Optional[List[str]] = Field(\\n        None,\\n        description=\\'The data source IDs to filter the knowledge base by. It must be a list of valid data source IDs from the resource://knowledgebases MCP resource\\',\\n    ),\\n) -> str:\\n    \"\"\"Query an Amazon Bedrock Knowledge Base using natural language.\\n \\n    ## Usage Requirements\\n    - You MUST first use the `resource://knowledgebases` resource to get valid knowledge base IDs\\n    - You can query different knowledge bases or make multiple queries to the same knowledge base\\n \\n    ## Query Tips\\n    - Use clear, specific natural language queries for best results\\n    - You can use this tool MULTIPLE TIMES with different queries to gather comprehensive information\\n    - Break complex questions into multiple focused queries\\n    - Consider querying for factual information and explanations separately\\n     \"\"\"\\n## Additional Implementation details …\\n```\\n\\nPython\\n\\nWhat makes this tool powerful is its flexibility in querying knowledge bases with natural language. It supports several key features:\\n\\n1. **Configurable result sizes** – Adjust the number of results based on whether you need focused or comprehensive information\\n2. **Optional reranking** – Improve relevance using language models (such as reranking models from Amazon or Cohere)\\n3. **Data source filtering** – Target specific sections of the knowledge base when needed\\n\\nReranking is disabled by default in this implementation but can be quickly enabled through environment variables or direct parameter configuration.\\n\\n### Enhanced relevance with reranking\\n\\nA notable feature of this implementation is the ability to rerank search results using language models available through Amazon Bedrock. This capability allows the system to rescore search results based on deeper semantic understanding:\\n\\n```\\n# Parse reranking enabled environment variable\\nkb_reranking_enabled_raw = os.getenv(\\'BEDROCK_KB_RERANKING_ENABLED\\')\\nkb_reranking_enabled = False  # Default value is now False (off)\\nif kb_reranking_enabled_raw is not None:\\n    kb_reranking_enabled_raw = kb_reranking_enabled_raw.strip().lower()\\n    if kb_reranking_enabled_raw in (\\'true\\', \\'1\\', \\'yes\\', \\'on\\'):\\n        kb_reranking_enabled = True\\n```\\n\\nPython\\n\\nReranking is particularly valuable for queries where semantic similarity might not be enough to determine the  \\n most relevant content. For example, when answering a specific question, the most relevant document isn’t necessarily  \\n the one with the most keyword matches, but the one that directly addresses the question being asked.\\n\\n### Full interaction flow\\n\\nThis section walks through a complete interaction flow to show how all these components work  \\n together:\\n\\n1. The user asks a question to a language model such as Anthropic’s Claude through an application:\\n\\n```\\n   \"What\\'s our quarterly IT security audit procedure?\"\\n```\\n\\nCode\\n\\n2. The language model recognizes it needs to access the knowledge base and calls the MCP tool:\\n\\n```\\n{\\n  \"toolUse\": {\\n    \"name\": \"QueryKnowledgeBases\",\\n    \"input\": {\\n      \"query\": \"What\\'s our quarterly IT security audit procedure?\",\\n      \"knowledge_base_id\": \"kb-12345abcde\",\\n      \"reranking\": true\\n    }\\n  }\\n} \\n```\\n\\nJSON\\n\\n3. The MCP server processes the request by querying the knowledge base with the specified parameters\\n4. The MCP server returns formatted results to the language model, including content, location, and relevance scores:\\n\\n```\\nApplied metadata filters: department=IT, document_type=Procedure, category=Security Audit, frequency=Quarterly\\n \\n   Results have been reranked to improve relevance.\\n \\n   Result 1 [Score: 0.92]:\\n   Source: S3 - s3://company-docs/procedures/it/security/quarterly-audit-procedure-v2.pdf\\n   Content: The IT Security Quarterly Audit Procedure outlines the steps for conducting systematic evaluations of the organization\\'s information security controls. This document provides guidance on scope, methodology, reporting requirements, and remediation tracking...\\n   Metadata:\\n     • department: IT\\n     • document_type: Procedure\\n     • category: Security Audit\\n     • frequency: Quarterly\\n     • last_updated: 2024-11-15\\n```\\n\\nCode\\n\\n5. The language model incorporates these results into its response to the user:\\n\\n```\\n   Based on our IT Security Quarterly Audit Procedure, the process involves four main phases:\\n \\n   1. Planning: Define scope, objectives, and schedule for the audit\\n   2. Execution: Conduct the technical assessments and control evaluations\\n   3. Reporting: Document findings, risks, and recommendations\\n   4. Remediation: Track and verify resolution of identified issues\\n \\n   The procedure was last updated on November 15, 2024, and specifies that the Cybersecurity team leads the effort with support from IT Operations.\\n```\\n\\nCode\\n\\nThis interaction, illustrated in the following diagram, demonstrates the seamless fusion of language model capabilities with enterprise knowledge, enabled by the MCP protocol. The user doesn’t need to specify complex search parameters or know the structure of the knowledge base—the integration layer handles these details automatically.\\n\\n## Looking ahead: The MCP journey continues\\n\\nAs we’ve explored throughout this post, the Model Context Protocol provides a powerful framework for connecting language models to your enterprise data and tools on AWS. But this is just the beginning of the journey.\\n\\nThe MCP landscape is rapidly evolving, with new capabilities and implementations emerging regularly. In future posts in this series, we’ll dive deeper into advanced MCP architectures and use cases, with a particular focus on remote MCP implementation.\\n\\nThe introduction of the new [Streamable HTTP transport layer](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#streamable-http) represents a significant advancement for MCP, enabling truly enterprise-scale deployments with features such as:\\n\\n* Stateless server options for simplified scaling\\n* Session ID management for request routing\\n* Robust authentication and authorization mechanisms for secure access control\\n* Horizontal scaling across server nodes\\n* Enhanced resilience and fault tolerance\\n\\nThese capabilities will be essential as organizations move from proof-of-concept implementations to production-grade MCP deployments that serve multiple teams and use cases.\\n\\nWe invite you to follow this blog post series as we continue to explore how MCP and AWS services can work together to create more powerful, context-aware AI applications for your organization.\\n\\n## Conclusion\\n\\nAs language models continue to transform how we interact with technology, the ability to connect these models to enterprise data and systems becomes increasingly critical. The Model Context Protocol (MCP) offers a standardized, secure, and scalable approach to integration.\\n\\nThrough MCP, AWS customers can:\\n\\n* Establish a standardized protocol for AI-data connections\\n* Reduce development overhead and maintenance costs\\n* Enforce consistent security and governance policies\\n* Create more powerful, context-aware AI experiences\\n\\nThe Amazon Bedrock Knowledge Bases implementation we explored demonstrates how MCP can transform simple retrieval into intelligent discovery, adding value far beyond what either component could deliver independently.\\n\\n## Getting started\\n\\nReady to begin your MCP journey on AWS? Here are some resources to help you get started:\\n\\n**Learning resources:**\\n\\n* [AWS Labs MCP client and server code repository](https://github.com/awslabs/mcp/tree/main)\\n* [Model Context Protocol documentation](https://modelcontextprotocol.io/)\\n* [Amazon Bedrock Developer Guide](https://docs.aws.amazon.com/bedrock/)\\n* [MCP servers repository](https://github.com/modelcontextprotocol/servers)\\n\\n**Implementation steps:**\\n\\n1. Identify a high-value use case where AI needs access to enterprise data\\n2. Select the appropriate MCP servers for your data sources\\n3. Set up a development environment with local MCP implementations\\n4. Integrate with Amazon Bedrock using the patterns described in this post\\n5. Deploy to production with appropriate security and scaling considerations\\n\\nRemember that MCP offers a “start small, scale incrementally” approach. You can begin with a single server connecting to one data source, then expand your implementation as you validate the value and establish patterns for your organization.\\n\\nWe encourage you to try the MCP with AWS services today. Start with a simple implementation, perhaps connecting a language model to your documentation or code repositories, and experience firsthand the power of context-aware AI.\\n\\nShare your experiences, challenges, and successes with the community. The open source nature of MCP means that your contributions—whether code, use cases, or feedback—can help shape the future of this important protocol.\\n\\nIn a world where AI capabilities are advancing rapidly, the difference between good and great implementations often comes down to context. With MCP and AWS, you have the tools to make sure your AI systems have the right context at the right time, unlocking their full potential for your organization.\\n\\n*This blog post is part of a series exploring the Model Context Protocol (MCP) on AWS. In our next installment, we’ll explore the world of agentic AI, demonstrating how to build autonomous agents using the open-source\\xa0[Strands Agents](https://aws.amazon.com/blogs/opensource/introducing-strands-agents-an-open-source-ai-agents-sdk/)\\xa0SDK with MCP to create intelligent systems that can reason, plan, and execute complex multi-step workflows. We’ll also explore advanced implementation patterns, remote MCP architectures, and discover additional use cases for MCP.*\\n\\n---\\n\\n### About the authors\\n\\n**Aditya Addepalli** is a Delivery Consultant at AWS, where he works to lead, architect, and build applications directly with customers. With a strong passion for Applied AI, he builds bespoke solutions and contributes to the ecosystem while consistently keeping himself at the edge of technology. Outside of work, you can find him meeting new people, working out, playing video games and basketball, or feeding his curiosity through personal projects.\\n\\n**Elie Schoppik**\\xa0leads live education at Anthropic as their Head of Technical Training. He has spent over a decade in technical education, working with multiple coding schools and starting one of his own. With a background in consulting, education, and software engineering, Elie brings a practical approach to teaching Software Engineering and AI. He’s shared his insights at a variety of technical conferences as well as universities including MIT, Columbia, Wharton, and UC Berkeley.\\n\\n**Jawhny Cooke** is a Senior Anthropic Specialist Solutions Architect for Generative AI at AWS. He specializes in integrating and deploying Anthropic models on AWS infrastructure. He partners with customers and AI providers to implement production-grade generative AI solutions through Amazon Bedrock, offering expert guidance on architecture design and system implementation to maximize the potential of these advanced models.\\n\\n**Kenton Blacutt**\\xa0is an AI Consultant within the GenAI Innovation Center. He works hands-on with customers helping them solve real-world business problems with cutting edge AWS technologies, especially Amazon Q and Bedrock. In his free time, he likes to travel, experiment with new AI techniques, and run an occasional marathon.\\n\\n**Mani Khanuja** is a Principal Generative AI Specialist Solutions Architect, author of the book Applied Machine Learning and High-Performance Computing on AWS, and a member of the Board of Directors for Women in Manufacturing Education Foundation Board. She leads machine learning projects in various domains such as computer vision, natural language processing, and generative AI. She speaks at internal and external conferences such AWS re:Invent, Women in Manufacturing West, YouTube webinars, and GHC 23. In her free time, she likes to go for long runs along the beach.\\n\\n**Nicolai van der Smagt**\\xa0is a Senior Specialist Solutions Architect for Generative AI at AWS, focusing on third-party model integration and deployment. He collaborates with AWS’ biggest AI partners to bring their models to Amazon Bedrock, while helping customers architect and implement production-ready generative AI solutions with these models.\\n\\n[AWS Podcast\\n\\nSubscribe for weekly AWS news and interviews\\n\\nLearn more](https://aws.amazon.com/podcasts/aws-podcast/?sc_icampaign=aware_aws-podcast&sc_ichannel=ha&sc_icontent=awssm-2021&sc_iplace=blog_tile&trk=ha_awssm-2021)\\n\\n[AWS Partner Network\\n\\nFind an APN member to support your cloud business needs\\n\\nLearn more](https://aws.amazon.com/partners/find/?sc_icampaign=aware_apn_recruit&sc_ichannel=ha&sc_icontent=awssm-2021&sc_iplace=blog_tile&trk=ha_awssm-2021)\\n\\n[AWS Training & Certifications\\n\\nFree digital courses to help you develop your skills\\n\\nLearn more](https://aws.amazon.com/training/?sc_icampaign=aware_aws-training_blog&sc_ichannel=ha&sc_icontent=awssm-2021&sc_iplace=blog_tile&trk=ha_awssm-2021)'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build your own tools in LangChain\n",
        "\n",
        "Tools are interfaces that an agent, chain, or LLM can use to interact with the world. They combine a few things:\n",
        "\n",
        "- The name of the tool\n",
        "- A description of what the tool is\n",
        "- JSON schema of what the inputs to the tool are\n",
        "- The function to call\n",
        "- Whether the result of a tool should be returned directly to the user\n",
        "\n",
        "It is useful to have all this information because this information can be used to build action-taking systems! The name, description, and JSON schema can be used to prompt the LLM so it knows how to specify what action to take, and then the function to call is equivalent to taking that action."
      ],
      "metadata": {
        "id": "-GNP2J9Dd_nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Simple Math Tool"
      ],
      "metadata": {
        "id": "ZtoArDYfheYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start by building a simple tool which does some basic math"
      ],
      "metadata": {
        "id": "JvPAmW62eLyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def multiply(a, b):\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "# Let's inspect some of the attributes associated with the tool.\n",
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa0mztbQ8Ae3",
        "outputId": "23d9826d-cbb7-4ea1-a12f-efa755b2c58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiply\n",
            "Multiply two numbers.\n",
            "{'a': {'title': 'A'}, 'b': {'title': 'B'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(multiply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "tfP2TjeK8FsR",
        "outputId": "36e4d65d-0584-430b-81ce-0bcd6f8ed6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.tools.structured.StructuredTool"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.tools.structured.StructuredTool</b><br/>def warning_emitting_wrapper(*args: Any, **kwargs: Any) -&gt; Any</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/tools/structured.py</a>Tool that can operate on any number of inputs.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 39);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.invoke({\"a\": 2, \"b\": 3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsOVBIvX8Agu",
        "outputId": "1cc9e9a5-a882-44f9-b48e-029330c1c745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.invoke({\"a\": 2.1, \"b\": 3.2})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC7o_Mv5-Grc",
        "outputId": "5048dff7-a5c1-48ef-fd65-6b7ce4ff1a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.720000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.invoke({\"a\": 2, \"b\": 'abc'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vN4tHdDa-Tm2",
        "outputId": "7cd9b72f-87db-4072-c860-628db54ee60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcabc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now build a tool with data type enforcing"
      ],
      "metadata": {
        "id": "XED8giGYeS_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.tools import StructuredTool\n",
        "\n",
        "class CalculatorInput(BaseModel):\n",
        "    a: float = Field(description=\"first number\")\n",
        "    b: float = Field(description=\"second number\")\n",
        "\n",
        "\n",
        "def multiply(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "# we could also use the @tool decorator from before\n",
        "multiply = StructuredTool.from_function(\n",
        "    func=multiply,\n",
        "    name=\"multiply\",\n",
        "    description=\"use to multiply numbers\",\n",
        "    args_schema=CalculatorInput,\n",
        "    return_direct=True\n",
        "    )\n",
        "\n",
        "# Let's inspect some of the attributes associated with the tool.\n",
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sKF2zqQ8Aih",
        "outputId": "e30067b7-17eb-4dd9-ea78-c5666a6651b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiply\n",
            "use to multiply numbers\n",
            "{'a': {'description': 'first number', 'title': 'A', 'type': 'number'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'number'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply.invoke({\"a\": 2, \"b\": 3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5taFxZg8Akc",
        "outputId": "eaef0aa4-88e5-4614-8970-29c088108de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code will error out as abc is not a floating point number\n",
        "multiply.invoke({\"a\": 2, \"b\": 'abc'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3PTl9ezG8Ans",
        "outputId": "cd5bed23-eed8-40d9-cadf-bc15a2c380b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for CalculatorInput\nb\n  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='abc', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/float_parsing",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-303488317.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this code will error out as abc is not a floating point number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmultiply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'abc'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m     ) -> Any:\n\u001b[1;32m    606\u001b[0m         \u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prep_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mchild_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                 tool_args, tool_kwargs = self._to_args_and_kwargs(\n\u001b[0m\u001b[1;32m    855\u001b[0m                     \u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36m_to_args_and_kwargs\u001b[0;34m(self, tool_input, tool_call_id)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# StructuredTool with no args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0mtool_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;31m# For backwards compatibility, if run_input is a string,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;31m# pass as a positional argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36m_parse_input\u001b[0;34m(self, tool_input, tool_call_id)\u001b[0m\n\u001b[1;32m    671\u001b[0m                             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                         \u001b[0mtool_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m                 \u001b[0mresult_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseModelV1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36mmodel_validate\u001b[0;34m(cls, obj, strict, from_attributes, context, by_alias, by_name)\u001b[0m\n\u001b[1;32m    703\u001b[0m             )\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m         return cls.__pydantic_validator__.validate_python(\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_attributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_alias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby_alias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         )\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for CalculatorInput\nb\n  Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='abc', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/float_parsing"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a Web Search & Information Extraction Tool"
      ],
      "metadata": {
        "id": "QMsvq9sVhjuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_raw_content=True)\n",
        "\n",
        "result = tavily_tool.invoke(\"Tell me about Microsoft's Q1 2025 earning call report\")\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cazBMQsghoaB",
        "outputId": "f886de17-ff75-4b71-8a62-5afc2d389391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'Microsoft (MSFT) Q1 2025 Earnings Call Transcript | The Motley Fool',\n",
              "  'url': 'https://www.fool.com/earnings/call-transcripts/2024/10/30/microsoft-msft-q1-2025-earnings-call-transcript/',\n",
              "  'content': 'Thank you, Satya. And good afternoon, everyone. This quarter, revenue was $65.6 billion, up 16%, and earnings per share was $3.30, an increase of 10%. With strong execution by our sales teams and partners, we delivered a solid start to our fiscal year with double-digit top and bottom line growth. [...] Results were ahead of expectations, driven by stronger-than-expected performance in both first- and third-party content as well as consoles. Xbox content and services revenue increased 61% with 53 points of net impact from the Activision acquisition. Segment gross margin dollars increased 16% and 17% in constant currency with 12 points of net impact from the Activision acquisition. Gross margin percentage was relatively unchanged year-over-year. [...] We also saw continued share gains across many of our businesses. In our commercial business, increased demand, and growth in long-term commitments to our Microsoft Cloud platform drove our results. Commercial bookings were ahead of expectations and increased 30% and 23% in constant currency. Results were driven by strong execution across our core annuity sales motions and growth in the number of $10 million-plus contracts for both Azure and Microsoft 365.',\n",
              "  'score': 0.9646194,\n",
              "  'raw_content': \"[▲ S&P 500\\n**+189%**\\n|\\n▲ Stock Advisor\\n**+1056%**\\nJoin The Motley Fool](https://www.fool.com/mms/mark/e-foolcom-sa-top-nav-returns)\\n\\n[Accessibility](#)\\n[Log In](/auth/authenticate/)\\n[Help](https://support.fool.com/)\\n\\n[S&P 500\\n\\n6,584.29\\n\\n-0.0%\\n\\n-$3.18](/quote/snpindex/^gspc/)\\n[DJI\\n\\n45,834.22\\n\\n-0.6%\\n\\n-$273.78](/quote/djindices/^dji/)\\n[NASDAQ\\n\\n22,141.10\\n\\n+0.4%\\n\\n+$98.03](/quote/nasdaqindex/^ixic/)\\n[Bitcoin\\n\\n115,959.00\\n\\n+0.6%\\n\\n+662.54](/quote/crypto/btc/)\\n[AAPL\\n\\n$234.07\\n\\n+1.8%\\n\\n+$4.04](/quote/nasdaq/aapl/)\\n[AMZN\\n\\n$228.24\\n\\n-0.7%\\n\\n-$1.71](/quote/nasdaq/amzn/)\\n[GOOG\\n\\n$241.44\\n\\n+0.3%\\n\\n+$0.66](/quote/nasdaq/goog/)\\n[META\\n\\n$756.15\\n\\n+0.7%\\n\\n+$5.25](/quote/nasdaq/meta/)\\n[MSFT\\n\\n$510.11\\n\\n+1.8%\\n\\n+$9.10](/quote/nasdaq/msft/)\\n[NVDA\\n\\n$177.94\\n\\n+0.4%\\n\\n+$0.77](/quote/nasdaq/nvda/)\\n[TSLA\\n\\n$395.39\\n\\n+7.2%\\n\\n+$26.58](/quote/nasdaq/tsla/)\\n\\n\\n[Daily Stock Gainers](https://www.fool.com/markets/top-stock-gainers/)\\n[Daily Stock Losers](https://www.fool.com/markets/top-stock-losers/)\\n[Most Active Stocks](https://www.fool.com/markets/most-active-stocks/)\\n\\n[Daily Stock Gainers](https://www.fool.com/markets/top-stock-gainers/)\\n[Daily Stock Losers](https://www.fool.com/markets/top-stock-losers/)\\n[Most Active Stocks](https://www.fool.com/markets/most-active-stocks/)\\n\\nFree Article\\n\\n\\nYou're reading a free article with opinions that may differ\\nfrom The Motley Fool's Premium Investing Services. Become a Motley Fool member today to\\n**get instant access to our top analyst recommendations, in-depth research, investing resources,**\\nand more. [Learn More](https://www.fool.com/mms/mark/op-free-tbox-art)\\n\\n# Microsoft (MSFT) Q1 2025 Earnings Call Transcript\\n\\nBy [Motley Fool Transcribing](/author/20032/)\\n–\\nOct 30, 2024 at 9:30PM\\n\\n## [NASDAQ: MSFT](/quote/nasdaq/msft/)\\n\\n### Microsoft\\n\\nMarket Cap\\n\\n$3.7T\\n\\nToday's Change\\n\\n(1.82%)\\xa0$9.10\\n\\nCurrent\\xa0Price\\n\\n$510.11\\n\\nPrice as of September 12, 2025, 3:58 p.m. ET\\n\\nMSFT earnings call for the period ending September 30, 2024.\\n\\nImage source: The Motley Fool.\\n\\n**Microsoft** ([MSFT](/quote/nasdaq/msft/) 1.82%)  \\nQ1 2025 Earnings Call  \\nOct 30, 2024, *5:30 p.m. ET*\\n\\n## Contents:\\n\\n* Prepared Remarks\\n* Questions and Answers\\n* Call Participants\\n\\n## Prepared Remarks:\\n\\n  \\n\\n**Operator**\\n\\nGreetings, and welcome to the Microsoft Fiscal Year 2025 first-quarter earnings conference call. [Operator instructions] As a reminder, this conference is being recorded. It is now my pleasure to introduce your host, Brett Iversen, vice president of investor relations. Please go ahead.\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\nGood afternoon, and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer; Amy Hood, chief financial officer; Alice Jolla, chief accounting officer; and Keith Dolliver, corporate secretary and deputy general counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today's call and provides the reconciliation of differences between GAAP and non-GAAP financial measures. We have recast certain prior period amounts to reflect the FY '25 changes to the composition of our segments announced in August 2024.\\n\\nAdditional details, including FY '23 and FY '24 recast segment revenue, operating income, and product and service level revenue can be found in the financial statements filed on the Investor Relations website. More detailed outlook slides will also be available on the Microsoft Investor Relations website when we provide outlook commentary on today's call. On this call, we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP.\\n\\nThey are included as additional clarifying items to aid investors in further understanding the company's first quarter performance in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year, unless otherwise noted. We will also provide growth rates in constant currency when available as a framework for assessing how our underlying businesses performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only.\\n\\nWe will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website.\\n\\nDuring this call, we'll be making forward-looking statements, which are predictions, projections, or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call, and in the Risk Factors section of our Form 10-K, Forms 10-Q and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement.\\n\\nAnd with that, I'll turn the call over to Satya.\\n\\n**Satya Nadella** -- *Chair and Chief Executive Officer*\\n\\nThank you, Brett. We are off to a solid start to our fiscal year, driven by continued strength of Microsoft Cloud, which surpassed $38.9 billion in revenue, up 22%. AI-driven transformation is changing work, work artifacts and workflow across every role, function, and business process, helping customers drive new growth and operating leverage. All up, our AI business is on track to surpass an annual revenue run rate of $10 billion next quarter, which will make it the fastest business in our history to reach this milestone.\\n\\nNow I'll highlight examples of our progress starting with infrastructure. Azure took share this quarter. We are seeing continued growth in cloud migration. Azure Arc now has over 39,000 customers across every industry, including American Tower, CTT, L'Oréal, up more than 80% year-over-year.\\n\\nWe now have data centers in over 60 regions around the world. And this quarter, we announced new cloud and AI infrastructure investments in Brazil, Italy, Mexico, and Sweden as we expand our capacity in line with our long-term demand signals. At the silicon layer, our new Cobalt 100 VMs are being used by companies like Databricks, Elastic, Siemens, Snowflake and Synopsys to power their general-purpose workloads at up to 50% better price performance than previous generations. On top of this, we are building out our next-generation AI infrastructure, innovating across the full stack to optimize our fleet for AI workloads.\\n\\nWe offer the broadest selection of AI accelerators, including our first-party accelerator, Maia 100 as well as the latest GPUs from AMD and NVIDIA. In fact, we are the first cloud to bring up NVIDIA's Blackwell system with GB200-powered AI servers. Our partnership with OpenAI also continues to deliver results. We have an economic interest in a company that has grown significantly in value, and we have built differentiated IP and are driving revenue momentum.\\n\\nMore broadly with Azure AI, we are building an end-to-end app platform to help customers build their own copilots and agents. Azure OpenAI usage more than doubled over the past 6 months as both digital natives like Grammarly and Harvey as well as established enterprises like Bajaj Finance, Hitachi, KT, and LG move apps from test to production. GE Aerospace, for example, used Azure OpenAI to build a new digital assistant for all 52,000 of its employees. In just 3 months, it has been used to conduct over 500,000 internal queries and process more than 200,000 documents.\\n\\nAnd this quarter, we added support for OpenAI's newest model family, o1. We're also bringing industry-specific models through Azure AI, including a collection of best-in-class multimodal models for medical imaging. And with the GitHub models, we now provide access to our full model catalog directly within the GitHub developer workflow. Azure AI is also increasingly an on-ramp to our data and analytics services.\\n\\nAs developers build new AI apps on Azure, we have seen an acceleration of Azure Cosmos DB and Azure SQL DB hyperscale usage as customers like Air India, Novo Nordisk, Telefonica, Toyota Motor North America and Uniper take advantage of capabilities purpose built for AI applications. And with Microsoft Fabric, we provide a single AI-powered platform to help customers like Chanel, EY, KPMG, Swissair and Syndigo unify their data across clouds. We now have over 16,000 paid Fabric customers, over 70% of the Fortune 500. Now on to developers.\\n\\nGitHub Copilot is changing the way the world builds software. Copilot enterprise customers increased 55% quarter-over-quarter as companies like AMD and Flutter Entertainment tailor Copilot to their own code base. And we are introducing the next phase of AI code generation, making GitHub Copilot agentic across the developer workflow. GitHub Copilot Workspace is a developer environment, which leverages agents from start to finish so developers can go from spec to plan to code all in natural language.\\n\\nCopilot Autofix is an AI agent that helps developers at companies like Asurion and Auto Group fix vulnerabilities in their code over three times faster than it would take them on their own. We're also continuing to build on GitHub's open platform ethos by making more models available via GitHub Copilot. And we are expanding the reach of GitHub to a new segment of developers introducing GitHub Spark, which enables anyone to build apps in natural language. Already, we have brought generative AI to Power Platform to help customers use low-code, no-code tools to cut costs and development time.\\n\\nTo date, nearly 600,000 organizations have used AI-powered capabilities in Power Platform, up four times year-over-year. Citizen developers at ZF, for example, built apps simply by describing what they need using natural language. And this quarter, we introduced new ways for customers to apply AI to streamline complex workflows with Power Automate. Now on to work.\\n\\nWe launched the next wave of Microsoft 365 Copilot innovation last month, bringing together web, work, and Pages as the new design system for knowledge work. Pages is the first new digital artifact for the AI age, and it's designed to help you ideate with AI and collaborate with other people. We've also made Microsoft 365 Copilot responses two times faster and improved response quality by nearly 3x. This innovation is driving accelerated usage, and the number of people using Microsoft 365 daily more than doubled quarter-over-quarter.\\n\\nWe are also seeing increased adoption from customers in every industry as they use Microsoft 365 Copilot to drive real business value. Vodafone, for example, will roll out Microsoft 365 Copilot to 68,000 employees after a trial showed that, on average, they save 3 hours per person per week. And UBS will deploy 50,000 seats in our largest finserve deal to date. And we continue to see enterprise customers coming back to buy more seats.\\n\\nAll up, nearly 70% of the Fortune 500 now use Microsoft 365 Copilot, and customers continue to adopt it at a faster rate than any other new Microsoft 365 suite. Copilot is the UI for AI, and with Microsoft 365 Copilot, Copilot Studio and agents and now autonomous agents, we have built an end-to-end system for AI business transformation. With Copilot Studio, organizations can build and connect Microsoft 365 Copilot to autonomous agents, which then delegate to Copilot when there is an exception. More than 100,000 organizations from Nsure, Standard Bank and Thomson Reuters to Virgin Money and Zurich Insurance have used Copilot Studio to date, up over two times quarter-over-quarter.\\n\\nMore broadly, we are seeing AI drive a fundamental change in the business applications market as customers shift from legacy apps to AI-first business processes. Dynamics 365 continues to take share as organizations like Evron, Heineken and Lexmark chose our apps over other providers. And monthly active users of Copilot across our CRM and ERP portfolio increased over 60% quarter-over-quarter. Our Dynamics 365 contact center is also winning customers like Currys, Le Creuset and RXO as it brings generative AI to every customer engagement channel.\\n\\nAnd just last week, we added 10 out-of-the-box autonomous agents to Dynamics 365 that helps customers automatically qualify sales leads, track suppliers and work hand in hand with service reps to resolve issues. We're also bringing AI to industry-specific workflows. One year in, DAX Copilot is now documenting over 1.3 million physician-patient encounters each month at over 500 healthcare organizations like Baptist Medical Group, Baylor Scott & White, Greater Baltimore Medical Center, Novant Health and Overlake Medical Center. It is showing faster revenue growth than GitHub Copilot did in this first year.\\n\\nAnd new features extend DAX beyond notes, helping physicians automatically draft referrals, after-visit instructions, and diagnostic evidence. On top of all this AI innovation, Microsoft Teams usage remains at all-time highs as people use it to streamline all their communications. Nearly 75% of our Teams Enterprise customers now buy Premium, Phone or Rooms. When it comes to Windows, our new class of Copilot+ PCs is winning new customers.\\n\\nThey offer best-in-class AI capability, performance, and value. AMD, Intel, and Qualcomm now all support Copilot+ PCs. This quarter, we also introduced new AI experience only available on Copilot+ PCs like Click to Do, which places an interactive overlay over your desktop to suggest next best actions. And as we approach the end of support for Windows 10 a year from now, we are well positioned to transition our customers to Windows 11, ensuring they benefit from enhanced features and security improvements we've introduced over the past few years.\\n\\nNow on to security. We continue to prioritize security above all else. With our Secure Future Initiative, we have dedicated the equivalent of 34,000 full-time engineers to address the highest-priority security tasks. We have made significant progress to better protect tenants' identities, networks, and engineering systems, and we have created new processes to ensure security is prioritized at every level of the company.\\n\\nAnd we continue to take what we learn and turn it into innovations across our products. Security Copilot, for example, is being used by companies in every industry, including Clifford Chance, Intesa Sanpaolo, and Shell to perform SecOps tasks faster and more accurately. And we are now helping customers protect their AI deployments, too. Customers have used Defender to discover and secure more than 750,000 GenAI app instances and used Purview to audit over 1 billion Copilot interactions to meet their compliance obligations.\\n\\nAnd all up, we continue to take share across all major categories we serve and are consistently recognized by top analysts as a leader in 20 categories more than any other vendor. Now let me turn to our consumer businesses, starting with LinkedIn. Member growth continues to accelerate with markets in India and Brazil both growing at double digits. We are also seeing record engagement as we introduce new ways for our more than 1 billion members to connect, sell services, get hired and share knowledge.\\n\\nOur investments in rich formats like video strengthen our leadership in B2B advertising and amplify the value we deliver to our customers. Weekly immersive video views increased six times quarter-over-quarter, and total video viewership on LinkedIn is up 36% year-over-year. Our AI-powered tools also continue to transform how people sell, learn and hire. In Sales, new AI features help every team member perform at the level of top sellers and drive more profitable growth.\\n\\nIn Learning, just yesterday, we announced updates to our coaching experience, including personalized career development plans. LinkedIn's first agent hiring assistant will help hirers find qualified candidates faster by tackling the most time-consuming task. Already hirers who use AI assistant messages see a 44% higher acceptance rate compared to those who don't. And our hiring business continues to take share.\\n\\nNow on to Search, Advertising and News. With Copilot, we are seeing the first step toward creating a new AI companion for everyone with new Copilot experience we introduced earlier this month, includes a refreshed design and tone along with improved speed and fluency across the web and mobile. And it includes advanced capabilities like voice and vision that make it more delightful and useful and feel more natural. You can both browse and converse with Copilot simultaneously because Copilot sees what you see.\\n\\nMore broadly, AI is also transforming search, browsers, and digital advertising, and we continue to take share across Bing and Edge. Bing ex TAC revenue growth outpaced the search market. Now on to Gaming. One year since we closed our acquisition of Activision Blizzard King, we are focused on building a business positioned for long-term growth, driven by higher-margin content and services.\\n\\nYou already see this transformation in our results as we diversify the ways that gamers access our content. We set new records for monthly active users in the quarter as more players than ever play our games across devices and on the Xbox platform. Game Pass also set a new Q1 record for total revenue and average revenue per subscriber. And as we look ahead, our IP across our studios has never been stronger.\\n\\nLast week's launch of Black Ops 6 was the biggest Call of Duty release ever, setting a record for day 1 players as well as Game Pass subscriber adds on launch day. And unit sales on PlayStation and Steam were also up over 60% year-over-year. This speaks to our strategy of meeting gamers where they are by enabling them to play more games across the screens they spend their time on. In closing, we are rapidly innovating to expand our opportunity across our commercial and consumer businesses.\\n\\nIn 3 weeks' time, we will hold our Ignite Conference, and I look forward to sharing more then about how we are helping every business function use AI to drive growth in this new era. With that, let me turn it over to Amy.\\n\\n**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\\n\\nThank you, Satya. And good afternoon, everyone. This quarter, revenue was $65.6 billion, up 16%, and earnings per share was $3.30, an increase of 10%. With strong execution by our sales teams and partners, we delivered a solid start to our fiscal year with double-digit top and bottom line growth.\\n\\nWe also saw continued share gains across many of our businesses. In our commercial business, increased demand, and growth in long-term commitments to our Microsoft Cloud platform drove our results. Commercial bookings were ahead of expectations and increased 30% and 23% in constant currency. Results were driven by strong execution across our core annuity sales motions and growth in the number of $10 million-plus contracts for both Azure and Microsoft 365.\\n\\nAdditionally, we also saw an increase in the number of $100-million-plus contracts for Azure. Commercial remaining performance obligation increased 22% and 21% in constant currency to $259 billion. Roughly 40% will be recognized in revenue in the next 12 months, up 17% year-over-year. The remaining portion, recognized beyond the next 12 months, increased 27%.\\n\\nAnd this quarter, our annuity mix increased to 98%. In addition to commercial results that were in line with expectations, we also saw some benefit from in-period revenue recognition across Microsoft 365 commercial, Azure, and our on-premises server business. At a company level, Activision contributed a net impact of approximately 3 points to revenue growth with a 2 point drag on operating income growth and had a negative $0.05 impact to earnings per share. A reminder that this net impact includes adjusting for the movement of Activision content from our prior relationship as a third-party partner to first-party and includes $911 million from purchase accounting adjustments, integration, and transaction-related cost.\\n\\nFX did not have a significant impact on our results and was roughly in line with expectations on total company revenue, segment-level revenue, COGS, and operating expense growth. Microsoft Cloud revenue was $38.9 billion and grew 22%, roughly in line with expectations. Microsoft Cloud gross margin percentage decreased 2 points year-over-year to 71%. This was slightly better than expected due to improvement in Azure, although the gross margin percentage decrease year-over-year continues to be driven by scaling our AI infrastructure.\\n\\nCompany gross margin dollars increased 13% and 14% in constant currency, and gross margin percentage was 69%, down 2 points year-over-year, driven by the lower Microsoft Cloud gross margin noted earlier as well as the impact from purchase accounting adjustments, integration, and transaction-related costs from the Activision acquisition. Operating expenses increased 12%, lower than expected due to our focus on cost efficiencies and ongoing prioritization work. Operating expense growth included 9 points from the Activision acquisition. At a total company level, headcount at the end of September was 8% higher than a year ago.\\n\\nExcluding the growth from the Activision acquisition, headcount was 2% higher. Operating income increased 14% and operating margins were 47%, down 1 point year-over-year. Excluding the net impact from the Activision acquisition, operating margins were up 1 point as we continue to drive efficiencies across our businesses as we invest in AI infrastructure and capabilities. Now to our segment results.\\n\\nRevenue from Productivity and Business Processes was $28.3 billion and grew 12% and 13% in constant currency, ahead of expectations, driven by better-than-expected results across all businesses. M365 commercial cloud revenue increased 15% and 16% in constant currency with business trends that were as expected. The better-than-expected result was due to a small benefit from the in-period revenue recognition noted earlier. ARPU growth was primarily driven by E5 as well as M365 Copilot.\\n\\nPaid M365 commercial seats grew 8% year-over-year with installed base expansion across all customer segments. Seat growth was driven by our small and medium business and frontline worker offerings. M365 commercial cloud revenue represents nearly 90% of total M365 commercial products and cloud services. M365 commercial products revenue increased 2% and 3% in constant currency, ahead of expectations, primarily due to the benefit from in-period revenue recognition noted earlier.\\n\\nM365 consumer products and cloud services revenue increased 5% and 6% in constant currency. M365 consumer cloud revenue increased 6% and 7% in constant currency, with continued momentum in M365 consumer subscriptions, which grew 10% to 84.4 million. M365 consumer cloud revenue represents 85% of total M365 consumer products and cloud services. LinkedIn revenue increased 10% and 9% in constant currency, slightly ahead of expectations with growth across all lines of business.\\n\\nDynamics revenue grew 14%, driven by Dynamics 365, which grew 18% and 19% in constant currency with continued growth across all workloads and continued share gains. As a reminder, Dynamics 365 represents about 90% of total Dynamics revenue. Segment gross margin dollars increased 11% and 12% in constant currency, and gross margin percentage decreased slightly year-over-year, driven by scaling our AI infrastructure. Operating expenses increased 2%, and operating income increased 16%.\\n\\nNext, the Intelligent Cloud segment. Revenue was $24.1 billion, increasing 20% and 21% in constant currency, in line with expectations. Azure and other cloud services revenue grew 33% and 34% in constant currency, with healthy consumption trends that were in line with expectations. The better-than-expected result was due to the small benefit from in-period revenue recognition noted earlier.\\n\\nAzure growth included roughly 12 points from AI services similar to last quarter. Demand continues to be higher than our available capacity. Non-AI growth trends were also in line with expectations in total and across regions as customers continued to migrate and modernize on the Azure platform. The non-AI point contribution to Azure growth was sequentially lower by approximately 1 point.\\n\\nIn our on-premises server business, revenue decreased 1%. Lower-than-expected transactional purchasing ahead of the Windows Server 2025 launch as well as lower purchasing of licenses running in multi-cloud environments was mostly offset by the benefit from in-period revenue recognition noted earlier. Enterprise and partner services revenue decreased 1% and was relatively unchanged in constant currency. Segment gross margin dollars increased 15%, and gross margin percentage decreased 3 points year-over-year, driven by scaling our AI infrastructure.\\n\\nOperating expenses increased 8% and operating income grew 18%. Now to More Personal Computing. Revenue was $13.2 billion, increasing 17% with 15 points of net impact from the Activision acquisition. Results were above expectations, driven by Gaming and Search.\\n\\nWindows OEM and Devices revenue increased 2% year-over-year as better-than-expected results in Windows OEM due to mix shift to higher monetizing markets was partially offset by the lower-than-expected results in devices due to execution challenges in the commercial segment. Search and news advertising revenue ex TAC increased 18% and 19% in constant currency ahead of expectations, primarily due to continued execution improvement. We saw rate expansion in addition to healthy volume growth in both Edge and Bing. And in Gaming, revenue increased 43% and 44% in constant currency with 43 points of net impact from the Activision acquisition.\\n\\nResults were ahead of expectations, driven by stronger-than-expected performance in both first- and third-party content as well as consoles. Xbox content and services revenue increased 61% with 53 points of net impact from the Activision acquisition. Segment gross margin dollars increased 16% and 17% in constant currency with 12 points of net impact from the Activision acquisition. Gross margin percentage was relatively unchanged year-over-year.\\n\\nOur strong execution on margin improvement in gaming and search was offset by sales mix shift to those businesses. Operating expenses increased 49% with 51 points from the Activision acquisition. Operating income decreased 4%. Now back to total company results.\\n\\nCapital expenditures including finance leases were $20 billion, in line with expectations, and cash paid for PP&E was $14.9 billion. Roughly half of our cloud and AI-related spend continues to be for long-lived assets that will support monetization over the next 15 years and beyond. The remaining cloud and AI spend is primarily for servers, both CPUs and GPUs, to serve customers based on demand signals. Cash flow from operations was $34.2 billion, up 12%, driven by strong cloud billings and collections, partially offset by higher supplier employee and tax payments.\\n\\nFree cash flow was $19.3 billion, down 7% year-over-year, reflecting higher capital expenditures to support our cloud and AI offerings. This quarter, other income expense was negative $283 million, significantly more favorable than anticipated due to foreign currency remeasurement and net gains on investments. Our losses on investments accounted for under the equity method were as expected. Our effective tax rate was approximately 19%.\\n\\nAnd finally, we returned $9 billion to shareholders through dividends and share repurchases. Now moving to our Q2 outlook, which, unless specifically noted otherwise, is on a U.S. dollar basis. First, FX.\\n\\nWith the weaker U.S. dollar and assuming current rates remain stable, we expect FX to increase total revenue and segment level revenue growth by less than 1 point. We expect FX to have no meaningful impact to COGS or operating expense growth. Our outlook has many of the trends we saw in Q1 continue through Q2.\\n\\nCustomer demand for our differentiated solutions should drive another quarter of strong growth. In commercial bookings, we expect strong growth on a growing expiry base driven by increased long-term commitments to our platform and strong execution across core annuity sales motions. As a reminder, larger long-term Azure contracts, which are more unpredictable in their timing, can drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 70%, down year-over-year, driven by the impact of scaling our AI infrastructure.\\n\\nWe expect capital expenditures to increase on a sequential basis given our cloud and AI demand signals. As I said last quarter, we will stay aligned and if needed, adjust to the demand signals we see. As a reminder, there can be quarterly spend variability from cloud infrastructure build-outs and the timing of delivery of finance leases. Next, segment guidance, starting with Productivity and Business Processes.\\n\\nWe are the market leader when it comes to knowledge-based copilots and agents in the enterprise space, and we are focused on continuing to gain share across our productivity solutions. Therefore, we expect revenue in Productivity and Business Processes to grow between 10% and 11% in constant currency or USD 28.7 billion to USD 29 billion. M365 commercial cloud revenue growth should be approximately 14% in constant currency with moderating seat growth across customer segments and ARPU growth through E5 and M365 Copilot. For H2, we expect revenue growth to remain relatively stable compared to Q2.\\n\\nWe continue to see growth in M365 Copilot seats, and we expect the related revenue to continue to grow gradually over time. For M365 commercial products, we expect revenue to decline in the low single digits. As a reminder, M365 commercial products include on-premises components of M365 suites, so our quarterly revenue growth can have variability primarily from in-period revenue recognition depending on the mix of contracts. M365 consumer cloud revenue growth should be in the mid-single digits driven by M365 subscriptions.\\n\\nFor LinkedIn, we expect revenue growth of approximately 10%, driven by continued growth across all businesses. And in Dynamics 365, we expect revenue growth to be in the mid- to high teens, driven by continued growth across all workloads. Next, Intelligent Cloud. Helping our customers transform and grow with innovative cloud and AI solutions is driving continued growth in Azure.\\n\\nTherefore, we expect revenue in Intelligent Cloud to grow between 18% and 20% in constant currency or USD 25.55 billion to USD 25.85 billion. Revenue will continue to be driven by Azure, which, as a reminder, can have quarterly variability primarily from in-period revenue recognition depending on the mix of contracts. In Azure, we expect Q2 revenue growth to be 31% to 32% in constant currency, driven by strong demand for our portfolio of services. We expect consumption growth to be stable compared to Q1, and we expect to add more sequential dollars to Azure than any other quarter in history.\\n\\nWe expect the contribution from AI services to be similar to last quarter, given the continued capacity constraints as well as some capacity that shifted out of Q2. And in H2, we still expect Azure growth to accelerate from H1 as our capital investments create an increase in available AI capacity to serve more of the growing demand. And in our on-premises server business, we expect revenue to decline in the low to mid-single digits on a prior year comparable that benefited from purchasing ahead of Windows Server 2012 end of support. And in Enterprise and partner services, we expect revenue growth to be in the low single digits.\\n\\nNow to More Personal Computing. We continue to make decisions to prioritize strategic higher-margin opportunities within each of our consumer businesses. Our outlook reflects the improvement in gross and operating margins from this prioritization work across gaming, search, and devices. We expect revenue in More Personal Computing to be USD 13.85 billion to USD 14.25 billion.\\n\\nWindows OEM and devices revenue should decline in the low to mid-single digits. We expect Windows OEM revenue growth in line with the PC market to be more than offset by a decline in devices as the trends from Q1 continue. Search and news advertising ex TAC revenue growth should be in the high teens, with continued growth in both volume and revenue per search. This will be higher than overall search and news advertising revenue growth, which we expect to be in the high single digits.\\n\\nAnd in Gaming, we expect revenue to decline in the high single digits due to hardware. We expect Xbox content and services revenue growth to be relatively flat. We're excited about last week's launch of Call of Duty, where we saw the most Game Pass subscriber adds we've ever seen on a launch day. There are two things about the launch that are different than the Call of Duty launch a year ago, where revenue was mostly recognized in the quarter of purchase.\\n\\nFirst, the game is available on Game Pass, so for players who play through Game Pass, the subscription revenue is recognized over time. Second, the game requires an online connection to play, so even for players who purchased the stand-alone game, revenue recognition will also occur ratably over time. Now back to company guidance. We expect COGS to grow between 11% and 13% in constant currency or to be between USD 21.9 billion to USD 22.1 billion, and operating expense to grow approximately 7% in constant currency or to be between USD 16.4 billion and USD 16.5 billion.\\n\\nThis should result in another quarter of operating margin expansion. Other income and expense is expected to be roughly negative $1.5 billion, primarily driven by our share of the expected loss from OpenAI, which is accounted for under the equity method. As a reminder, we do not recognize mark-to-market gains or losses on equity method investments. As you heard from Satya, our strategic partnership and investment in OpenAI has been pivotal in building and scaling our AI business and positioning us as the leader in the AI platform wave.\\n\\nAnd lastly, we expect our Q2 effective tax rate to be approximately 19%. In closing, we remain focused on strategically investing in the long-term opportunities that we believe drive shareholder value. Monetization from these investments continues to grow, and we're excited that only 2.5 years in, our AI business is on track to surpass $10 billion of annual revenue run rate in Q2. This will be the fastest business in our history to reach this milestone.\\n\\nWe are committed to growing this leadership position across our entire Microsoft Cloud while maintaining our disciplined focus on cost management and prioritization across every team. With that, let's go to Q&A, Brett.\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\nThanks, Amy. We'll now move over to Q&A. [Operator instructions] Operator, can you please repeat your instructions?\\n\\n## Questions & Answers:\\n\\n  \\n\\n**Operator**\\n\\n[Operator instructions] Our first question comes from the line of Keith Weiss with Morgan Stanley. Please go ahead.\\n\\n**Keith Weiss** -- *Analyst*\\n\\nExcellent. Thank you, guys, for taking the questions. Congratulations on a really solid quarter. So Satya, the expansion of capabilities, the speed of innovation, the magnitude of the opportunities ahead for generative AI makes this the most exciting period for software I've seen in my 25 years of covering this space.\\n\\nAnd based upon this call, it seems like you share that excitement. But in my investor conversation, that excitement also feeds two related questions, and they both have to do with constraints. And the first is like what are the internal constraints or guardrails that Microsoft has when it comes to investing behind these innovations, particularly in relation to the funding of future generations of foundational models, where people are talking about price tags using the tens of billions or even $100 billion plus. And then on the other side of the spectrum, what are the external constraints that Microsoft sees in building out this capacity to meet the demand and capture the opportunity, particularly constraints in your ability to power all these new data centers being built out and power it in an environmentally sustainable fashion? I'd love to get the Microsoft perspective on both those questions.\\n\\n**Satya Nadella** -- *Chair and Chief Executive Officer*\\n\\nThank you, Keith, for those questions. I think on the first point, ultimately, when you think about, let's say, capital outlay for training because that's essentially what you're asking, it is going to be rate limited by your monetization of inference in a given generation, right? So just like in the past, we would allocate capital to build out cloud based on the demand signal we were seeing and then we would then project the demand, and that's what we would build it for. So you can think of training essentially as that, right, which is you're building the next-generation model so that then you have a more capable model that then drives more inference demand, right? So ultimately -- even with all the scaling laws and what have you, I think you ultimately will normalize to having a pace. In fact, I think the best way to think about even is given that Moore's Law effectively is working on the sort of silicon and system side, so it's just not compute, right? It's efficiencies in compute.\\n\\nIt's data as well as algorithms. You will want to sort of keep on that curve, which is you really want to refresh your fleet with the Moore's Law every year and then effectively depreciate it over the period of the life cycle of it. And then the inference demand ultimately will govern how much we invest in training because that's, I think, at the end of the day, you're all subject to ultimately demand. The second piece of the external constraints, we have run into obviously lots of external constraints because this demand all showed up pretty fast, right? I mean if you think about even the most hit product of this generation, all are in our cloud, right, whether it's ChatGPT, whether it's Copilot, whether it's GitHub Copilot or even DAX Copilot.\\n\\nI mean pick the top 4 or 5 products of this generation. They're all sort of in and around our ecosystem. And so therefore, we ran into a set of constraints, which are everything because DCs don't get built overnight. So there is DCs.\\n\\nThere is power. And so that's sort of been the short-term constraint. Even in Q2, for example, some of the demand issues we have -- or our ability to fulfill demand is because of, in fact, external third-party stuff that we leased moving out. So that's the constraints we have.\\n\\nBut in the long run, we do need effectively power and we need DCs. And some of these things are more long lead. But I feel pretty good that going into the second half of even this fiscal year, that some of that supply/demand will match up.\\n\\n**Keith Weiss** -- *Analyst*\\n\\nExcellent. Thank you, guys.\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\nThanks, Keith. Operator, next question please.\\n\\n**Operator**\\n\\nThe next question comes from the line of Brent Thill with Jefferies.\\n\\n**Brent Thill** -- *Analyst*\\n\\nThanks, Amy. Good to hear the reacceleration in the back half for Azure. I guess many are asking, 34% growth in Q1 falling to low 30s. I know the comp is a couple of points harder.\\n\\nBut is there anything else you're contemplating in that guide for Q2 to see that deceleration other than a tougher comp? Thank you.\\n\\n**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\\n\\nThanks, Brent. Maybe this is a great question because I can sort of reiterate some of the points I made and tie them together a little bit. In Q1, the 34% in CC, we talked about that upside versus the 33% that we had guided to was primarily due to some revenue recognition benefits. And so I think about that on a sort of a pure consumption basis and AI as being 33%.\\n\\nAnd you think about 1 point or 2 of decel that we've guided to, and the majority of that is due to, unfortunately, some supply pushouts that I mentioned and then Satya reiterated in terms of AI supply coming online that we counted on. The underlying consumption growth is stable Q1 to Q2. And so to your question on some ins and outs, it is certainly some ins and outs. I do, as you heard, have confidence, as we get a good influx of supply across the second half of the year particularly on the AI side, that we'll be better able to do some supply demand matching and hence, while we're talking about acceleration in the back half.\\n\\nI'll also take the opportunity to say, when you see usage in AI workloads, we always intend to think about that as just a GPU exercise. The importance of having GPUs and CPUs be able to run these workloads is also important. So that's a piece of the acceleration in H2 as well.\\n\\n**Brent Thill** -- *Analyst*\\n\\nThanks.\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\nThanks, Brant. Operator, next question please.\\n\\n**Operator**\\n\\nThe next question comes from the line of Mark Moerdler with Bernstein. Please proceed.\\n\\n**Mark Moerdler** -- *Analyst*\\n\\nThank you very much for taking my question. Congratulations on the quarter. The question every investor obviously asks is a question on the capex growth and the capex spend. Obviously, half of that facility is an equivalent that have a longer life, but the other half is the rest of the components.\\n\\nCan you give any color on how you think of that growth? Does it return to the traditional approach, where basically capex is going to grow in line or slightly slower than cloud revenue? And if so, any sense of the timing? Do we have enough facilities online by sometime next year, et cetera? Any color would be appreciated.\\n\\n**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\\n\\nThanks, Mark. I think in some ways, it's helpful to go back to the cloud transition that we worked on over a decade ago, I think, in the early stages. And what you did see, and you'll see us do in the same time is you have to build to meet demand. Unlike the cloud transition, we're doing it on a global basis in parallel as opposed to sequential given the nature of the demand.\\n\\nAnd then as long as we continue to see that demand grow, you're right, the growth in capex will slow and the revenue growth will increase. And those 2 things, to your point, get closer and closer together over time. The pace of that entirely depends really on the pace of adoption. And to Satya's point, some of that spend goes toward building the next training infrastructure so you won't see all of it in COGS.\\n\\nSome of it goes to opex when you're spending it on training. But in general, that's a healthy way to think about the balance as that over time does do and should, like the last cycle, get closer together.\\n\\n**Mark Moerdler** -- *Analyst*\\n\\nThank you very much. That's very helpful.\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\nThanks, Mark. Operator, next question please.\\n\\n**Operator**\\n\\nThe next question comes from the line of Karl Keirstead with UBS. Please proceed.\\n\\n**Karl Keirstead** -- *Analyst*\\n\\nOK. Great. Thank you. I'm actually not going to ask a question about the numbers, but Satya and Amy, I'd love to ask a question about OpenAI.\\n\\nSince the print 3 months ago, we, investors have been hit with a torrent of media stories about OpenAI and Microsoft. And I'd love to give Microsoft an opportunity to frame the relationship. It seems to me it's critically important. But we have been, I think, everyone on the line, picking up signals that perhaps Microsoft wants to diversify somewhat at the model layer and offer customers choice.\\n\\nSo Satya, I'd love to get your framing of the relationship. And then in terms of the numbers, maybe this is a little bit more for you, Amy. But how does Microsoft manage the demands on capex from helping OpenAI with its scaling ambitions? And how do you manage the impact on other income that you just gave us some color on?\\n\\n**Satya Nadella** -- *Chair and Chief Executive Officer*\\n\\nSure. Thanks, Karl. So I'd say, first, the partnership for both sides, that's OpenAI and Microsoft, has been super beneficial. After all, we were the -- we effectively sponsored what is one of the most highest-valued private companies today when we invested in them and really took a bet on them and their innovation 4, 5 years ago.\\n\\nAnd that has led to great success for Microsoft. That's led to great success for OpenAI. And we continue to build on it, right? So we serve them with world-class infrastructure on which they do their innovation in terms of models, on top of which we innovate on both the model layer with some of the post-training stuff we do as well as some of the small models we build and then, of course, all of the product innovation, right? One of the things that my own sort of conviction of OpenAI and what they were doing came about when I started seeing something like GitHub Copilot as a product get built or DAX Copilot get built or M365 Copilot get built. So we have a fantastic portfolio of innovation that we build on top of that.\\n\\nAnd the same also, I would say, we are investors. We feel very, very good about sort of our investment stake in OpenAI. And so our focus -- and we're always in constant dialogue with them in a partnership like this where both sides have achieved mutual success at the pace at which we've achieved it. That means we need to kind of push each other to do more, to capture the moment, and that's what we plan to do, and we intend to keep building on it.\\n\\n**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\\n\\nAnd maybe to your other two questions, Karl, listen, I'm thrilled with their success and need for supply from Azure and infrastructure and really what it's meant in terms of being able to also serve other customers for us. It's important that we continue to invest capital to meet not only their demand signal and needs for compute but also from our broader customers. That's partially why you've seen us committing the amount of capital we've seen over the past few quarters, is our commitment to both grow together and for us to continue to grow the Azure platform for customers beyond them. And so I don't really think of it as how do you balance it.\\n\\nIt's just we have customers who have needs and real use cases and delivering value today. And if we can't meet that, we need to work to meet it. And that means working harder and faster to make sure we do that, which is what the team is committed to do. Second piece of your question, I think, was on the impact to other income.\\n\\nAnd not to get too accounting heavy on the earnings phone call, but I would say, just a reminder, this is under the equity method, which means we just take our percentage of losses every quarter. And those losses, of course, are capped by the amount of investment we make in total, which we did talk about in the Q this quarter as being $13 billion. And so over time, that's just the constraint, and it's a bit of a mechanical entry. And so I don't really think about managing that.\\n\\nThat's the investment and acceleration that OpenAI is making in themselves, and we take a percentage of that.\\n\\n**Karl Keirstead** -- *Analyst*\\n\\nGot it. OK. Very helpful. Thank you both.\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\nThanks, Karl. Operator, next question please.\\n\\n**Operator**\\n\\nThe next question comes from the line of Kash Rangan with Goldman Sachs. Please proceed.\\n\\n**Kash Rangan** -- *Analyst*\\n\\nHi. Thank you very much. Satya, when you talked about the investment cycle, these models are getting bigger, more expensive, but you also pointed out to how in the inference phase, we're likely to get paid. How does that cycle look like in inference for Microsoft? Where are the products and the applications that will show up on the Microsoft P&L as a result of the inference phase of AI kicking in?\\n\\n**Satya Nadella** -- *Chair and Chief Executive Officer*\\n\\nThanks, Kash. I mean the good news for us is that we're not waiting for that inference to show up, right? If you sort of think about the point we even made that this is going to be the fastest growth to $10 billion of any business in our history, it's all inference, right? One of the things that may not be as evident is that we're not actually selling raw GPUs for other people to train. In fact, that's sort of a business we turn away because we have so much demand on inference that we are not taking what I would -- in fact, there's a huge adverse selection problem today where people -- it's just a bunch of tech companies still using VC money to buy a bunch of GPUs. We kind of really are not even participating in most of that because we are literally going to the real demand, which is in the enterprise space or our own products like GitHub Copilot or M365 Copilot.\\n\\nSo I feel the quality of our revenue is also pretty superior in that context. And that's what gives us even the conviction, to even Amy's answers previously, about our capital spend, is if this was just all about sort of a bunch of people training large models and that was all we got, then that would be ultimately still waiting, to your point, for someone to actually have demand, which is real. And in our case, the good news here is we have a diversified portfolio. We're seeing real demand across all of that portfolio.\\n\\n**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\\n\\nAnd Kash, maybe just to add a little bit to what Satya is saying. I think a part of his 2 answers is that what you're seeing is this number we're talking about, the $10 billion, across inference and our apps is already what that momentum and that investment and that progress and that revenue is what builds the next cycle of training, right? And so it's that circle as opposed to, oh, we're doing training now and then inference. Much of the training investments that are -- that fuel this revenue growth came before, and we already funded that work. And so that's an important part.\\n\\n**Kash Rangan** -- *Analyst*\\n\\nThat's, to your point, that you invest now, and you can get the growth later even if you slow down the capex, right? That's what you're trying to tell us.\\n\\n**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\\n\\nThat's the cycle that is important to understand.\\n\\n**Kash Rangan** -- *Analyst*\\n\\nGot it. Thank you so much.\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\nThanks, Kash. Operator, next question please.\\n\\n**Operator**\\n\\nThe next question comes from the line of Mark Murphy with J.P. Morgan. Please proceed.\\n\\n**Mark Murphy** -- *Analyst*\\n\\nThank you very much. I'm wondering if you can shed any more light just on the nature of the supply limitations that you're mentioning that are impacting Azure in Q2, where that impact might be incrementally just a touch more than we expected. Is it more the GPU supply? Is there some element of power cooling or the ability to wire up the networks? And Amy, should we infer that the supply is constraining Azure growth by roughly a couple of few points in Q2? Or am I overestimating that?\\n\\n**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\\n\\nMaybe to answer both those questions, Mark, very directly, I wouldn't think about it component logic in my Q2 answer. The supply pushout, as Satya said, was third parties that are delivering later than we had expected, that get pushed mainly into the second half of the year and in general, Q3. So that's third parties where we have tended to buy supply inclusive of kits, so it's complete end-to-end third-party delivery. In terms of the impact, as I was saying, when you think about having flat consumption Q1 to Q2, there really are only 2 things that impact that difference, and 1 was the help we got in Q1 from the revenue and accounting help.\\n\\nAnd then Q2 has been the supply pushout.\\n\\n**Mark Murphy** -- *Analyst*\\n\\nThank you.\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\nThanks, Mark. Operator, next question please.\\n\\n**Operator**\\n\\nThe next question comes from the line of Raimo Lenschow with Barclays. Please proceed.\\n\\n**Raimo Lenschow** -- *Analyst*\\n\\nThank you. If you talk about the market at the moment -- because you were first with Copilot, you had identified a lot with copilots and now we're talking agents. Can you kind of -- Satya, how do you think about that? And to me, it looks like an evolution that we're discovering how to kind of productize AI better, et cetera. So how do you think about that journey between copilots, agents and maybe what's coming next?\\n\\n**Satya Nadella** -- *Chair and Chief Executive Officer*\\n\\nSure. The system we have built is Copilot, Copilot Studio, agents, and autonomous agents. You should think of that as the spectrum of things, right? So ultimately, the way we think about how this all comes together is you need humans to be able to interface with AI. So the UI layer for AI is Copilot.\\n\\nYou can then use Copilot Studio to extend Copilot. For example, you want to connect it to your CRM system, to your office system, to your HR system. You do that through Copilot Studio by building agents effectively. You also build autonomous agents.\\n\\nSo you can use even -- that's the announcement we made a couple of weeks ago, is you can even use Copilot Studio to build autonomous agents. Now these autonomous agents are working independently, but from time to time, they need to raise an exception, right? So autonomous agents are not fully autonomous because, at some point, they need to either notify someone or have someone input something. And when they need to do that, they need a UI layer, and that's where, again, it's Copilot. So Copilot, Copilot agents built-in Copilot Studio, autonomous agents built in Copilot Studio, that's the full system, we think, that comes together, and we feel very, very good about the position.\\n\\nAnd then, of course, we are taking the underlying system services across that entire stack that I just talked about, making it available in Azure, right? So you have the raw infrastructure if you wanted. You have the model layer independent of it. You have the AI app server in Azure AI, right? So everything is also a building block service in Azure for you to be able to build. In fact, if you want to build everything that we have built in the Copilot stack, you can build it yourself using the AI platform.\\n\\nSo that's sort of, in simple terms, our strategy, and that's kind of how it all comes together.\\n\\n**Raimo Lenschow** -- *Analyst*\\n\\nOK. Perfect. Very clear.\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\nThanks, Raimo. Operator, we have time for one last question.\\n\\n**Operator**\\n\\nAnd the last question will come from the line of Rishi Jaluria with RBC. Please proceed.\\n\\n**Rishi Jaluria** -- *Analyst*\\n\\nWonderful. Thanks. Hi, Satya. Hi, Amy.\\n\\nAppreciate the question. I want to go and think a little bit about Copilot, how we should be thinking about kind of numbers here with the recategorization. It seems like that was maybe softer in the past than expected or maybe with the numbers this quarter starting to pick up. Can you maybe walk us through what you're seeing on that and maybe more importantly, how we should be thinking about your overall AI strategy on consumer versus enterprise, especially now with Moustafa on the fold?\\n\\n**Satya Nadella** -- *Chair and Chief Executive Officer*\\n\\nYes. On the first part, Rishi, to your question, I think we feel very, very good about the momentum we have in the commercial Copilot, right? As I said in my remarks and Amy talked about, this is the fastest growth of a new suite in M365. If I compare it to what we saw even back -- way back in E3 or E5 or the transition from O to M, this is really much faster, right? It's the numbers of penetration of the Fortune 500 and then the fact that they're coming back for more seats and what have you. So it's very strong in that context.\\n\\nThe other thing I'd also mention is that we want this to be something that is systemic, right, because people need to be able to put the security controls. Then they need to deploy. Then there's skilling, and then there's change management. So this is not like you just -- it's not a tool.\\n\\nLike when I talk about Copilot, Copilot Studio, agents, it's really as much about a new way to work. And sometimes I describe it as what happened throughout the '90s with PC penetration. After all, if you take a business process like forecasting, what was it like pre email and Excel and post email and Excel? That's the type of change that you see with Copilot. But overall, we feel great about the rate of progress and the penetration.\\n\\nAnd then on the consumer side, look, for us, the exciting part here is to be able to use the same investment we are making in the commercial where we have structural strength and then beyond the offense. One of the things that, I think, I hope you all catch in our earnings is ex TAC. Our revenue, when it comes to what we describe as search, news, and ads, is growing faster than market. So that's -- it's fantastic to see that.\\n\\nAnd so that's kind of our consumer business, which in Microsoft's large scope, it's sort -- even a $10-plus billion business sort of sometimes go missing. But in our case, it is actually a fantastic growth business that's growing faster than market. We feel good about how we will use AI in LinkedIn. In fact, LinkedIn is a consumer business as you know.\\n\\nYou saw even this week, they announced some new capabilities for both consumers and in their case, even recruiting. So we think that AI, the same investment gets monetized even through LinkedIn's innovation. And gaming, of course, is another place where you'll see some of these things apply and Windows, right? So the place where I think I'm excited about is Copilot+ PCs. For us, it's not about having a disconnected edge.\\n\\nIt's about having hybrid AI where the rebirth of sort of the PC as the edge of AI is going to be one of the most exciting things for developers. So we feel well positioned, quite frankly, with the same investment. So this is -- that's the thing. We're not a conglomerate here.\\n\\nWe are sort of one company. That means we invest once, and then we have all these categories that benefit from that. And that's the theory of the firm for us. And so we feel good about all of that coming together.\\n\\n**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\\n\\nAnd maybe just to add one piece because I think, Rishi, now that I'm listening and thinking through the question, it feels like you're wondering, like why am I not seeing the Copilot, if you've made all this progress and the results, and the answer is you already are. In that M365 commercial number, we've seen that seat growth, but those seats that we're adding, the majority of them are driven by frontline worker and small businesses. Those have a lower ARPU point. And so it masks some of the ARPU that we're already seeing not just from E5, which continues to contribute, but also this quarter, additional impact from Copilot.\\n\\nSo as we go forward, being able -- that is where you're going to see the impact will be in ARPU in M365 commercial, and as Satya said, I think you'll see the impact of Copilot engagement, frankly, across the same ex TAC number.\\n\\n**Rishi Jaluria** -- *Analyst*\\n\\nOK. Wonderful. Thank you.\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\nThanks, Rishi. That wraps up the Q&A portion of today's earnings call. Thank you for joining us today, and we look forward to speaking with all of you again soon.\\n\\n**Operator**\\n\\n[Operator signoff]\\n\\n**Duration: 0 minutes**\\n\\n## Call participants:\\n\\n**Brett Iversen** -- *Vice President, Investor Relations*\\n\\n**Satya Nadella** -- *Chair and Chief Executive Officer*\\n\\n**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\\n\\n**Keith Weiss** -- *Analyst*\\n\\n**Brent Thill** -- *Analyst*\\n\\n**Amy Hood** -- *Executive Vice President, Chief Financial Officer*\\n\\n**Mark Moerdler** -- *Analyst*\\n\\n**Karl Keirstead** -- *Analyst*\\n\\n**Kash Rangan** -- *Analyst*\\n\\n**Mark Murphy** -- *Analyst*\\n\\n**Raimo Lenschow** -- *Analyst*\\n\\n**Rishi Jaluria** -- *Analyst*\\n\\n[More MSFT analysis](https://www.fool.com/quote/msft)\\n\\n[All earnings call transcripts](https://www.fool.com/earnings-call-transcripts/)\\n\\n*This article is a transcript of this conference call produced for The Motley Fool. While we strive for our Foolish Best, there may be errors, omissions, or inaccuracies in this transcript. As with all our articles, The Motley Fool does not assume any responsibility for your use of this content, and we strongly encourage you to do your own research, including listening to the call yourself and reading the company's SEC filings. Please see our* [*Terms and Conditions*](https://www.fool.com/legal/terms-and-conditions/fool-rules) *for additional details, including our Obligatory Capitalized Disclaimers of Liability.*\\n\\n*The Motley Fool has positions in and recommends Microsoft. The Motley Fool recommends the following options: long January 2026 $395 calls on Microsoft and short January 2026 $405 calls on Microsoft. The Motley Fool has a [disclosure policy](https://www.fool.com/legal/fool-disclosure-policy/).*\\n\\n\\n\\nThis website uses cookies and other tracking technologies to enhance user experience and to analyze performance and traffic on our website. We also share information about your use of our site with our social media, advertising and analytics partners. If we have detected an opt-out preference signal then it will be honored. Further information is available in our [Privacy Policy](https://www.fool.com/legal/privacy-statement/)\"},\n",
              " {'title': 'Earnings call transcript: Microsoft Q1 2025 earnings beat ...',\n",
              "  'url': 'https://www.investing.com/news/transcripts/earnings-call-transcript-microsoft-q1-2025-earnings-beat-expectations-stock-surges-93CH-4015220',\n",
              "  'content': 'Amy Hood, Chief Financial Officer, Microsoft: Thank you, Satya, and good afternoon, everyone. This quarter revenue was $70,100,000,000 up 1315% in constant currency. Gross margin dollars increased 1113% in constant currency, while operating income increased 1619% in constant currency. And earnings per share was $3.46 an increase of 1819% in constant currency. Results exceeded expectations driven by focused execution from our sales and partner teams. [...] Next, the Intelligent Cloud segment. Revenue was $26,800,000,000 and grew 2122% in constant currency ahead of expectations driven by Azure. In Azure and other cloud services revenue grew 3335% in constant currency including 16 points from AI services. Focused execution drove non AI services results where we saw accelerated growth in our enterprise customer segment as well as some improvement in our scale motions. And in Azure AI services we brought capacity online faster than expected. [...] We continue to see strong demand for our cloud and AI offerings as they help customers drive productivity, increase efficiencies and grow their businesses. And again this quarter revenue from our AI business was above expectations. Commercial bookings increased 1817% in constant currency significantly ahead of expectations again this quarter driven by an Azure commitment from OpenAI. We also saw consistent execution across our core annuity sales motions and continued long term commitments to',\n",
              "  'score': 0.9558869,\n",
              "  'raw_content': '# Earnings call transcript: Microsoft Q1 2025 earnings beat expectations, stock surges\\n\\n[Transcripts](https://www.investing.com/news/transcripts)\\n\\nPublished 04/30/2025, 06:38 PM\\n\\nEarnings call transcript: Microsoft Q1 2025 earnings beat expectations, stock surges\\n\\n[View all comments (0)0](#comments-4015220)\\n\\n© Reuters.\\n\\n[MSFT\\n\\n0.23%](https://www.investing.com/equities/microsoft-corp)\\n\\nMicrosoft Corporation, with its impressive $2.93 trillion market capitalization, reported its fiscal Q1 2025 earnings, surpassing analysts’ expectations with an earnings per share (EPS) of $3.46 against a forecast of $3.23. The company’s revenue reached $70.1 billion, exceeding the anticipated $68.53 billion. Trading at a P/E ratio of 31.34x, Microsoft shares rose 7.92% in aftermarket trading, closing at $426.57.\\n\\n[InvestingPro](https://www.investing.com/pro/MSFT) analysis reveals 12 key investment tips for Microsoft, including its 19-year streak of dividend increases and strong financial health metrics. Subscribers can access the complete analysis in the comprehensive Pro Research Report, available exclusively on InvestingPro.\\n\\n## **Key Takeaways**\\n\\n* Microsoft reported a significant earnings beat, with EPS of $3.46 compared to a forecast of $3.23.\\n* The company’s revenue of $70.1 billion surpassed expectations, driven by strong cloud and AI service demand.\\n* Microsoft shares surged 7.92% in aftermarket trading, reflecting positive investor sentiment.\\n* Microsoft Cloud revenue grew by 20-22% in constant currency, highlighting robust growth.\\n* The company introduced major innovations, including the Majorana One quantum computing initiative.\\n\\n## **Company Performance**\\n\\nMicrosoft demonstrated strong performance in the first quarter of 2025, with a notable increase in revenue and earnings per share. The company’s focus on cloud and AI services contributed significantly to its growth, aligning with broader industry trends. Microsoft’s strategic investments in data centers and AI capabilities have positioned it as a leader in the tech sector.\\n\\n## **Financial Highlights**\\n\\n* Revenue: $70.1 billion, up 13.15% in constant currency\\n* Earnings per share: $3.46, up 18.19% in constant currency\\n* Gross margin: Increased by 11.13% in constant currency\\n* Operating income: Rose by 16.19% in constant currency\\n* Microsoft Cloud revenue: $42.4 billion, with a growth rate of 20-22%\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\n## **Earnings vs. Forecast**\\n\\nMicrosoft’s actual EPS of $3.46 exceeded the forecast of $3.23, representing a surprise of approximately 7.12%. Revenue also surpassed expectations, with actual figures of $70.1 billion compared to a forecast of $68.53 billion. This earnings beat marks a continuation of Microsoft’s trend of outperforming analyst expectations, driven by strong cloud and AI demand.\\n\\n## **Market Reaction**\\n\\nFollowing the earnings announcement, Microsoft’s stock experienced a significant increase of 7.92% in aftermarket trading, closing at $426.57. This surge reflects investor confidence in the company’s growth prospects, particularly in cloud and AI services. The stock remains within its 52-week range, with a high of $468.35 and a low of $344.79. Analyst consensus is strongly bullish, with price targets ranging from $415 to $650.\\n\\nBased on [InvestingPro](https://www.investing.com/pro/MSFT)’s Fair Value analysis, Microsoft currently appears to be trading near its Fair Value. For deeper insights into valuation metrics and comprehensive analysis, investors can access the full Pro Research Report.\\n\\n## **Outlook & Guidance**\\n\\nLooking ahead, Microsoft anticipates continued growth in cloud and AI services, despite potential AI capacity constraints beyond June. The company expects its Q4 Microsoft Cloud gross margin to be around 67% and plans to moderate its capital expenditure growth rate. These strategic initiatives aim to sustain Microsoft’s competitive edge in the tech industry.\\n\\n## **Executive Commentary**\\n\\nSatya Nadella, CEO of Microsoft, emphasized the transformative role of cloud and AI, stating, \"Cloud and AI are the essential inputs for every business to expand output, reduce costs and accelerate growth.\" Nadella also highlighted the company’s focus on innovation, saying, \"We are rapidly innovating opportunity across both consumer and commercial businesses.\"\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\n## **Risks and Challenges**\\n\\n* Potential AI capacity constraints may impact service delivery and growth.\\n* Economic uncertainties, including potential recession risks, could affect customer spending.\\n* Increased competition in cloud services from other tech giants may pressure market share.\\n* Regulatory challenges in different regions could impact operations and expansion plans.\\n* Supply chain disruptions may affect hardware and infrastructure development.\\n\\n## **Q&A**\\n\\nDuring the earnings call, analysts inquired about Microsoft’s data center strategy and capacity planning, as well as the growth of AI workloads and infrastructure scaling. The company addressed concerns about its resilience to potential economic downturns and highlighted the performance of non-AI Azure services. These insights underscored Microsoft’s strategic focus on sustaining growth and innovation.\\n\\n## **Full transcript - Microsoft Corporation (MSFT) Q3 2025:**\\n\\n**Conference Operator**: Greetings, and welcome to the Microsoft Fiscal Year twenty twenty five Third Quarter Earnings Conference Call. At this time, all participants are in a listen only mode. A question and answer session will follow the formal presentation. As a reminder, this conference is being recorded. It is now my pleasure to introduce Jonathan Nielsen, Vice President of Investor Relations.\\n\\nPlease go ahead.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Good afternoon, and thank you for joining us today. On the call with me are Satya Nadella, Chairman and Chief Executive Officer Amy Hood, Chief Financial Officer Alex Jolla, Chief Accounting Officer and Keith Dolliver, Corporate Secretary and Deputy General Counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today’s call and provides the reconciliation of differences between GAAP and non GAAP financial measures. More detailed outlook slides will be available on the Microsoft Investor Relations website when we provide outlook commentary on today’s call. On this call, we will discuss certain non GAAP items.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nThe non GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP. They are included as additional clarifying items to aid investors in further understanding the company’s third quarter performance in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year, unless otherwise noted. We will also provide growth rates in constant currency when available as a framework for assessing how our underlying business performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rates only.\\n\\nWe will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today’s call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website. During this call, we will be making forward looking statements, which are predictions, projections or other statements about future events.\\n\\nThese statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today’s earnings press release, in the comments made during this conference call and in the Risk Factors section of our Form 10 ks, Forms 10 Q and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward looking statement. And with that, I’ll turn the call over to Satya.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Thank you, Jonathan. It was a record quarter driven by continued strength of Microsoft Cloud, which surpassed $42,000,000,000 in revenue, up 22% in constant currency. Cloud and AI are the essential inputs for every business to expand output, reduce costs and accelerate growth. Now I’ll highlight examples starting with infrastructure. We continue to expand our data center capacity.\\n\\nThis quarter alone, we opened DCs in 10 countries across four continents. Model capabilities are doubling in performance every six months, thanks to multiple compounding scaling laws. We continue to optimize and drive efficiencies across every layer from DC design to hardware and silicon to system software to model optimization all towards lowering costs and increasing performance. You see this in our supply chain where we have reduced dock to lead times for new GPUs by nearly 20% across our blended fleet where we have increased AI performance by nearly 30% ISO power and our cost per token, which is more than halved. When it comes to cloud migrations, we saw accelerating demand with customers in every industry from Abercrombie and French to Coca Cola and ServiceNow, expanding their footprints on Azure.\\n\\nAnd we remain the cloud of choice for customers’ mission critical VMware, SAP and Oracle workloads with more regional availability than any other hyperscaler. We’re also excited about the next frontier in cloud systems with Quantum. In addition to putting our Quantum stack on machines from our partners, we’re also making real progress on a path to a utility scale quantum computer with the introduction of Majorana One. When it comes to data and analytics, we have deeply integrated our AI platform with our data stack. PostgreSQL usage accelerated for the third consecutive quarter and it is now used by nearly 60% of the Fortune 500, including companies like BMW and BNY Mellon.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nCosmos DB revenue growth also accelerated again this quarter and remains the go to database for globally distributed NoSQL workloads at any scale. It is used by customers in every industry like CarMax, DocuSign, NTT Data and OpenAI. This quarter, we also saw analytics consumption accelerate. Microsoft Fabric has more than 21,000 paid customers, up 80% year over year. Fabric brings together data workloads like data warehousing, data science, real time intelligence along with Power BI into one end to end solution.\\n\\nReal time intelligence is now the fastest growing workload in fabric with 40% of customers already using it in just five months since becoming generally available. All up more than 50% of fabric customers like AmorePacific, Louisiana State Government and Petrobras use three or more workloads. And the amount of data in our multi cloud data lake, OneLake has grown more than 6x over the past year. Now on to AI Platform and Tools. Foundry is the agent in AI app factory.\\n\\nIt’s now used by developers at over 70,000 enterprises and digital natives from Atomic Work to Epic, Fujitsu and Gainsight to H and R Block and LG Electronics to design, customize and manage their AI apps and agents. We processed over 100,000,000,000,000 tokens this quarter, up 5x year over year, including a record 50,000,000,000,000 tokens last month alone. And four months in, over 10,000 organizations have used our new agent service to build, deploy and scale their agents. This quarter, we also made a new suite of fine tuning tools available to customers with industry leading reliability. And we brought the latest models from OpenAI along with new models from Cohere, DeepSeek, Meta, Mistral, Stability to Foundry.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nAnd we’ve expanded our PHY family of SLMs with new multimodal and mini models. All up PHY has been downloaded 38,000,000 times. And our research teams are taking it one step further with BitNet B1.58, a billion parameter large language model that can run on just CPUs coming to the foundry. Now on to developer tools. We are evolving GitHub Copilot from pair to peer programmer.\\n\\nWith agent mode in Versus Code, Copilot can now iterate on code, recognize errors and fix them automatically. This adds to other Copilot agents like AutoFix, which helps developers remediate vulnerabilities as\\n\\n**Conference Operator**: well\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: as Code Review Agent, which has already reviewed over 8,000,000 pull requests. And we are previewing a first of its kind SWE Agent capable of synchronously executing developer tasks. All up, we now have over 15,000,000 GitHub Copilot users up over 4x year over year. And both digital natives like Twilio and enterprises like Cisco, HPE, Skyscanner and Target continue to choose GitHub Copilot to equip their developers with AI throughout the entire dev life cycle. With Visual Studio and Versus Code, we have the world’s most popular editor with over 50,000,000 monthly active users.\\n\\nAnd with Power Platform, we have the leading low code platform for AI makers too. We now have 56,000,000 monthly active Power Platform users, up 27% year over year, who increasingly use our AI features to build apps and automate processes. Now on to future of work. Microsoft three sixty five Copilot is built to facilitate human agent collaboration. Hundreds of thousands of customers across geographies and industries now use Copilot, up 3x year over year.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nOur overall deal size continues to grow and this quarter we saw a record number of customers returning to buy more seats. And we are going further. Just last week, we announced a major update bringing together agents, notebooks, search and create into a new scaffolding for work. Our new researcher and analyst deep reasoning agents analyze vast amounts of web and enterprise data to deliver highly skilled expertise on demand directly within Copilot. Beyond horizontal knowledge work, we are introducing agents for every role and business process.\\n\\nOur sales agent turns contacts into qualified leads and with Sales Chat reps can quickly get up to speed on new accounts and our customer service agent is deflecting customer inquiries and helping service reps resolve issues faster. With Copilot Studio, customers can extend Copilot and build their own agents with no code, low code. More than 230,000 organizations including 90% of the Fortune 500 have already used Copilot Studio. With deep reasoning and agent flows in Copilot Studio, customers can build agents that perform more complex tasks and also handle deterministic scenarios like document processing and financial approvals. And they can now build computer use agents that take action on the UI across desktop and web apps.\\n\\nAnd with just a click they can turn any SharePoint site into an agent too. This quarter alone customers created over 1,000,000 custom agents across SharePoint and Copilot Studio, up 130 quarter over quarter. When it comes to business applications, Dynamics three sixty five again took share as companies like Avaya, Brunswick, Softcat switched to Dynamics from legacy providers. Verizon for example chose Dynamics three sixty five sales to improve the efficiency of its sellers. In Healthcare, Dragon Co Pilot is off to a fast start.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nLast quarter alone we helped document nearly 9,500,000 physician patient encounters at providers like City of Hope, Ottawa Hospital, Tufts Medicine and Wellstar up over 50% quarter over quarter. In manufacturing, we introduced factory operations and safety agents at Hanover Massay and leading partners like Autodesk, PTC and Siemens have all built their own industrial AI solutions on our stack. And in retail, we have introduced agents to help customers like Bath and Body Works build more personalized shopping experience and improve store operations. When it comes to Windows Copilot plus PCs are faster and have better battery life than any other device in their category. We also continue to win new customers with best in class AI capabilities.\\n\\nWe offer a growing number of AI apps from partners like Adobe, Canva and Zoom. Just last week, we rolled out exclusive AI experiences like Recall, Click to Do and Windows Search to all Copilot plus PCs. And we continue to see increased commercial traction as we approach end of support for Windows 10. Windows 11 commercial deployments increased nearly 75% year over year. Now on to security.\\n\\nSecurity is our top priority and we have made significant progress against the engineering objectives we outlined a year and a half ago as part of our Secure Future initiative. We are now applying these learnings to deliver new innovation across our platform. Last month along with our partners, we introduced security copilot agents to help defenders autonomously handle high volume security and IT tasks informed by 84,000,000,000,000 daily threat signals. We also added new capabilities to Defender, Entra and Purview to help organizations secure and govern their AI deployments. All up, we now have 1,400,000 secondurity customers, over 900,000 including Global, ManpowerGroup, TriNet, Regions Bank have four or more workloads, up 21% year over year.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nAnd in Identity, Entra now has more than 900,000,000 monthly active users. Now on to our consumer businesses, starting with LinkedIn. Over 1,000,000,000 professionals use LinkedIn to connect, learn, hire and sell and our membership continues to grow at double digits year over year. Time spent watching videos on the platform was up 36% and comments were up 32% year over year. We’re also seeing more members use AI to gain new skills and find jobs.\\n\\nThe number of learners who have used AI powered coaching increased over 2x quarter over quarter. And we remain the market leader in hiring as customers like Equinix and Verizon use LinkedIn hiring assistance to find qualified candidates faster. When it comes to LinkedIn Premium, we saw over 75% quarter over quarter subscriber growth to our Premium Pages offering for SMBs. And LinkedIn marketing solution continues to be the best way to reach B2B decision makers with two consecutive quarters of accelerated revenue growth. More broadly, when it comes to advertising, we are transforming how people search, browse, discover content and use AI as a personal assistant.\\n\\nWith Copilot Search in Bing, we are reimagining search results with overview pages curated by AI and embedded conversational capabilities. With Copilot Vision and Edge, Copilot sees what you see and gives you real time responses while you browse. With Copilot Discover, we are personalizing experience based on user interactions and preferences. And with our updated Copilot app, we are focused on building daily engagement and successful sessions across a range of modalities, whether it is conversing, searching, shopping or travel planning. All up, we again took share across Bing and Edge and our total advertising revenue across our businesses has surpassed $20,000,000,000 over the past twelve months.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nNow on to Gaming. We continue to transform the business and focus on margin expansion as we bring our games to over 500,000,000 monthly active users across devices. We ended the quarter as the top publisher by pre orders and pre installs on both Xbox and PlayStation Store. PC Game Pass revenue increased over 45% year over year with Xbox Play Anywhere players now can access more than 1,000 games they can play across console and PC. And just last week, we brought cloud gaming to LG TVs.\\n\\nCloud gaming set a new record surpassing 150,000,000 hours played for the first time this quarter. We are also integrating AI across the Xbox. New Copilot for Gaming is a personalized gaming companion that provides in game assistant and expert coaching and our first of its kind Muse model can generate gameplay in real time. Finally, it’s fantastic to see the success of the Minecraft movie, which is the top grossing film of the year. In addition to monetizing our IP in new ways, we have seen a 75% plus increase in weekly active users of the game year over year since the release.\\n\\nIn closing, we are rapidly innovating opportunity across both consumer and commercial businesses. In just a few weeks at our BUILD conference, we’ll share how we are creating the most powerful AI platform for developers and I encourage you to tune in. With that, let me turn it over to Amy.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\n**Amy Hood, Chief Financial Officer, Microsoft**: Thank you, Satya, and good afternoon, everyone. This quarter revenue was $70,100,000,000 up 1315% in constant currency. Gross margin dollars increased 1113% in constant currency, while operating income increased 1619% in constant currency. And earnings per share was $3.46 an increase of 1819% in constant currency. Results exceeded expectations driven by focused execution from our sales and partner teams.\\n\\nWe continue to see strong demand for our cloud and AI offerings as they help customers drive productivity, increase efficiencies and grow their businesses. And again this quarter revenue from our AI business was above expectations. Commercial bookings increased 1817% in constant currency significantly ahead of expectations again this quarter driven by an Azure commitment from OpenAI. We also saw consistent execution across our core annuity sales motions and continued long term commitments to our platform. Commercial remaining performance obligation increased to $315,000,000,000 up 3433% in constant currency.\\n\\nRoughly 40% will be recognized in revenue in the next twelve months up 17% year over year. The remaining portion recognized beyond the next twelve months increased 47%. And this quarter our annuity mix was 98%. FX was roughly in line with expectations on total company revenue, segment level revenue and operating expense growth. FX decreased COGS growth by only one point, one point unfavorable to expectations.\\n\\nMicrosoft Cloud revenue was $42,400,000,000 ahead of expectations and grew 2022% in constant currency. Microsoft Cloud gross margin percentage was 69% in line with expectations and decreased three points year over year driven by the impact of scaling our AI infrastructure. Company gross margin percentage was also 69% down one point year over year driven by scaling our AI infrastructure. Operating expenses increased 23% in constant currency lower than expected due to our focus on cost efficiencies as well as investments that shifted to Q4. Operating margins increased one point year over year to 46% better than expected as we continue to focus on building high performing teams and increasing our agility by reducing layers with fewer managers.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nAt a total company level, headcount at the March was 2% higher than a year ago and was down slightly compared to last quarter. Now to our segment results. Revenue from Productivity and Business Processes was $29,900,000,000 and grew 1013% in constant currency ahead of expectations driven by LinkedIn, Microsoft three sixty five Commercial Products and Microsoft three sixty five Consumer. M365 Commercial Cloud revenue increased 1215% in constant currency in line with expectations. ARPU growth was again driven by E5 and M365 Copilot.\\n\\nWith M365 Copilot, we continue to see growth across customer segments and geos. Paid M365 commercial seats grew 7% year over year to over $430,000,000 While we continue to see installed base expansion across all customer segments growth was primarily driven by our small and medium business and frontline worker offerings. M365 commercial products revenue increased 58% in constant currency ahead of expectations due to higher than expected office transactional purchasing. M365 consumer cloud revenue increased 1012% in constant currency ahead of expectations driven by higher than expected subscription growth following the January price increase. M365 consumer subscriptions grew 9% to $87,700,000 LinkedIn revenue increased seven percent and eight percent in constant currency.\\n\\nResults were ahead of expectations due to better than expected performance across all businesses. The Talent Solutions business continues to be impacted by weakness in the hiring market. Dynamics three sixty five revenue increased 1618% in constant currency in line with expectations with continued growth across all workloads. Segment gross margin dollars increased 1013% in constant currency and gross margin percentage was relatively unchanged year over year even with the impact of scaling our AI infrastructure. Operating expenses increased 12% in constant currency and operating income increased 1518% in constant currency.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nNext, the Intelligent Cloud segment. Revenue was $26,800,000,000 and grew 2122% in constant currency ahead of expectations driven by Azure. In Azure and other cloud services revenue grew 3335% in constant currency including 16 points from AI services. Focused execution drove non AI services results where we saw accelerated growth in our enterprise customer segment as well as some improvement in our scale motions. And in Azure AI services we brought capacity online faster than expected.\\n\\nIn our on premises server business revenue decreased 64% in constant currency slightly below expectations driven by renewals with lower in period revenue recognition from the mix of contracts. The year over year decline is reflective of the continued customer shift to cloud offerings. Enterprise and Partner Services revenue increased 56% in constant currency slightly ahead of expectations due to better than expected performance in Enterprise Support Services. Segment gross margin dollars increased 1314% in constant currency and gross margin percentage decreased four points year over year driven by scaling our AI infrastructure. Operating expenses increased 67% in constant currency and operating income grew 1718% in constant currency.\\n\\nNow to more personal computing. Revenue was $13,400,000,000 and grew six percent and seven percent in constant currency ahead of expectations due to better than expected results across all businesses. Windows OEM and devices revenue increased 3% year over year ahead of expectations as tariff uncertainty through the quarter resulted in inventory levels that remained elevated. Search and news advertising revenue ex TAC increased 2123% in constant currency. Results were significantly ahead of expectations driven by usage from a third party partnership, better than expected rate expansion and volume growth across Edge and Bing.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nAnd in gaming, revenue increased 56% in constant currency. Xbox content and services revenue increased 89% in constant currency ahead of expectations driven by stronger than expected performance in third party and first party content. Segment gross margin dollars increased 911% in constant currency. Gross margin percentage increased two points year over year driven by strong execution on margin improvement in Search and Gaming. Operating expenses increased 1%.\\n\\nOperating income increased 2123% in constant currency driven by continued prioritization of higher margin opportunities. Now back to total company results. Capital expenditures including finance leases were $21,400,000,000 slightly lower than expected due to normal variability from the timing of delivery of data center leases. Cash paid for PP and E was $16,700,000,000 roughly half of our cloud and AI related spend was on long lived assets that will support monetization over the next fifteen years and beyond. The remaining cloud and AI spend was primarily for servers both CPUs and GPUs to serve customers based on demand signals including our customer contracted backlog of $315,000,000,000 Cash flow from operations was $37,000,000,000 up 16% driven by strong cloud billings and collections partially offset by higher tax payments.\\n\\nAnd this quarter free cash flow was $20,300,000,000 Other income and expense was negative $623,000,000 more favorable than anticipated primarily due to net gains on derivatives and investments. Our losses on investments accounted for under the equity method were slightly higher than expected. Our effective tax rate was approximately 18%. And finally, we returned $9,700,000,000 to shareholders through dividends and share repurchases, an increase of 15% year over year. Now moving to our Q4 outlook, which unless specifically noted otherwise is on a U.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nS. Dollar basis. First, through April demand signals across our commercial businesses as well as in LinkedIn, gaming and search have remained consistent. Our outlook assumes those trends continue in Q4. If the environment changes, our results may be impacted.\\n\\nIn our Windows OEM business, our outlook assumes the elevated inventory levels from Q3 will come down in Q4. We have widened our guidance range in our More Personal Computing segment to account for some of this variability. Next, FX. With the weakening of the U. S.\\n\\nDollar in April, we now expect FX to increase total revenue growth by one point. Within the segments, we expect FX to increase revenue growth by one point in Productivity and Business Processes and less than one point in Intelligent Cloud and More Personal Computing. We expect FX to increase COGS operating expense growth by less than one point. In Commercial Bookings, we expect solid growth on a significant prior year comparable and a growing ex pre base. Bookings growth will be driven by strong execution across our core annuity sales motions and continued long term commitments to our platform.\\n\\nAs a reminder, larger longer term Azure contracts which are more unpredictable in their timing can drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 67% down year over year primarily driven by the impact of scaling our AI infrastructure. And now capital expenditures. We expect Q4 capital expenditures to increase on a sequential basis. H2 CapEx in total remains unchanged from our January guidance.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nAs a reminder, there can be quarterly spend variability from cloud infrastructure build outs and the timing of delivery of finance leases. Next to segment guidance. In Productivity and Business Processes, we expect revenue of US32.05 billion dollars to US32.35 billion dollars or growth of 11% to 12% in constant currency. M365 Commercial Cloud revenue growth should be approximately 14% in constant currency relatively stable compared to the prior quarter. We expect continued ARPU growth through E5 and M365 Copilot and some seat growth moderation given the size of the installed base.\\n\\nM365 Commercial Products revenue growth should be in the mid single digits. As a reminder, M365 Commercial Products includes both the Windows commercial on premises components of M365 suites and Office transactional purchasing both of which can be variable due to end period revenue recognition dynamics. M365 Consumer Cloud revenue growth should be in the mid teens driven by the January price increase. For LinkedIn, we expect revenue growth in the high single digits. And in Dynamics three sixty five, we expect revenue growth to be in the mid to high teens with continued growth across all workloads.\\n\\nFor Intelligent Cloud, we expect revenue of $28,750,000,000 to $29,050,000,000 or growth of 20 to 22% in constant currency. Revenue will continue to be driven by Azure which as a reminder can have quarterly variability primarily from in period revenue recognition depending on the mix of contracts. In Azure, we expect Q4 revenue growth to be between 3435% in constant currency driven by strong demand for our portfolio of services. In our non AI services, we expect focused execution to continue driving healthy growth. And in our AI services, while we continue to bring data center capacity online as planned, demand is growing a bit faster.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nTherefore, we now expect to have some AI capacity constraints beyond June. In our on premises server business, we again expect revenue to decline in the mid single digits with the ongoing customer shift to cloud offerings. And the Enterprise and Partner Services, we expect revenue growth to be in the mid to high single digits driven by Enterprise Support Services. In More Personal Computing, we expect revenue to be $12,350,000,000 to $12,850,000,000 Windows OEM and devices revenue should decline in the mid to high single digits. We expect Windows OEM revenue to decline in the low to mid single digits assuming OEM inventory levels come down through the quarter as noted earlier.\\n\\nAlthough the range of potential outcomes is wider than normal. Devices revenue should decline in the high teens. Search and news advertising ex TAC revenue growth should be in the high teens even on a strong prior year comparable. We expect to see continued growth in both volume and revenue per search with share gains across Edge and Bing. Overall search and news advertising revenue growth should be in the mid teens.\\n\\nAnd in gaming, we expect revenue growth to be in the mid single digits. We expect Xbox content and services revenue growth to be in the high single digits driven by first party content. Now back to company guidance. We expect COGS of 23,600,000,000.0 to $23,800,000,000 or growth of 19% to 20% in constant currency and operating expense of $18,000,000,000 to $18,100,000,000 or growth of approximately 5% in constant currency. Therefore, even with ongoing AI investments as we scale, we continue to expect full year FY 2025 operating margins expected to be roughly negative $1,200,000,000 primarily driven by investments accounted for under the equity method.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nAs a reminder, we do not recognize mark to market gains or losses on equity method investments. And lastly, we expect our Q4 effective tax rate to be approximately 19%. Now I’d like to share some closing thoughts as we look to the next fiscal year. We remain committed to investing against the strong demand signals we see for our services. So as a reminder, our earlier comments on FY 2026 capital expenditures remain unchanged.\\n\\nWe expect CapEx to grow. It will grow at a lower rate than FY 2025 and will include a greater mix of short lived assets, which are more directly correlated to revenue than long lived assets. These investments along with focused execution that delivers near term value to our customers will ensure we continue to lead through the cloud and AI opportunity ahead. With that, let’s go to Q and A, Jonathan.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thanks, Amy. We’ll now move over to Q and A.\\n\\n**Amy Hood, Chief Financial Officer, Microsoft**: Out of respect to others on the call,\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: we request that participants please only ask Operator, can you please repeat your instructions?\\n\\n**Conference Operator**: And our first question comes from the line of Keith Weiss with Morgan Stanley. Please proceed.\\n\\n**Keith Weiss, Analyst, Morgan Stanley**: Excellent. Thank you guys for taking the question and congratulations on a fantastic quarter. In what all of us are looking at as a difficult environment, a lot of uncertainty out there, so really impressive to put up the results that you guys did. One of the things that we heard a lot about this quarter in the media and press reports was changing data center commitments, maybe Microsoft walking away from some of those data center commitments. But it sounds like the AI demand is very strong.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nYou’re talking about not being able to hit all that demand with supply. So could you talk to us about what’s going on with your data center strategy? Are there any shifts taking place? And maybe in particular, Satya, you could talk about some of the comments that you had made about the potential risk for oversupply in GPUs out in the future. What exactly was that risk you were talking about?\\n\\nAnd are you incorporating that risk into your data center strategy?\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Yes. First of all, thanks, Keith, for the question. The reality is we’ve always been making adjustments to build, lease, what pace we build all through the last whatever, ten, fifteen years. It’s just that you all pay a lot more attention to what we do quarter over quarter nowadays. Having said that, the key thing for us is to have our build and lease be positioned for what is the workload growth of the future.\\n\\nRight? So that’s what you have to go and seek to. So there’s a demand part to it. There is the shape of the workload part to it and there is a location part So you don’t want to be upside down on having one big data center in one region when you have a global demand footprint.\\n\\nYou don’t want to be upside down when the shape of demand changes because after all with essentially pre training plus test time compute, that’s a big change in terms of how you think about even what is training, right, forget inferencing. So fundamentally given all of that and then every time that there’s great Moore’s Law, but remember this is a compounding sort of S curve, right, which is Moore’s Law, there’s system software, there’s model architecture changes, there’s the app server efficiency. Given all of that, we just want to make sure we’re building accounting for the latest and greatest sort of information we have on all of that. And that’s what you see reflected. And I feel very, very good about the pace.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nIn fact, Amy just mentioned, we will be short power. And so therefore but it’s not power it’s not a blanket statement. I need power in specific places so that we can either lease or build at the pace at which we want. And so that’s the sort of plan that we’re executing to. Maybe Amy, you can add\\n\\n**Amy Hood, Chief Financial Officer, Microsoft**: to that.\\n\\n**Unspecified Speaker**: Yes. Maybe just to add a little bit to Satya’s comments. Just a reminder, these are very long lead time decisions from land to build to build outs can be lead times of five to seven years, two to three years. So we’re constantly in a balancing position as we watch demand curves and many of the things Satya watched. And the second part is just to maybe remind you when Satya talks about being short power, he’s really talking about data center space.\\n\\nAnd so we’ve continued through the second half to put things in place. In fact, we talked a little bit about pulling even some of that space to be ready earlier and being able to deliver that earlier to customers this quarter, which is really good work by the teams as we continue to get more and more efficient at that process. And I look forward to being able to continue to do that in the future. I did talk about in my comments, we had hoped to be in balance by the end of Q4. We did see some increased demand, as you saw through the quarter.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nSo, we are going to be a little short, still stay a little tight as we exit the year, but are encouraged by that.\\n\\n**Keith Weiss, Analyst, Morgan Stanley**: Excellent. Thank you, guys.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thanks, Keith. Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Brent Thill with Jefferies. Please proceed.\\n\\n**Brent Thill, Analyst, Jefferies**: Thanks. Satya, on your comment about accelerating demand for cloud migrations, I’m curious if you could dig in and extrapolate a little more what you’re seeing there? Thank you.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Thanks, Brent. So yes, so I sort of think about three big things that are happening in the cloud all in parallel and there’s also a relationship between them. One is, I’ll just say the classic migration of whether it’s SQL, Windows Server. And so that sort of again got good steady state progress because the reality is, I think everyone’s now perhaps there’s another sort of kick in the data center migrations just because of the efficiency, the cloud provides. So that’s sort of one part.\\n\\nThe second piece is good data growth. You saw some like Postgres on Azure. I mean, forgetting even SQL Server, Postgres on Azure is growing, Cosmos is growing. The analytics stuff I talked about with Fabric. It’s even the others, whether it is Databricks or even Snowflake on Azure are growing.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nSo we feel very good about Fabric, growth and our data growth. Then the cloud native growth. So this is again before we even get to AI, some of the core compute consumption of cloud native players is also pretty very healthy. It was healthy throughout the quarter. We projected to go moving forward as well.\\n\\nThen the thing to notice is the ratio and I think we mentioned this multiple times before. If you look underneath even chat GPT, in fact that team does a fantastic job of thinking about not only their growth in terms of AI accelerators they need, they use Cosmos DB, they use Postgres, they use core compute and storage. And so there’s even a ratio between any AI workload in terms of AI accelerator to others. So those are the four pockets, I’d say, or four different trend lines which all have a relationship with each other. And if I step back, and Amy and I talk a lot about this, this time around there’s nothing certain for sure in the future except for one thing, which is our largest business is our infrastructure business.\\n\\nAnd the good news here is the next big platform shift builds on that. So it’s not a complete rebuild. Having gone through some of these platform shifts where you have to come out on the other side with a full rebuild. If there is good news here and is that we have a good business in Azure that continues to grow and the new platform depends on that. So we want to stay disciplined and execute super well on that.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thank you. Thanks, Brent. Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Mark Moerdler with Bernstein Research. Please proceed.\\n\\n**Mark Moerdler, Analyst, Bernstein Research**: Thank you very much for taking my question and I will reiterate what my peers have said. Congratulations on the great quarter. Satya and Amy, Microsoft is a very different business than it was during the last recession. Incredible job you’ve done. If we get into a recession, I hope we don’t, how do you think about the stability, the sustainability, revenue volatility of Microsoft today if we were to get into recession?\\n\\nWould the business react early to recession or late? Would a recession have a more shallow impact on revenue? Any thoughts would\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: be appreciated. Maybe I’ll start and then Amy should add, Mark. The way at least I think we will approach it is quite frankly be very focused on how we help our customers. If there is any turbulence in the macro. Because one of the things that we feel we can’t do just because of the efficiencies of the cloud And the footprint we have and the differentiated sort of layers of the stack from the SaaS application side to the infrastructure side.\\n\\nI think if you sort of buy into the argument that software is the most malleable resource we have to fight any type of inflationary pressure or any type of growth pressure where you need to do more with less, I think we can be super helpful in that. And so if anything, we would probably have more of that mindset is how do we make sure we are helping our customers. And then of course, we’ll look to share gains.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thanks, Mark. Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Karl Keirstead with UBS. Please proceed.\\n\\n**Brent Thill, Analyst, Jefferies**: Okay. Thanks. A number of metrics to applaud, but I think the one that stands out to me is the 16 growth rate lift to Azure from AI. Sachin, Amy, I\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: just wanted to ask if you\\n\\n**Brent Thill, Analyst, Jefferies**: could unpack that a little bit. Of course, you mentioned that you got a bit of a kicker from capacity coming online. But I’m a little bit more interested in where the demand came in above expectations, like what workload type. It’s hard for us to see that on the outside. Was it a surge in ChatGPT inference that landed in Azure?\\n\\nWas it an uptick in enterprise AI adoption? And Amy, do you think that 16 points could be higher in June? Thank you.\\n\\n**Unspecified Speaker**: Thanks, Carl, for the question. Just to provide some clarity, because I think your question implies something that we didn’t mean to imply on the call. First, the real outperformance in Azure this quarter was in our non AI business. So then to talk about the AI business, really what was better was precisely what we said. We talked about this.\\n\\nWe knew Q3 that we had really matched supply and demand pretty carefully and so didn’t expect to do much better than we had guided to on the AI side. We’ve been quite consistent on that. So the only real upside we saw on the AI side of the business was that we were able to deliver supply early to a number of customers. And being able to do that throughout the quarter creates quite a good benefit to us. But the majority of our outperformance versus where we had expected to be was on the non AI piece of the business.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thanks, Karl. Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Kash Rangan with Goldman Sachs. Please proceed.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Hi, thank you very much. One question for Amy. You’ve said in the past that you can attain better and better capital efficiency with the cloud business and probably cloud and AI business. Where do you stand today, Amy? Maybe, Satya, you can opine as well, that you’ve said before that you can slow down your CapEx growth rate while still accelerate Azure, which includes AI.\\n\\nCan we get a mark to market on that? Thank you so much.\\n\\n**Unspecified Speaker**: Maybe I’ll I’ll start, Kash, and let Satya add on. Because I really think when you go back and read some of Satya’s comments on how the s curves build on themselves, that’s actually the levers that go into the answer of the question that you’re asking. And so the way, of course, you’ve seen that historically is, right, when we went through the prior cloud transitions, you see CapEx accelerate, you build out data center footprints, you slowly fill CPU capacity. And over time, you see software efficiencies and hardware efficiencies build on themselves. And you saw that process for us for, goodness, now quite a long time.\\n\\nAnd what Tatya is talking about is how quickly that’s happening on the AI side of the business and you add to that model diversity. So think about the same levers plus model efficiency, those compound. Now the one thing that’s a little different this time is just the pace. And so when you’re seeing that happen, pace in terms of efficiency side, but also pace in terms of the build out, So it can mask some of the progress, but we are working hard across all of the teams, hardware, software, even the build teams to get things in place as quickly as possible, dock to live times. All of that is improving and all of that actually is benefiting us.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nAnd I’ll go ahead and say, our margins on the AI side of the business are better than they were at this point by far than when we went through the same transition and the server to cloud transition.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Yes. I mean, I think at a macro level, think the way to think about this is you can ask the question, what’s the difference between a hosting business and a hyperscale business? It’s software. That’s I think the gist of it. We asked for sure it’s a capital intensive business, but capital efficiency comes from that system wide software optimization.\\n\\nAnd that’s what makes the hyperscale business attractive and that’s what we want to just keep executing super well on. Super. Thanks so much.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Mark Murphy with JPMorgan. Please proceed.\\n\\n**Mark Murphy, Analyst, JPMorgan**: Thank you so much. Satya, you had commented recently that the DeepSeek moment is a real thing. And you had said that software efficiencies mean that the fleet will be aged for a longer time. Can you comment on how those advances are affecting the pace and volume of AI experimentation and activity in the marketplace? And Amy, could we start to consider the possibility that software enhancements might extend the useful life assumption that you’re using for GPUs?\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nOr is it a little premature to be thinking that way?\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Yeah. First of all, I think some of the work that actually OpenAI first pioneered and did with all of the reasoning models and of course DeepSeek has sort of added to it and done good work as well and others as well. The idea that you can have test time compute plus pre training and then some of the great optimization at inference time that has all happened has proven out. I mean if you look at it, I would say for every Moore’s law change and movement, there’s probably a 10x improvement because of software, right? That’s sort of what’s happening with these models.\\n\\nSome of it comes from model architecture, some of that comes from data efficiency, compute efficiency and what have you. So that’s what we are riding and we feel that all up when you have a commodity that is getting that better then the question is how do you build out a fleet that’s super balanced so that then the workloads can be built and can in fact take advantage of that efficiency at the underlying infrastructure. I mean it’s kind of like virtualization. What is the difference between servers and sort of again client server with virtualization? It was efficiency.\\n\\nWhat is the difference between virtualization and cloud? It was efficiency. What is the difference between this generation of cloud and AI? It’s efficiency. So the more you can kind of continue to think about software driving that efficiency is what drives demand ultimately.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\n**Unspecified Speaker**: And to your specific question, in terms of thinking about the depreciable life of an asset, we like to have a long history before we make any of those. We’re focused on getting every bit of useful life we can, of course, out of assets. But to Tatya’s point, that tends to be a software question more than a hardware one.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Thank you. Thanks, Mark.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Operator, next question please.\\n\\n**Conference Operator**: The next question comes from the line of Kirk Materne with Evercore ISI. Please proceed.\\n\\n**Kirk Materne, Analyst, Evercore ISI**: Yes, thanks very much and congrats on a great quarter. Amy, you mentioned that the upside in Azure came from the non AI services this time around. I was wondering if you could just talk a little bit more about that. And I guess as you look forward, maybe what’s different this go round versus what we saw a few years ago when obviously things like optimization weighed on the growth a little bit? It sounds like the product portfolio is much broader right now.\\n\\nBut just wondering if you could add some color on that front. Thank you.\\n\\n**Unspecified Speaker**: Sure. And thanks for the question, Kirk. When we go to non AI, I talked a little bit about this. In general, we saw better than expected performance across our segments, but we saw acceleration in our largest customers. We call that the enterprise segment in general.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nAnd then in what we talked about of our scale motions where we had some challenges in Q2, things were a little better. And we still have some work to do in our scale motions, and we’re encouraged by our progress. We’re excited to stay focused on that as, of course, we work through the final quarter of our fiscal year. By geo, the performance was pretty consistent. Satya actually highlighted some of the workloads that came in a little better than we thought.\\n\\nObviously, just some good consistent work on migrations, good execution by the sales and partner teams, the data workloads he went through. And so in general, Kirk, I wouldn’t say it’s anything beyond that. I do think it was improved execution, And I was happy to see it, but there’s still some work to do on our scale motions in particular. Thank you.\\n\\n**Satya Nadella, Chairman and Chief Executive Officer, Microsoft**: Thanks, Kirk.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Operator, we have time for one last question.\\n\\n**Conference Operator**: The last question will come from the line of Alex Zukin with Wolfe Research. Please proceed.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**0: Hey, guys. Thanks for squeezing me in. And again, just amazing congratulations on those Azure numbers, which I think are quite honestly just inspiring. So so maybe to Amy, to to the point that you’re making that the surprise factor was on the non Azure, non AI side of the house. And and it sounds like that there’s confidence in that continuing, beyond.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nHow much of that are you starting to see the pull pull in of the non AI driven by the AI portion of Azure? And on the AI portion specifically, as test time compute really just blows out kind of prior conceptions of scaling law challenges, how much does that change potentially the curve of the AI Azure growth as you go forward here over the next few quarters?\\n\\n**Unspecified Speaker**: Hi, Doc. Let me, first of all, say I think we’ve talked about this quite a bit. It’s always good to have a chance to to iterate this. It’s getting harder and harder to separate what an AI workload is from a non AI workload. And we’ve talked about it this way, I think, in most instances, to make sure people understood that when we were accelerating all of our CapEx spend over the past two point five three years now, that people had confidence that we were turning that into revenue and product in a way that was transparent and that everyone could understand really the goals that we had set for ourselves and for our partners and customers in terms of building product that turned to Revit.\\n\\nBut\\n\\n**Amy Hood, Chief Financial Officer, Microsoft**: if you take a\\n\\n**Unspecified Speaker**: step back from that, it’s that these workloads are being built, GPU, CPU, storage, network, all the same things. And so I think, really, what we’re talking about is really how Satya talked about in one of the earlier questions. You know, we’re seeing digital natives. Digital natives build workloads. They do AI work.\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\nThey do non AI work. Do they tend to do that work in the same cloud? Lots of times. Sometimes, it’s all in the same place. Not all the time, but that relationship gets stronger and stronger as people pivot to more of AI heavy workloads.\\n\\nAnd so I think you’re starting to see some of that relationship. I think we’ll continue to see that as AI workloads continue to get built and experimented with and proof of concepts get expanded. And so I think I mostly focus on the fact that together we saw good performance in Q3 on Azure. Azure inclusive of both components in terms of our execution, in terms of the field and partner teams and backlog and conversion and interesting workloads and adding customer value and solving real problems and adding real value. And I think that’s probably how I would approach that number more than trying to separate it in the way that even we have talked about it, but for very different reasons.\\n\\n**Jonathan Nielsen, Vice President of Investor Relations, Microsoft**: Thanks, Alex. That wraps up the Q and A portion of today’s earnings call. Thank you for joining us today, and we look forward to speaking with you all soon.\\n\\n**Unspecified Speaker**: Thank you. Thank you.\\n\\n**Conference Operator**: This concludes today’s conference. You may disconnect your lines at this time. Enjoy the rest of your day.\\n\\n*This article was generated with the support of AI and reviewed by an editor. For more information see our T&C.*\\n\\n3rd party Ad. Not an offer or recommendation by Investing.com. See disclosure [here](#) or **[remove ads](/ad-free-subscription?source=desktop&medium=article_ad)**.\\n\\n## MSFT: is this perennial leader facing new challenges?\\n\\nWith valuations skyrocketing in 2024, many investors are uneasy putting more money into stocks. Sure, there are always opportunities in the stock market – but finding them feels more difficult now than a year ago.\\nUnsure where to invest next? One of the best ways to discover new high-potential opportunities is to look at the top performing portfolios this year.\\nProPicks AI offers 6 model portfolios from Investing.com which identify the best stocks for investors to buy right now. For example, ProPicks AI found 9 overlooked stocks that jumped over 25% this year alone.\\nThe new stocks that made the monthly cut could yield enormous returns in the coming years.\\nIs MSFT one of them?\\n\\n[Unlock ProPicks AI to find out](/pro/propicks)\\n\\nEarnings call transcript: Microsoft Q1 2025 earnings beat expectations, stock surges\\n\\n[View all comments (0)0](#comments-4015220)\\n\\n## Latest comments\\n\\nLoading next article…\\n\\n[Trade With A Regulated Broker](https://www.investing.com/brokers/forex-brokers/)\\n\\n1D\\n\\n1W\\n\\n1M\\n\\n6M\\n\\n1Y\\n\\n5Y\\n\\nMax\\n\\n[US 30](https://www.investing.com/indices/us-30-futures?cid=1175152 \"US 30 Cash - (CFD)\")\\n\\n44,282.50\\n\\n+106.4\\n\\n+0.24%\\n\\n[US 500](https://www.investing.com/indices/us-spx-500-futures?cid=1175153 \"US 500 Cash - (CFD)\")\\n\\n6,395.30\\n\\n+5.8\\n\\n+0.09%\\n\\n[Dow Jones](https://www.investing.com/indices/us-30 \"Dow Jones Industrial Average\")\\n\\n44,175.61\\n\\n+206.97\\n\\n+0.47%\\n\\n[S&P 500](https://www.investing.com/indices/us-spx-500 \"S&P 500 - (CFD)\")\\n\\n6,389.45\\n\\n+49.45\\n\\n+0.78%\\n\\n[Nasdaq](https://www.investing.com/indices/nasdaq-composite \"NASDAQ Composite\")\\n\\n21,450.02\\n\\n+207.33\\n\\n+0.98%\\n\\n[S&P 500 VIX](https://www.investing.com/indices/volatility-s-p-500 \"CBOE Volatility Index - (CFD)\")\\n\\n15.91\\n\\n+0.76\\n\\n+5.02%\\n\\n[Dollar Index](https://www.investing.com/currencies/us-dollar-index \"US Dollar Index Futures - (CFD)\")\\n\\n98.132\\n\\n+0.123\\n\\n+0.13%\\n\\n[Crude Oil WTI Futures](https://www.investing.com/commodities/crude-oil \"Crude Oil WTI Futures - (CFD)\")\\n\\n63.84\\n\\n-0.04\\n\\n-0.06%\\n\\n[Brent Oil Futures](https://www.investing.com/commodities/brent-oil \"Brent Oil Futures - (CFD)\")\\n\\n66.63\\n\\n+0.04\\n\\n+0.06%\\n\\n[Natural Gas Futures](https://www.investing.com/commodities/natural-gas \"Natural Gas Futures - (CFD)\")\\n\\n2.915\\n\\n-0.075\\n\\n-2.51%\\n\\n[Gold Futures](https://www.investing.com/commodities/gold \"Gold Futures - (CFD)\")\\n\\n3,409.85\\n\\n-81.45\\n\\n-2.33%\\n\\n[Silver Futures](https://www.investing.com/commodities/silver \"Silver Futures - (CFD)\")\\n\\n37.94\\n\\n-0.602\\n\\n-1.56%\\n\\n[Copper Futures](https://www.investing.com/commodities/copper \"Copper Futures - (CFD)\")\\n\\n4.4552\\n\\n-0.0163\\n\\n-0.36%\\n\\n[US Soybeans Futures](https://www.investing.com/commodities/us-soybeans \"US Soybeans Futures - (CFD)\")\\n\\n1,009.38\\n\\n+22.38\\n\\n+2.27%\\n\\n[U.S. 10Y](https://www.investing.com/rates-bonds/u.s.-10-year-bond-yield \"United States 10-Year\")\\n\\n4.258\\n\\n-0.025\\n\\n-0.58%\\n\\n[U.S. 30Y](https://www.investing.com/rates-bonds/u.s.-30-year-bond-yield \"United States 30-Year\")\\n\\n4.824\\n\\n-0.030\\n\\n-0.62%\\n\\n[U.S. 5Y](https://www.investing.com/rates-bonds/u.s.-5-year-bond-yield \"United States 5-Year\")\\n\\n3.812\\n\\n-0.016\\n\\n-0.42%\\n\\n[U.S. 3M](https://www.investing.com/rates-bonds/u.s.-3-month-bond-yield \"United States 3-Month\")\\n\\n4.26\\n\\n+0.017\\n\\n+0.40%\\n\\n[US 10Y T-Note Futures](https://www.investing.com/rates-bonds/us-10-yr-t-note \"US 10 Year T-Note Futures\")\\n\\n111.98\\n\\n+0.16\\n\\n+0.14%\\n\\n[Euro Bund Futures](https://www.investing.com/rates-bonds/euro-bund \"Euro Bund Futures - (CFD)\")\\n\\n129.79\\n\\n+0.06\\n\\n+0.05%\\n\\n[10-2 Yield Spread](https://www.investing.com/rates-bonds/10-2-year-treasury-yield-spread \"10-2 Year Treasury Yield Spread\")\\n\\n31.32\\n\\n+4.15\\n\\n+15.27%\\n\\n[AAPL](https://www.investing.com/equities/apple-computer-inc \"Apple Inc\")\\n\\n229.35\\n\\n+9.32\\n\\n+4.24%\\n\\n[NVDA](https://www.investing.com/equities/nvidia-corp \"NVIDIA Corporation\")\\n\\n182.70\\n\\n+1.93\\n\\n+1.07%\\n\\n[GOOGL](https://www.investing.com/equities/google-inc \"Alphabet Inc Class A\")\\n\\n201.42\\n\\n+4.90\\n\\n+2.49%\\n\\n[TSLA](https://www.investing.com/equities/tesla-motors \"Tesla Inc\")\\n\\n329.65\\n\\n+7.38\\n\\n+2.29%\\n\\n[AMZN](https://www.investing.com/equities/amazon-com-inc \"Amazon.com Inc\")\\n\\n222.69\\n\\n-0.44\\n\\n-0.20%\\n\\n[NFLX](https://www.investing.com/equities/netflix,-inc. \"Netflix Inc\")\\n\\n1,211.64\\n\\n+31.27\\n\\n+2.65%\\n\\n[META](https://www.investing.com/equities/facebook-inc \"Meta Platforms Inc\")\\n\\n769.30\\n\\n+7.47\\n\\n+0.98%\\n\\nMost Popular Articles\\n\\nNews\\n\\nAnalysis\\n\\n[Futures higher; data wave incoming this week - what’s moving markets](https://www.investing.com/news/economy-news/futures-higher-data-wave-incoming-this-week--whats-moving-markets-4181905)\\n\\nBy Investing.co...\\n\\nAug 11, 2025\\n\\n[Chinese state media flags security risks from Nvidia’s H20 chips](https://www.investing.com/news/stock-market-news/chinese-state-media-flags-security-risks-from-nvidias-h20-chips-4181816)\\n\\nBy Investing.co...\\n\\nAug 11, 2025\\n\\n[Bitcoin price today: surges to $122k, near record high on US regulatory cheer](https://www.investing.com/news/cryptocurrency-news/bitcoin-price-today-surges-to-122k-near-record-high-on-us-regulatory-cheer-4181792)\\n\\nBy Investing.co...\\n\\nAug 11, 2025\\n\\n[Nvidia, AMD to pay 15% of China chip sales revenue to U.S. government - FT](https://www.investing.com/news/stock-market-news/nvidia-amd-to-pay-15-of-china-chip-sales-revenue-to-us-govt-ft-4181743)\\n\\nBy Investing.co...\\n\\nAug 10, 2025\\n\\n[Asia stocks tentative ahead of China tariff deadline; Australia hits record high](https://www.investing.com/news/stock-market-news/asia-stocks-tentative-ahead-of-china-tariff-deadline-australia-hits-record-high-4181765)\\n\\nBy Investing.co...\\n\\nAug 11, 2025\\n\\n[Top 5 Positions You Need to Exit NOW](https://www.investing.com/analysis/top-5-positions-you-need-to-exit-now-200665011)\\n\\nBy Nolan Gouvei...\\n\\nAug 08, 2025\\n\\n[1 Stock to Buy, 1 Stock to Sell This Week: Cisco, Deere](https://www.investing.com/analysis/1-stock-to-buy-1-stock-to-sell-this-week-cisco-deere-200665062)\\n\\nBy Jesse Cohen\\n\\nAug 10, 2025\\n\\n[Why America Is Suddenly Slowing Down on Electric Vehicles](https://www.investing.com/analysis/why-america-is-suddenly-slowing-down-on-electric-vehicles-200664834)\\n\\nBy Charles-Henr...\\n\\nAug 09, 2025\\n\\n[How Today’s Bull Market Compares to the Great Runs of the Past](https://www.investing.com/analysis/secular-bull-markets-the-shotclock-is-ticking-200664755)\\n\\nBy Brian Gilmar...\\n\\nAug 09, 2025\\n\\n[3 Bargain Stocks Offering Reliable Dividends and Promising Upside Potential](https://www.investing.com/analysis/3-bargain-stocks-offering-reliable-dividends-and-promising-upside-potential-200664947)\\n\\nBy Ismael De La...\\n\\nAug 08, 2025\\n\\n[More News](https://www.investing.com/news/most-popular-news)\\n\\n[Market Movers](https://www.investing.com/markets/united-states)\\n\\n| Name | Last | Chg. % | Vol. |\\n| --- | --- | --- | --- |\\n| [NVDA](https://www.investing.com/equities/nvidia-corp) | 182.70 | +1.07% | 123.40M |\\n| [AAPL](https://www.investing.com/equities/apple-computer-inc) | 229.35 | +4.24% | 113.85M |\\n| [TSLA](https://www.investing.com/equities/tesla-motors) | 329.65 | +2.29% | 91.20M |\\n| [AMD](https://www.investing.com/equities/adv-micro-device) | 172.76 | +0.21% | 68.87M |\\n| [PLTR](https://www.investing.com/equities/palantir-technologies-inc) | 186.96 | +2.61% | 62.66M |\\n| [MSFT](https://www.investing.com/equities/microsoft-corp) | 522.04 | +0.23% | 15.53M |\\n| [LLY](https://www.investing.com/equities/eli-lilly-and-co) | 625.65 | -2.37% | 14.13M |\\n\\n| Name | Last | Chg. % | Vol. |\\n| --- | --- | --- | --- |\\n| [GILD](https://www.investing.com/equities/gilead-sciences-inc) | 119.41 | +8.28% |  |\\n|  | 75.48 | +7.74% |  |\\n|  | 30.45 | +7.71% |  |\\n|  | 64.69 | +6.40% |  |\\n|  | 118.89 | +6.28% |  |\\n|  | 455.98 | +4.26% |  |\\n| [AAPL](https://www.investing.com/equities/apple-computer-inc) | 229.35 | +4.24% | 113.85M |\\n\\n| Name | Last | Chg. % | Vol. |\\n| --- | --- | --- | --- |\\n|  | 54.23 | -38.61% |  |\\n|  | 133.35 | -11.25% |  |\\n|  | 10.51 | -10.48% |  |\\n|  | 10.91 | -8.01% |  |\\n|  | 61.87 | -6.57% |  |\\n|  | 70.53 | -5.66% |  |\\n|  | 44.60 | -4.44% |  |\\n\\n## [Trending Stocks](https://www.investing.com/equities/trending-stocks)\\n\\n| Name | Last | Chg. % | Vol. |\\n| --- | --- | --- | --- |\\n| [NVDA](https://www.investing.com/equities/nvidia-corp) | 182.70 | +1.07% | 123.40M |\\n| [TSLA](https://www.investing.com/equities/tesla-motors) | 329.65 | +2.29% | 91.20M |\\n| [AAPL](https://www.investing.com/equities/apple-computer-inc) | 229.35 | +4.24% | 113.85M |\\n| [PLTR](https://www.investing.com/equities/palantir-technologies-inc) | 186.96 | +2.61% | 62.66M |\\n| [AMD](https://www.investing.com/equities/adv-micro-device) | 172.76 | +0.21% | 68.87M |\\n\\nShow more\\n\\nProPicks AI\\n\\nAI-powered **stock picks** with a proven track record to **beat the S&P 500**.\\n\\n[Tech Titans](/pro/propicks/tech-titans)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/tech-titans?entry=ws_propicks)\\n\\n[Beat the S&P 500](/pro/propicks/beat-sp-500)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-sp-500?entry=ws_propicks)\\n\\n[Dominate the Dow](/pro/propicks/dominate-the-dow)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/dominate-the-dow?entry=ws_propicks)\\n\\n[Mid-Cap Movers](/pro/propicks/midcap-movers)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/midcap-movers?entry=ws_propicks)\\n\\n[Top Value Stocks](/pro/propicks/top-value-stocks)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/top-value-stocks?entry=ws_propicks)\\n\\n[Best of Buffett](/pro/propicks/best-of-buffett)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/best-of-buffett?entry=ws_propicks)\\n\\n[Mexican Stock Exchange Leaders](/pro/propicks/beat-bmv-ipc)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-bmv-ipc?entry=ws_propicks)\\n\\n[Best Brazilian Stocks](/pro/propicks/beat-bovespa)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-bovespa?entry=ws_propicks)\\n\\n[Italian Market Elite](/pro/propicks/beat-ftse-italia)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-ftse-italia?entry=ws_propicks)\\n\\n[Alpha Germany Select](/pro/propicks/beat-dax)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-dax?entry=ws_propicks)\\n\\n[TASI Superstars](/pro/propicks/beat-tasi)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-tasi?entry=ws_propicks)\\n\\n[Korean Market Leaders](/pro/propicks/beat-kospi)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-kospi?entry=ws_propicks)\\n\\n[Mexican Bargains](/pro/propicks/mexican-bargains)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/mexican-bargains?entry=ws_propicks)\\n\\n[Beat the TSX](/pro/propicks/beat-tsx)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/beat-tsx?entry=ws_propicks)\\n\\n[Mexican Mid-Cap Movers](/pro/propicks/mexican-mid-cap-movers)\\n\\nStocks in this Strategy\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\naaa aaaaaaa aaaa aaa\\n\\n[Unlock Strategy](/pro/propicks/mexican-mid-cap-movers?entry=ws_propicks)\\n\\n---\\n\\nCalendars\\n\\n[Economic Calendar](/economic-calendar/)[Earnings Calendar](/earnings-calendar/)[Holiday Calendar](/holiday-calendar/)\\n\\nUS Economy\\n\\n[Fed Rate Monitor Tool](/central-banks/fed-rate-monitor)[US Treasury Yield Curve](/rates-bonds/usa-government-bonds)\\n\\nMore Tools\\n\\n[Stock Screener](/stock-screener/)[Currency Converter](/currency-converter/)\\n\\nInstall Our AppScan QR code to install app\\n\\nRisk Disclosure: Trading in financial instruments and/or cryptocurrencies involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors. Prices of cryptocurrencies are extremely volatile and may be affected by external factors such as financial, regulatory or political events. Trading on margin increases the financial risks.  \\nBefore deciding to trade in financial instrument or cryptocurrencies you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.  \\n**Fusion Media**\\xa0would like to remind you that the data contained in this website is not necessarily real-time nor accurate. The data and prices on the website are not\\xa0necessarily\\xa0provided by any market or exchange, but may be provided by\\xa0market makers, and so prices may not be accurate and may differ from the actual price at any given market, meaning prices are indicative and not appropriate for trading purposes.\\xa0**Fusion Media**\\xa0and\\xa0any provider of the data contained in this website\\xa0will not accept liability for any loss or damage as a result of your trading, or your reliance on the information contained within this website.  \\nIt is prohibited to use, store, reproduce, display, modify, transmit or distribute the data contained in this website without the explicit prior written permission of Fusion Media and/or the data provider. All intellectual property rights are reserved by the providers and/or the exchange providing the data contained in this website.  \\n**Fusion Media** may be compensated by the advertisers that appear on the website, based on your interaction with the advertisements or advertisers.\\n\\n© 2007-2025 - Fusion Media Limited. All Rights Reserved.'},\n",
              " {'title': 'WATCH LIVE: Microsoft Q1 2025 Earnings Call | $MSFT - YouTube',\n",
              "  'url': 'https://www.youtube.com/watch?v=Qbna4xKBBRU',\n",
              "  'content': 'constant currency in line with expectations Azure and other cloud services Revenue grew 33% and 34% in constant currency with healthy consumption trends that were in line with expectations the better than expected result was due to the small benefit from in period Revenue recognition noted earlier Azure growth included roughly 12 points from AI Services similar to last quarter demand continues to be higher than our available capacity non- AI growth Trends were also in line with expectations in [...] increased demand and growth in long-term commitments to our Microsoft cloud platform drove our results commercial bookings were ahead of expectations and increased 30% and 23% in constant currency results were driven by strong execution across our core annuity sales motions and growth in the number of 10 million plus contracts for both Azure and Microsoft 365 additionally we also saw an increase in the number of a $100 million plus contracts for Azure commercial remaining performance obligation [...] and partner Services Revenue decreased 1% and was relatively unchanged in constant currency segment gross margin dollars increased 15% and gross margin percentage decreased three points year-over-year driven by scaling our AI infrastructure operating expenses increased 8% and operating income grew 18% now to more personal Computing Revenue was 13.2 billion increasing 177% with 15 points of net impact from the Activision acquisition results were above expectations driven by Gaming and search',\n",
              "  'score': 0.939919,\n",
              "  'raw_content': \"# 🔴WATCH LIVE: Microsoft Q1 2025 Earnings Call | $MSFT\\n## Benzinga\\n287000 subscribers\\n42 likes\\n\\n### Description\\n8077 views\\nPosted: 30 Oct 2024\\nMicrosoft Q1 Earnings Highlights: 'AI-Driven Transformation Is Changing Work,' Company Beats Revenue, EPS Estimates - https://www.benzinga.com/news/earnings/24/10/41636770/microsoft-q1-earnings-highlights-ai-driven-transformation-is-changing-work-company-beats-revenue-ep\\n\\nMicrosoft Q1 2025 GAAP EPS $3.30 Beats $3.09 Estimate, Sales $65.60B Beat $64.51B Estimate\\n\\r\\nLooking for a transcript of this call? Check out the Benzinga Earnings Call Transcripts API - https://www.benzinga.com/apis/cloud-p...\\r\\n\\r\\n🌐💻Find more coverage on www.benzinga.com\\r\\n\\r\\n📃🖊 Sign up for Benzinga's Trading Competition Powered by TradeZero for your chance to win up to $30,000! - https://benzingapartners.go2cloud.org...\\r\\n\\r\\nFollow us on socials:\\r\\n📷 Instagram: www.instagram.com/benzinga\\r\\n👨\\u200d👩\\u200d👦📕Facebook: www.facebook.com/benzinga\\r\\n⏱TikTok: www.tiktok.com/benzinga\\r\\n🐤Twitter: twitter.com/benzinga\\r\\n\\r\\nDisclaimer: This live stream is for informational and educational purposes only. The content featured, including earnings calls, is publicly available and sourced from respective company disclosures. Benzinga is not affiliated with the companies being discussed, nor do we claim ownership of the material presented. Trading in financial markets involves significant risk, and there is no guarantee of profit. The information provided by any financial product or service is for educational purposes and should not be considered as financial advice. Before making any investment decisions, it's important to conduct thorough research and consult with a qualified financial advisor. Past performance is not indicative of future results. Always invest what you can afford to lose and be aware of the potential for loss in any investment strategy.\\r\\n\\r\\n#Microsoft #ArtificialIntelligence $MSFT\\n\\n4 comments\\n### Transcript:\\nbe for for [Music] [Applause] [Music] make me make me make me make me [Music] bab B Bab [Music] [Music] I [Music] [Applause] [Music] a a [Music] h [Music] a [Music] n [Music] [Applause] [Music] [Music] [Applause] [Music] [Applause] [Music] oh n [Music] we [Music] o [Music] yeah sh [Music] greetings and welcome to the Microsoft fiscal year 2025 first quarter earnings conference call at this time all participants are on a listen only mode a question and answer session will follow the formal presentation if anyone should require operator assistance during the conference please press star zero on your telephone keypad as a reminder this conference is being recorded it is now my pleasure to introduce your host Brett Iverson vice president of investor relations please go ahead good afternoon and thank you for joining us today on the call with me are Sati Nadella chairman and chief executive officer Amy Hood chief finan officer Alice Jala Chief accounting officer and Keith dolliver corporate secretary and Deputy General Counsel on the Microsoft invest relations website you can find our earnings press release and financial summary slide deck which is intended to supplement our prepared remarks during today's call and provides the reconciliation of differences between Gap and non-gaap financial measures we have recast certain prior period amounts to reflect the fy2 changes to the composition of our segments announced in August 2024 additional details including FY 23 and FY 24 recast segment Revenue operating income and product and service level Revenue can be found in the financial statements file on the investor relations website more detailed Outlook slides will also be available on the Microsoft invest relations website when we provide Outlook commentary on today's call on this call we we will discuss certain non-gap items the non-gaap financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with gap they are included as additional clarifying items to Aid investors in further understanding the company's first quarter performance in addition to the impact these items and events have [Music] on all growth comparisons we make on the call today relate to the corresponding period of last year unless otherwise noted we will also provide growth rates in constant currency when available as a framework for assessing how our underlying businesses performed excluding the effect of foreign currency rate fluctuations where growth rates are the same in constant currency we will refer to the growth rate only we will post our prepared remarks to website immediately following the call until the complete transcript is available today's call is being webcast live live and recorded if you ask a question it will be included in our live Transmission in the transcript and in any future use of the recording you can replay the call and view the transcript on the Microsoft invest relations website during this call we'll be making forward-looking statements which are predictions projections or other statements about future events these statements are based on current expectations and assumptions that are subject to risks and uncertainties actual results could materially differ because of factors discussed in today's earnings press release in the comments made during this conference call and in the risk factor section of our form 10K forms 10q and other reports and filings with the Securities and Exchange Commission we do not undertake any duty to update any forward-looking statement and with that I'll turn the call over to Saia thank you Brett we are off to a solid start to our fiscal year driven by continued strength of Microsoft cloud which surpassed $8.9 billion in Revenue up 22% AI driven transformation is changing work work artifacts and workflow across every role function and business process helping customers Drive New Growth and operating leverage all up our AI business is on track to surpass an annual revenue run rate of $10 billion next quarter which will make it the fastest business in our history to reach this Milestone now I'll highlight examples of our progress starting with infrastructure Azure took share this quarter we are seeing continued growth in Cloud migration Azure Arc now has over 39,000 customers across every industry including American Tower CTT L'Oreal up more than 80% year-over-year we now have data centers in over 60 regions around the world and this quarter we announced new cloud and AI infrastructure investments in Brazil Italy Mex Mexico and Sweden as we expand our capacity in line with our long-term demand signals at the Silicon layer a new cobalt 100 VMS are being used by companies like datab bricks elastic seamen Snowflake and synapsis to power their general purpose workloads at up to 50% better price performance than previous generations on top of this we're building out our next Generation AI infrastructure innovating across the full stack to optimize our Fleet for AI workloads we offer the broadest selection of AI accelerators including our first party accelerator Maya 100 as well as the latest gpus from AMD and Nvidia in fact we're the first Cloud to bring up nvidia's Blackwell system with gb200 power AI servers our partnership with open AI also continues to deliver results we have an economic interest in a company that has grown significantly in value and we have built differentiated IP and are driving Revenue momentum more broadly with Azure AI we are building an endtoend app platform to help customers build their own co-pilots and agents Azure open AI usage more than doubled over the past six months as both digital natives like grammarly and Harvey as well as established Enterprises like Bajaj Finance Hitachi KT and LG move apps from test to production GE Aerospace for example used Azure open AI to build a new digital assistant for all 52,000 of its employees in just 3 months it has been used to conduct over 500,000 internal queries and process more than 200,000 documents and this quarter we added support for open ai's newest model family 01 we're also bringing industry specific models to Azure AI including a collection of best-in-class multimodel models for medical imaging and with GitHub models we now provide access to our full model catalog directly within the GitHub developer workflow Azure AI is also increasingly an onramp to our data and analytics Services as developers build new AI apps on Azure we have seen an acceleration of azure Cosmos DB and Azure SQL DB hyperscale usage as customers like Air India Nova Nordisk telefonica Toyota motor North America and unipa take advantage of capabilities purpose build built for AI applications and with Microsoft fabric we provide a single AI powered platform to help customers like Chanel ey KPMG Swissair and syo unify their data across clouds we now have over 16,000 paid fabric customers over 70% of the Fortune 500 now on to developers get up copilot is changing the way the world builds software Copilot Enterprise customers increase 55% quarter over quarter as companies like AMD and flutter entertainment tailor co-pilot to their own code base and we are introducing the next phase of AI code generation making GitHub co-pilot agentic across the developer workflow giup co-pilot workspace is a developer environment which leverages Agents from start to finish so developers can go from spec to plan to code all in natural language co-pilot autofix is an AI agent that helps developers at companies like Assyrian and Auto Group fix vulnerabilities in their code over three times faster than it would take them on their own we're also continuing to build on github's open platform ethos by making more models available via GitHub co-pilot and we're expanding the reach of GitHub to a new segment of developers introducing GitHub spark which enables anyone to build apps in natural language already we have brought generative AI to power platform to help customers use low code no code tools to cut costs and development time to date nearly 600,000 organizations have used AI powered capabilities in Power Platform up Forex year-over-year citizen developers at ZF for example built apps simply by describing what they need using natural language and this quarter we introduced new ways for customers to apply AI to streamline complex workflows with power automate now on to work we launched the next wave of Microsoft 365 co-pilot Innovation last month bringing together web work and Pages as the new design system for knowledge work pages is the First new digital artifact for the AI age and it's designed to help you ideate with AI and collaborate with other people we've also made Microsoft 365 co-pilot responses 2x faster and improved response quality by nearly 3x this Innovation is driving accelerated usage and the number of people using Microsoft 365 daily more than doubled quarter over quarter we're also seeing increased adoption from customers in every industry as they use Microsoft 365 co-pilot to drive real business value vone for example will roll out Microsoft 365 co-pilot to 68,000 employees after a trial showed that on average they saved three hours per person per week and UBS will deploy 50,000 seats in our largest finser deal to date and we continue to see Enterprise customers coming back to buy more seats all up nearly 70% of the Fortune 500 now use Microsoft 365 co-pilot and customers continue to adopt it as a faster rate than any other new Microsoft 365 Suite co-pilot is the UI for AI and with Microsoft 365 co-pilot copilot studio and agents and now autonomous agents we have built an endtoend system for AI business transformation with co-pilot Studio organizations can build and connect Microsoft 365 co-pilot to autonomous agents which then delegate to co-pilot when there is an exception more than 100,000 organizations from urew Standard Bank and Thompson Reuters to Virgin money and Zurich Insurance have used co-pilot Studio to date up over 2x quarter over quarter more broadly we are seeing AI drive a fundamental change in the business applications Market as customers shift from Legacy apps to AI first business processes Dynamics 365 continues to take share as organizations like Evon Heineken and Lexar chose our apps over other providers and monthly active users of co-pilot across our CRM and Erp portfolio increased over 60% quarter over quarter our Dynamics 365 contact center is also winning customers like curries L Crosset and rxo as it brings generative AI to every customer engagement Channel and just last week we added 10 outof the-box autonomous agents to Dynamics 365 that helps customers automatically qualify sales leads track suppliers and work hand inand with service reps to resolve issues they're also bringing AI to Industry specific workflows one year in tax co-pilot is now documenting over one .3 million physician patient encounters each month at over 500 healthc care organizations like Baptist Medical Group Baya Scott and White gram Baltimore Medical Center Novant Health and Overlake Medical Center it is showing faster Revenue growth than gith up copilot did in this first year and new features extend Dax Beyond notes helping Physicians automatically draft referrals after visit instructions and diagnostic evidence on top of all this AI Innovation Microsoft teams usage remains at alltime highs as people use it to streamline all their Communications nearly 75% of our teams Enterprise customers now buy premium phone or rooms when it comes to Windows our new class of co-pilot plus PCS is winning new customers they offer best-in-class AI capability performance and value AMD Intel and Qualcomm now all support copilot plus PCS this quarter we also introduced new AI experience only available on copilot plus PCS like click Todo which places an interactive overlay over your desktop to suggest next best actions and as we approach the end of support for Windows 10 a year from now we are well positioned to transition our customers to Windows 11 ensuring they benefit from enhanced features and security improvements we've introduced over the past few years now on to security we continue to Prior prioritize security above all else with our secure future initiative we have dedicated the equivalent of 34,000 full-time Engineers to address the highest priority security tasks we have made significant progress to better protect tenants identities networks and Engineering Systems and we have created new processes to ensure security is prioritized at every level of the company and we continue to take what we learn and turn it into Innovations across our products security co-pilot for example is being used by companies in every industry including Clifford chance intessa sen Paulo and shell to perform SE Ops tasks faster and more accurately and we are now helping customers protect their AI deployments too customers have used Defender to discover and secure more than 750,000 gen app instances and use perview to audit over a billion co-pilot interactions to meet their compliance obligations and all up we continue to take share across all major categories we serve and are consistently recognized by top analysts as a leader in 20 categories more than any other vendor now let me turn to our consumer businesses starting with LinkedIn member growth continues to accelerate with markets in India and Brazil both growing at double digits we're also seeing record engagement as we introduce new ways for our more than 1 billion members to connect sell Services get hired and share knowledge our investments in Rich formats like video strengthen our leadership in B2B advertising and amplify the value we deliver to our customers weekly immersive video views increase 6X quarter over quarter and Total video viewership on LinkedIn is up 36% eurover year our AI power tools also continue to transform how people sell learn and higher in sales new AI features help every team member perform at the level of top sellers and drive more profitable growth in learning just yesterday we announced updates to our coaching experience including personalized Career Development plans linkedin's first agent hiring assistant will help hirers find qualified candidates Faster by tackling the most timec consuming tasks already hirers who use AI assistant messages see a 44% higher acceptance rate compared to those who don't and hiring business continues to take share now want to search advertising in news with co-pilot we seeing the first step towards creating a new AI companion for everyone with new co-pilot experience we introduced earlier this month includes a refresh design and tone along with improved speed and fluency across the web and mobile and it includes Advanced capabilities like voice and vision that make it more delightful and useful and feel more natural you can both browse and converse with co-pilot simultaneously because co-pilot sees what you see more broadly AI is also transforming search browsers and digital advertising and we continue to take share across being an edge being xstack Revenue growth outpace the suchar market now on to gaming one year since we closed our acquisition of Activision Blizzard King we have focused on building a business position for long-term growth driven by higher margin content and services you already see this transformation in our results as we diversify the ways that Gamers access our content we set new records for monthly active users in the quarter as more players than ever play our games across devices and on the Xbox platform Game Pass also set a new q1 record for total revenue and average revenue per subscriber and as we look ahead our IP across our Studios has never been stronger last week's launch of Black Ops 6 was the biggest Call of Duty release ever setting a record for day one players as well as Game Pass subscriber ads on launch day and unit sales on PlayStation and steam were also up over 60% Euro year this speaks to our strategy of meeting Gamers where they are by enabling them to play more games across the screens they spend their time on in closing we're rapidly innovating to expand our opportunity across our commercial and consumer businesses in 3 weeks time we will hold our ignite conference and I look forward to sharing more then about how we are helping every business function use AI to drive growth in this new era with that let me turn it over to Amy thank you Saia and good afternoon everyone this quarter Revenue was 65.6 billion up 16% and earnings per share was $3.30 an increase of 10% with strong execution by our Sal teams and partners we delivered a solid start to our fisal year with double-digit top and bottom line growth we also saw continued share gains across many of our businesses in our Commercial Business increased demand and growth in long-term commitments to our Microsoft cloud platform drove our results commercial bookings were ahead of expectations and increased 30% and 23% in constant currency results were driven by strong execution across our core annuity sales motions and growth in the number of 10 million plus contracts for both Azure and Microsoft 365 additionally we also saw an increase in the number of a $100 million plus contracts for Azure commercial remaining performance obligation increased 22% and 21% in constant currency to $259 billion roughly 40% will be recognized in Revenue in the next 12 months up 17% year-over-year the remaining portion recognized beyond the next 12 months increased 20 7% and this quarter our annuity mix increased to 98% in addition to commercial results that were in line with expectations we also saw some benefit from in Period Revenue recognition across Microsoft 365 commercial Azure and our on premises server business at a company level Activision contributed a net impact of approximately three points to revenue growth was a two-point drag on operating income growth and had a negative 5cent impact to earning per share a reminder that this net impact includes adjusting for the movement of Activision content from our prior relationship as a third party partner to first party and includes $91 million from purchase accounting adjustments integration and transaction related costs FX did not have a significant impact on our results and was roughly in line with expectations on total company Revenue segment level Revenue cogs and operating expense growth Microsoft cloud Revenue was 38 .9 billion and grew 22% roughly in line with expectations Microsoft cloud grow margin percentage decreased 2.0 over-year to 71% this was slightly better than expected due to Improvement in Azure although the gross margin percentage decrease year-over-year continues to be driven by scaling our AI infrastructure company gross margin dollars increased 133% and 14% in constant currency and gross margin percentage with 69% down 2.0 over-year driven by the lower Microsoft cloud gross margin noted earlier as well as the impact from purchase accounting adjustments integration and transaction related cost from the Activision acquisition operating expenses increased 12% lower than expected due to our focus on cost efficiencies and ongoing prioritization work operating expense growth included nine points from the Activision acquisition at a total company level head count at the end of September was 8% higher than a year ago excluding the growth from the Activision acis position head count was 2% higher operating income increased 14% And operating margins were 47% down one point year-over-year excluding the net impact from the Activision acquisition operating margins were up one point as we continue to drive efficiencies across our businesses as we invest in AI infrastructure and capabilities now to our segment results revenue from productivity and business processes was 28.3 billion and grew 12% and 13% % in constant currency ahead of expectations driven by better than expected results across all businesses M365 commercial Cloud Revenue increased 15% and 16% in constant currency with business trends that were as expected the better than expected result was due to a small benefit from the n period Revenue recognition noted earlier our growth was primarily driven by E5 as well as M365 co-pilots paid M365 commercial seats grew 8% year-over-year with installed base expansion across all customer segments seat growth was driven by our small and medium business and Frontline worker offerings M365 commercial Cloud Revenue represents nearly 90% of total M365 commercial products and cloud services M365 commercial products Revenue increased 2% and 3% in constant currency ahead of expectations primarily due to the benefit from in Period Revenue recognition noted earlier M365 consumer products and cloud services Revenue increased 5% and 6% % in constant currency M365 consumer Cloud Revenue increased 6% and 7% in constant currency with continued momentum in M365 consumer subscriptions which grew 10% to 84.4 million M365 consumer Cloud Revenue represents 85% of total M365 consumer products and cloud services LinkedIn Revenue increased 10% and 9% in constant currency slightly ahead of expectations with growth across all lines of business Dynamics Revenue grew 14% driven by Dynamics 365 which grew 18% and 19% in constant currency with continued growth across all workloads and continued share gains as a reminder Dynamics 365 represents about 90% of total Dynamics Revenue segment gross margin dollars increase 11% and 12% in constant currency and gross margin percentage decrease slightly year-over-year driven by scaling our AI infrastructure operating expenses increased 2% and operating income increased 16% next the intelligent Cloud segment Revenue was $24.1 billion increasing 20% and 21% in constant currency in line with expectations Azure and other cloud services Revenue grew 33% and 34% in constant currency with healthy consumption trends that were in line with expectations the better than expected result was due to the small benefit from in period Revenue recognition noted earlier Azure growth included roughly 12 points from AI Services similar to last quarter demand continues to be higher than our available capacity non- AI growth Trends were also in line with expectations in total and across regions as customers continued to migrate and modernize on the Azure platform the non AI Point contribution to Azure growth was sequentially lower by approximately 1 point in our on premises server business Revenue decreased 1% lower than expected transactional purchasing ahead of the Windows Server 2025 launch as well as lower purchasing of licenses running in multicloud environments was mostly offset by the benefit from in Period Revenue recognition noted earlier Enterprise and partner Services Revenue decreased 1% and was relatively unchanged in constant currency segment gross margin dollars increased 15% and gross margin percentage decreased three points year-over-year driven by scaling our AI infrastructure operating expenses increased 8% and operating income grew 18% now to more personal Computing Revenue was 13.2 billion increasing 177% with 15 points of net impact from the Activision acquisition results were above expectations driven by Gaming and search Windows OEM and devices Revenue increased 2% year-over-year as better than expected results in Windows OEM due to mix shift to higher mon izing markets was partially offset by the lower than expected results in devices due to execution challenges in the commercial segment search in news advertising Revenue xtac increased 18% and 19% in constant currency ahead of expectations primarily due to continued execution Improvement we saw rate expansion in addition to healthy volume growth in both Edge and Bing and in Gaming revenue increased 43% and 44% in constant currency with 43 points of net impact from the Activision acquisition results were ahead of expectation driven by stronger than expected performance in both first and third party content as well as consoles Xbox content and services Revenue increased 61% with 53 points of net impact from the Activision acquisition segment gross margin dollars increased 16% and 177% in constant currency with 12 points of net impact from the Activision acquisition gross margin percentage was relatively unchanged year over-year our strong execution on margin Improvement in gaming and search was offset by sales mix shift to those businesses operating expenses increased 49% with 51 points from the Activision acquisition operating income decreased 4% now back to Total company results Capital expenditures including Finance leases were $20 billion in line with expectations and cash paid for ppne was $14.9 billion roughly half of our cloud and AI related spend continues to be for long libed assets that will support monetization over the next 15 years and Beyond the remaining cloud and AI spend is primarily for servers both CPUs and gpus to serve customers based on demand signals cash flow from operations was $ 34.2 billion up 12% driven by strong Cloud Billings and collections partially offset by higher supplier employee and tax payments free cash flow was 19.3 billion down 7% year-over-year reflecting higher Capital expenditures to support our cloud and AI offerings this quarter other income expense was negative $283 million significantly more favorable than anticipated due to foreign currency remeasurement and net gains on investments our losses on investments accounted for under the equity method were as expected our effective tax rate was approximately 19% and finally we returned 9 billion dollars to shareholders through dividends and share repurchases now moving to our Q2 Outlook which unless specifically noted otherwise is on a US dollar basis first FX with the weaker US dollar and assuming current rates remain stable we expect FX to increase total revenue and segment level Revenue growth by less than one point we expect FX to have no meaningful impact to cogs or operating expense growth our Outlook has many of the trends we on q1 continue through Q2 customer demand for our differentiated Solutions should drive another quarter of strong growth in commercial bookings we expect strong growth on a growing XPR base driven by increased long-term commitments to our platform and strong execution across core annuity sales motions as a reminder larger long-term measure contracts which are more unpredictable in their timing can drive increased quarterly volatility and our bookings growth rate Microsoft cloud gross margin percentage should be roughly 70% down your overy year driven by the impact of scaling our AI infrastructure we expect Capital expenditures to increase on a sequential basis given our cloud and AI demand signals as I said last quarter we will stay aligned and if needed adjust to the demand signals we see as a reminder there can be quarterly spin variability from cloud infrastructure build outs and the timing of delivery of Finance leases next segment guidance starting with productivity and business processes we are the market leader when it comes to knowledge-based co-pilots and agents in the Enterprise space and we are focused on continuing to gain share across our productivity Solutions therefore we expect Revenue in productivity and business processes to grow between 10 and 11% in constant currency are 28.7 to 29 billion US M36 5 commercial Cloud Revenue growth should be approximately 14% in constant currency with moderating seat growth across customer segments and arpu growth through E5 and M365 co-pilots for H2 we expect Revenue growth to remain relatively stable compared to Q2 we continue to see growth in M365 co-pilot seats and we expect the related Revenue to continue to grow gradually over time for M365 commercial products we expect Revenue to decline in the low sing single digits as a reminder M365 commercial products include on premises components of M365 Suites so our quarterly Revenue growth can have variability primarily from in Period Revenue recognition depending on the mix of contracts M365 consumer Cloud Revenue growth should be in the mid single digits driven by M365 subscriptions for LinkedIn we expect Revenue growth of approximately 10% driven by continued growth across all businesses and in Dynamics 365 we expect Revenue growth to be in the mid to high teens driven by continued growth across all workloads next intelligent Cloud helping our customers transform and grow with Innovative cloud and AI Solutions is driving continued growth in asure therefore we expect Revenue in intelligent Cloud to grow between 18 and 20% in constant currency or 25.5 to 2.85 billion US Revenue will continue to be driven by Azure which as a reminder can have quarterly variability primarily from imperi revenue recognition depending on the mix of contracts in Azure we expect Q2 Revenue growth to be 31 to 32% in constant currency driven by strong demand for our portfolio of services we expect consumption growth to be stable compared to q1 and we expect to add more sequential dollars to Azure than any other quarter in history we expect the contribution from AI services to be similar to last quarter given the continued capacity constraints as well as some capacity that shifted out of Q2 and in H2 we still expect Azure growth to accelerate from H1 as our Capital Investments create an increase in available AI capacity to serve more of the growing demand and in our on premises server business we expect Revenue to decline in the loow to Mid single digits on a prior year comparable that benefited from purchasing ahead of Windows server 2012 end of support and in Enterprise and partner Services we expect Revenue growth to be in the low single digits now to more personal Computing we continue to make decisions to prioritize strategic higher margin opportunities within each of our consumer businesses our Outlook reflects the Improvement in grow and operating margins from this prioritization work across gaming search and devices we expect revenue and more personal Computing to be 13. 85 to 14.25 billion US Windows OEM and devices Revenue should decline in the low to mid single digits we expect Windows OEM Revenue growth in line with the PC market to be more than offset by a decline in devices as the trends from q1 continue search and news advertising xtac Revenue growth should be in the high teens with continued growth in both volume and revenue per search this will be higher than overall search and news advertising Revenue growth which we expect to be in the high single digits and in gaming we expect Revenue to decline in the high single digits due to Hardware we expect Xbox content and services Revenue growth to be relatively flat we're excited about last week's launch of Call of Duty where we saw the most Game Pass subscriber ads we've ever seen on a launch day there are two things about the launch that are different than the Call of Duty launch a year ago where Revenue was mostly recognized in the quarter of purchase first the game is a ailable on Game Pass so for players who play through game pass the subscription revenue is recognized over time second the game requires an online connection to play so even for players who purchase the Standalone game Revenue recognition will also occur ratably over time now back to company guidance we expect cogs to grow between 11 and 133% in constant currency or to be between 21.9 to 22.1 billion US an operating expense to grow approximately 7% in constant currency or to be between 16.4 and 16.5 billion US this should result in another quarter of operating margin expansion other income and expense is expected to be roughly negative 1.5 billion primarily driven by our share of the expected loss from open AI which is accounted for under the equity method as a reminder we do not recognize Mark to market gains or losses on Equity method method Investments as you heard from Saia our strategic partnership and investment in open aai has been pivotal in building and scaling our AI business and positioning us as the leader in the AI platform wave and lastly we expect our Q2 effective tax rate to be approximately 19% in closing we remain focused on strategically investing in the long-term opportunities that we believe Drive shareholder value monetization from these Investments continues to grow and we're excited that only two and a half years in our AI business is on track to surpass 10 billion of annual revenue run rate in Q2 this will be the fastest business in our history to reach this Milestone we are committed to Growing this leadership position across our entire Microsoft cloud while maintaining our disciplined focus on cost management and prioritization across every team with that let's go to Q&A Brett thanks Amy we'll now move over to Q&A out of respect for others of the call we request the participants please only ask one question operator can you please repeat your instructions thank you ladies and gentlemen if you would like to ask a question please press star one on your telephone keypad and a confirmation tone will indicate your lines in the question Quee you may press star two if you would like to remove your question from the queue for participants using speaker equipment it may be necessary to pick up your handset before pressing the start and our first question comes from the line of Keith Weiss with Morgan Stanley please proceed excellent uh thank you guys for taking the question and congratulations on a really solid quarter uh so Sakia the expansion of capabilities the speed of innovation the magnitude of the opportunities ahead for generative AI it makes this the most exciting period for software I've seen in my 25 years of covering the space and based upon this call it seems like you shared that excitement but am my that's conversation that excitement also feeds two related questions and they both have to do with constraints and the first is like what are the internal constraint or guard rail that Microsoft has when it comes to investing Behind These Innovations particularly in relation to the funding of future generations of foundational models where people were talking about price tags going to tens of billions or even hundred billion dollars plus and then on the other side of the spectrum um what are the external constraints that Microsoft sees in building out this capacity to meet to man and capture the opportunity particularly constraints in your ability to power all these new data centers being built out and power it in an environmentally sustainable fashion I I'd love to get the Microsoft perspective on both those uh questions no thank you uh Keith for those questions I think on the first point um ultimately our you know when you think about let's say a capital outlay for training because that's essentially what you're asking it is going to be rate Limited by your monetization of inference in a given generation right so just like in the past we would allocate Capital to build out cloud based on the demand signal we were seeing and then we would then project the demand and that's what we would build for so you can think of training essentially as that right which is you're building the Next Generation model so that then you have a more capable model that then drives more inference Demand right so ultimately even with all the scaling laws and what have you I think you ultimately will normalize to having a pace in fact I think the best way to think about even is given the Moors law effectively is working uh on the sort of uh silicon and system side so it's just not compute right its efficiencies in computed data as well as algorithms you will want to sort of keep on that curve which is you really want to refresh your Fleet U with the Moors law every year and then effectively depreciate uh over the period of the life cycle of it and then the insurance demand ultimately will govern how much we invest in training because that's I think at the end of the day uh you're all subject to ultimately demand the second piece of the external constraints we have run into obviously lots of external constraints because this demand all showed up pretty fast right I mean if you think about uh even CH the most hit products of this generation all are in our Cloud right whether it's chat GP whether it's co-pilot whether it's get up co-pilot or even Dax co-pilot I mean pick the top four or five products of this generation they're all sort of in and around our ecosystem and so therefore uh we ran into a set of constraints which are everything because DCS don't get built overnight so there is DCs uh there is power um and uh and so that's sort of been the short-term constraint even in Q2 for example some of the demand issues we have or our ability to fulfill demand is because of in external third party stuff that we least moving out so that's the constraints we have but in the long run um we do need effectively power um and we need DCS and some of these things are more long lead and but I feel pretty good that going into the second half of even uh this fiscal year that some of that Supply demand will match up excellent thank you guys thanks Keith operator next question please the next question comes from the line of Brent bill with jeffre please proceed thanks uh Amy good to hear uh the re acceleration in the back half for Azure I I guess many are asking uh you know 34% growth in q1 uh falling to low 30s I I know the comp is is a couple points harder but is there anything else you're contemplating in that guide for Q2 to see that uh to see that deceleration other than a tougher comp thank you uh thanks Brent maybe this is a great question because I can sort of reiterate some of the points I made and and tie them together a little bit uh in q1 uh the 34 in CC as we talked about um you know that upside versus the 33 that we had guided to was primarily due to some Revenue recognition benefits and so um I think about that on a sort of a pure consumption basis uh and AI as being you know 30 three and you think about a point or two uh of diesel that we've guided to and the majority of that is due to unfortunately some Supply pushouts that I mentioned and then sopia reiterated in terms of AI Supply coming online that we counted on the underlying consumption growth is stable q1 to Q2 uh and so to your question on some ins and out it is certainly uh some ins and outs um I do as you heard uh have confidence as we get um a good influx of Supply across the second half of the Year particularly uh on the AI side that will be better able to do some Supply demand matching and and hence while we're talking about acceleration in the back half I'll also take the opportunity to say when you see um usage in AI workloads we always intend to think about that is just a GPU exercise um the importance of having gpus and CPUs be able to run these workloads is also important so that's a piece um of the acceleration at age2 as well thanks thanks Brent operator next question please the next question comes from the line of Mark morler with Bernstein please proceed thank you very much for taking my question and congratulations on the quarter um the question every investor obviously asks is the question on the capex growth and the capex spend obviously half of that facilities an equivalent that have longer life but the other half is the rest of the components do can you give any color on how you think of that growth does it return to the traditional approach where basically capex is going to grow in line or slightly slower than Cloud Revenue um if so any sense of the timing do are we do we have enough facilities online by by sometime next year Etc any color would be appreciated uh thanks Mark you know I think in some ways it's helpful to go back um to the cloud transitions that we worked on um much over a decade ago I think in the early stages and what you did see and and you'll see us doing the same time is you have to build um to meet demand uh unlike the cloud transition we're doing it on a global basis uh in parallel as opposed to sequential uh given the nature of the demand and then um as long as we continue to see that demand grow you're right um the growth in capx will slow and the revenue growth will increase and those two things to your point um get closer and closer together over time the pace of that entirely depends really on the pace of adoption and to stop this point you know some of that spend goes toward building um the next training infrastructure so you won't see all of it in CX some of it uh goes to Opex um when you're spending it on on training but in general that's a that's a healthy way to think about the balance as it over time those do and should uh like the last cycle get closer together thank you very much that's very helpful thanks Mark operator next question please the next question comes from the line of Carl kirad with UBS please proceed okay great uh thank you I'm I'm actually not going to ask a question about the numbers but satian Amy I'd love to ask a question about uh open AI since um the the print three months ago we investors have been hit with a torrent of media stories about open Ai and Microsoft and I'd love to give Microsoft an opportunity to frame the relationship it seems to me it's critically important but uh we have been I think everyone on the line picking up signals that perhaps Microsoft wants to diversify somewhat at the model layer and and offer customers choice so SAA I'd love to get your framing of the relationship and then in terms of the numbers um maybe this is a little bit more for you Amy but how does Microsoft manage the the demands on capex from uh helping uh openi with its scaling Ambitions and how do you manage the the impact on other income that uh you just gave us some uh color on thank you so much sure um thanks SC so I'd say first the um partnership for both sides that's open Ai and Microsoft has been super beneficial um you know after all uh we were the you know we effectively sponsored what is one of the most highest valued uh uh private companies uh today when we uh invested in them and really took a bet on them and their Innovation uh four five years ago and uh uh that has led to great success for Microsoft it's great led to great success for open AI um uh and we continue uh to build on it right so we serve them with world-class infrastructure on which they do their uh innovation in terms of models on top of which we innovate both the model layer with some of the post trining stuff we do uh as well as some of the small models we build uh and then of course all of the product Innovation right one of the things that uh my own sort of conviction of open AI uh and what they were doing came about when I started seeing something like get up co-pilot as a product yet built or Dax co-pilot get built or M365 co-pilot get built so we have a a fantastic portfolio of innovation uh that we build on top of that um and um you know we at the same also I would say we are investors uh we feel very very good about sort of our uh investment stake in open Ai and uh uh and so our all our focus and we're always in constant dialogue with them in a partnership like this when both sides have achieved Mutual success at the face at which we achieved it that means we need to kind of push each other to do more uh to you know capture the moment and that's what uh we plan to do and we intend to keep building on it and maybe to your other two uh questions Carl you know listen um I'm thrilled uh with their success and need for Supply um from Azure and infrastructure and really what it's meant in terms of being able to also serve other customers for us um it's important that we continue uh to invest Capital to meet not only their demand signal uh and needs for compute but also from our broader customers uh that's partially why you've seen uh us committing the amounts of capital we've seen uh over the past few quarters Is our commitment to both grow together uh and for us to continue to grow the Azure platform for customers Beyond them uh and so I don't really think of it as how do you balance it it's just we have customers who have needs and real use cases and delivering value today and and if we can't meet that we need to work to meet it uh and that means working harder and faster to make sure we do that uh which is what the Keem is committed to do second piece of your question I think was on the impact to other income and um not to get too accounting heavy uh on the earning phone call but I would say uh just a reminder uh this is under the equity method uh which means um you know we just take our percentage of losses uh every quarter um and those losses of course are capped by the amount of investment we make in total uh which we did uh talk about in The Q's quarter uh as being $1 13 billion and so over time that's just the constraint um and it's a bit of a mechanical uh entry and so uh I don't really think about managing that that's the investment and acceleration that open AI is making in themselves and and we take a percentage of got it okay very helpful thank you both thanks Carl operator next question please the next question comes from the line of cash rangan with Goldman Sachs please proceed hi yeah thank you very much s when you talked about the investment cycle these models are getting bigger more expensive but you also pointed out to how in the inference phase uh we're likely to get paid how does that cycle look like an inference for Microsoft where are the the the products in the applications that will show up on the Microsoft pnl as a result of the inference phase of AI kicking it thank you very much thanks Cash I mean the good news for us um is that we're not waiting for that inance to show up right if you sort of think about uh the point we even made that this is going to be the fastest growth um uh to10 billion of any business in our history it's all INF uh right one of the things that it may not be um uh as evident is that we're not actually selling raw gpus for other people to train in fact that's sort of a business we turn away because we have so much Demand on inference that we are not taking what I would in fact that's an there's a huge adverse selection problem today where people it's just a bunch of tech companies still you know using VC money to buy a bunch of gpus we kind of really are not even participating in most of that because we are literally going to the deral demand which is in the Enterprise space or our own products like get up co-pilot or M365 co-pilot so I feel the quality of our revenue is also pretty Superior in that context uh and that's what gives us even the conviction to even Amy's answers previously about our Capital spend uh is if this was just all about sort of a bunch of people training large models and that was all we got uh then that would be you know ultimately still waiting to your point for someone to actually have demand which is real and in our case the good news here is we have a diversified portfolio we're seeing real demand uh across all of that portfolio and cash maybe just add a little bit to what Saia is saying I think a part of his two answers is that what you're saying is this number we're talking about the10 billion dollar across inference and our apps um is already what that momentum and that investment and that progress and that revenue is what builds the next cycle of training right and so it's that Circle as opposed to oh we're doing training now and then inference um much of the training Investments that are and that fuel this Revenue growth came before uh and we already funded that work and so that's that's an important part that's to your point that you invest now and you can get the growth later even if you slow down the capex right that that's what you're trying to tell us that's that's the cycle that is important to understand got thank you so much thanks Cash operator next question please the next question comes from the line of Mark Murphy with JP Morgan please proceed thank you very much I'm wondering if you can uh shed any more light just on the nature of the supply limitations that uh you're mentioning that are impacting Azure in Q2 um where that impact might be incrementally just a touch more than we expected is is it more the GPU uh Supply is there some element of power uh cooling or the ability to to wire up the networks and uh Amy um should we infer that uh the supply is constraining azure growth by roughly a couple few points in Q2 or am I am I overestimating that um maybe to answer uh both those questions uh Mark very directly I wouldn't think about it component logic in my Q2 answer the Supply push out as sopia said was third parties that are delivering later than we had expected um that gets pushed mainly into the second half of the year and in general Q3 um so that's third par is where we tended to buy um Supply inclusive uh of kits so it's complete endtoend third party delivery um in terms of the impact you know as I was saying you know when you think about having flat consumption um q1 to Q2 there really are only two things um that impact that difference and one was the help we got in q1 um from the revenue and revenue and accounting help and then uh Q2 has been the supply pushup thank you thanks Mark operator next question please the next question comes from the line of r l show with Barclays please proceed perfect thank you um the um if you if you talk about the market at the moment because you were first with co-pilot you had identified a lot with co-pilots and now we're talking agents um can you kind of s how do you think about that to me it looks like an evolution that we're discovering how to kind of productize AI better Etc so how do you think about that Journey you know between co-pilots agents and maybe what's coming next thank you sure um the way the system we built is um co-pilot co-pilot Studio agents and autonomous agents you should think of that as the spectrum of things right so ultimately the way uh we think about um how this all comes together is you need humans to be able to interface with AI so the UI layer for AI is copile you can then use copile Studio to extend co-pilot for example you want to connect it to your CRM system to your office system to your um you know HR System you do that through co-pilot Studio by building agents effectively you also build autonomous agents so you can use even that's the announcement we made a couple of weeks ago is you can even use copilot Studio to build autonomous agents now these autonomous agents are working independently but from time to time they need to raise is an exception right so autonomous agents are not fully autonomous because at some point they need to either notify someone or have someone input something and when they need to do that they need a UI layer and that's where again it's co-pilot so co-pilot co-pilot agents built in copilot Studio autonomous agents built in copilot Studio that's the full system uh we think that comes together and we feel very very good about the positioning and then of course we are taking the underlying system services that across that entire stack that I just talked about and I'm making it available in Azure right so you have the raw infastructure if you want it you have uh the model layer independent of it you have the AI app server and Azure AI right so everything is also a building block service in Azure for you to be able to build in fact if you want to build everything that we have built uh in the co-pilot stack you can build it yourself using the AI platform so that's sort of in simple terms our strategy and that's kind of how it all comes together okay perfect very clear thanks R operator we have time for one last question and the last question will come from the line of rishy galura with RBC please proceed oh wonderful thanks uh hi seia Amy appreciate the question um I I want to go and think a little bit about uh uh co-pilot Pro um how we should be thinking about uh kind of numbers here with the recategorization seems like that was maybe softer in the past than expected but maybe with uh the the numbers this quarter starting to pick up can you maybe walk us through what you're seeing on that and maybe more importantly how we should be thinking about your overall AI strategy on consumer versus Enterprise especially now with the Mustafa on the full thanks so much yeah on the first part uh Rishi uh to your question I think we feel very very good about the momentum we have in the commercial co-pilot right as I said in my remarks and Amy talked about this is the fastest growth of a new suite in M365 if I compare it to what we saw even back very back in E3 or E5 or the transition from o to M this is really much faster right it's the the numbers of penetration of the fortune uh you know 500 and then the fact that they're coming back for more seats and what have you so it's very strong uh in that context um the other thing I'd love to mention is that uh I we want this to be something that is system systemic right because people need to be able to put the security controls then they need to deploy then there's Skilling and then there's change management so this is not like you just it's not a tool like when I talk about co-pilot co-pilot uh Studio agents it's really as much about a new way to work um and um sometimes I describe it as what happened throughout the 90s with PC penetration after all you know if you take a business process like forecasting what was it like pre- email and Excel and post email and Excel that's the type of change uh that you see uh with copil but overall uh we feel great about the great of progress in the penetration and then on the consumer side look for us the exciting part here is to be able to use the same investment we are making in the commercial where we have structural strength uh and then be on the offense uh one of the things that I think um I hope you all catch in our earnings is uh xtac our Revenue when it comes to what we describe as search news and ads um is growing faster than market so that's uh you know it's fantastic to see that and uh you know so that's kind of a consumer business which you know in Microsoft's large scope you know it's sort of even a 10 plus billion dollar business sort of sometimes goes missing but in our case it is actually a fantastic growth business that's growing faster than Market uh we feel good about uh how we will use AI in LinkedIn in fact LinkedIn is a consumer business as you know you saw even today this week they announced some new capabilities for both consumers and in their case even uh recruiting uh so we think that AI the same investment gets monetized even through uh linkedin's Innovation um and and gaming of course is another place where you'll see some of these things uh apply and windows right so the place where I think I'm excited about is copilot plus PCS right for us it's not about having a disconnected Edge it's about having hybrid AI where uh The Rebirth of sort of the PC as the edge of AI is going to be one of the most exciting things for developers so we feel well position quite frankly uh with the same investment so this is that that's the thing that you know we're not a conglomerate here we are sort of one company that means we invest ones and then we have all these categories that you know benefit from that that's the theory of the here for us and so we feel good about all all of that coming together and maybe just to add one piece because I think rich now that I'm listening and thinking through that question um it feels like you're wondering like why am I not seeing uh the co-pilot if you got made all this progress in the results and the answer is you already are um in that infer 65 commercial number you we've seen that seat growth but those seats that we're adding uh the majority of them are driven by uh Frontline worker and small businesses those have a lower arpo point and so it masks some of the arpo that we're already seeing not just from E5 which continues to contribute but also this quarter um additional impact from co-pilot so as we go forward being able that is where you're going to see the impact will be in ARP uh in M365 commercial and as sopia said I think you'll see the impact of co-pilot engagement frankly across the same xtac number wonderful thank you thanks reishi that wraps up the Q&A portion of today's AR's call thank you for joining us today and we look forward to speaking with all of you again soon thank you this concludes today's conference you may disconnect your lines at this time enjoy the rest of your day\"},\n",
              " {'title': 'Earnings Release FY25 Q1 - Investor Relations - Microsoft',\n",
              "  'url': 'https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/performance',\n",
              "  'content': 'Cancel\\n\\nEarnings Release FY25 Q1\\n\\n=================================================\\n\\nPerformance\\n\\nRevenue increased $9.1 billion or 16% driven by growth across each of our segments. Intelligent Cloud revenue increased driven by Azure. Productivity and Business Processes revenue increased driven by Microsoft 365 Commercial cloud. More Personal Computing revenue increased driven by Gaming.\\n\\nCost of revenue increased $3.8 billion or 23% driven by growth in Microsoft Cloud and Gaming. [...] Gross margin increased $5.3 billion or 13% driven by growth across each of our segments.\\n\\n• Gross margin percentage decreased driven by Intelligent Cloud.\\n\\n• Microsoft Cloud gross margin percentage decreased to 71% driven by scaling our AI infrastructure.\\n\\nOperating expenses increased $1.6 billion or 12% driven by Gaming, with 9 points of growth from the Activision Blizzard acquisition, and investments in cloud engineering.',\n",
              "  'score': 0.92700076,\n",
              "  'raw_content': \"FY25 Q1 - Performance - Investor Relations - Microsoft\\n\\n===============\\n This is the Trace Id: fef30b3218ec59877284f41757919a7c \\n\\n![Image 1](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/performance)\\n\\n[](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/performance)\\n\\n[Skip to main content](javascript:void(0))\\n\\n[![Image 2](https://uhf.microsoft.com/images/microsoft/RE1Mu3b.png)Microsoft](https://www.microsoft.com/)\\n\\nInvestor Relations\\n\\n[Investor Relations](https://www.microsoft.com/en-us/Investor/default)\\n\\n Investor Relations \\n\\n*   [Home](https://www.microsoft.com/en-us/Investor/default)\\n*   \\nInvestor Relations\\n    *   [Home](https://www.microsoft.com/en-us/Investor/default)\\n    *   [Board & ESG](https://www.microsoft.com/en-us/Investor/corporate-governance/overview)\\n    *   [Annual Reports](https://www.microsoft.com/en-us/Investor/annual-reports)\\n    *   [SEC Filings](https://www.microsoft.com/en-us/Investor/sec-filings)\\n    *   [Events](https://www.microsoft.com/en-us/Investor/events/default)\\n    *   [Investor Information](https://www.microsoft.com/en-us/Investor/investor-information)\\n    *   [Contacts](https://www.microsoft.com/en-us/Investor/contact-information)\\n\\n*   \\nEarnings Releases\\n    *   [Press Release & Webcast](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/press-release-webcast)\\n    *   Financial Statements Financial Statements\\n        *   [Income Statements](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/income-statements)\\n        *   [Comprehensive Income](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/comprehensive-income)\\n        *   [Balance Sheets](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/balance-sheets)\\n        *   [Cash Flows](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/cash-flows)\\n        *   [Segment Revenue & Operating Income](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/segment-revenues)\\n\\n    *   [Performance](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/performance)\\n    *   [Metrics](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/metrics)\\n    *   Segment Results Segment Results\\n        *   [Productivity and Business Processes](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/productivity-and-business-processes-performance)\\n        *   [Intelligent Cloud](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/intelligent-cloud-performance)\\n        *   [More Personal Computing](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/more-personal-computing-performance)\\n\\n*   \\nFinancial Statements\\n    *   [Income Statements](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/income-statements)\\n    *   [Comprehensive Income](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/comprehensive-income)\\n    *   [Balance Sheets](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/balance-sheets)\\n    *   [Cash Flows](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/cash-flows)\\n    *   [Segment Revenue & Operating Income](https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q1/segment-revenues)\\n\\n*   More \\n\\n*   \\nAll Microsoft\\n    *   Global\\n------\\n\\n        *   [Microsoft 365](https://www.microsoft.com/microsoft-365)\\n        *   [Teams](https://www.microsoft.com/en-us/microsoft-teams/group-chat-software)\\n        *   [Copilot](https://copilot.microsoft.com/)\\n        *   [Windows](https://www.microsoft.com/en-us/windows/)\\n        *   [Surface](https://www.microsoft.com/surface)\\n        *   [Xbox](https://www.xbox.com/)\\n        *   [Deals](https://www.microsoft.com/en-us/store/b/sale?icid=gm_nav_L0_salepage)\\n        *   [Small Business](https://www.microsoft.com/en-us/store/b/business)\\n        *   [Support](https://support.microsoft.com/en-us)\\n\\n    *   Software Software\\n        *   [Windows Apps](https://apps.microsoft.com/home)\\n        *   [AI](https://www.microsoft.com/en-us/ai)\\n        *   [Outlook](https://www.microsoft.com/en-us/microsoft-365/outlook/email-and-calendar-software-microsoft-outlook)\\n        *   [OneDrive](https://www.microsoft.com/en-us/microsoft-365/onedrive/online-cloud-storage)\\n        *   [Microsoft Teams](https://www.microsoft.com/en-us/microsoft-teams/group-chat-software)\\n        *   [OneNote](https://www.microsoft.com/en-us/microsoft-365/onenote/digital-note-taking-app)\\n        *   [Microsoft Edge](https://www.microsoft.com/edge)\\n        *   [Moving from Skype to Teams](https://support.microsoft.com/en-us/office/moving-from-skype-to-microsoft-teams-free-3c0caa26-d9db-4179-bcb3-930ae2c87570?icid=DSM_All_Skype)\\n\\n    *   PCs & Devices PCs & Devices \\n        *   [Computers](https://www.microsoft.com/en-us/store/b/pc?icid=CNavDevicesPC)\\n        *   [Shop Xbox](https://www.microsoft.com/en-us/store/b/xbox?icid=CNavDevicesXbox)\\n        *   [Accessories](https://www.microsoft.com/en-us/store/b/accessories?icid=CNavDevicesAccessories)\\n        *   [VR & mixed reality](https://www.microsoft.com/en-us/store/b/virtualreality?icid=CNavVirtualReality)\\n        *   [Certified Refurbished](https://www.microsoft.com/en-us/store/b/certified-refurbished-products)\\n        *   [Trade-in for cash](https://www.microsoft.com/en-us/store/b/microsoft-trade-in)\\n\\n    *   Entertainment Entertainment\\n        *   [Xbox Game Pass Ultimate](https://www.xbox.com/en-us/games/store/xbox-game-pass-ultimate/cfq7ttc0khs0?icid=CNavAllXboxGamePassUltimate)\\n        *   [PC Game Pass](https://www.xbox.com/en-us/games/store/pc-game-pass/cfq7ttc0kgq8?icid=CNavAllPCGamePass)\\n        *   [Xbox games](https://www.microsoft.com/en-us/store/b/xboxgames?icid=CNavGamesXboxGames)\\n        *   [PC games](https://apps.microsoft.com/games)\\n\\n    *   Business Business\\n        *   [Microsoft Cloud](https://www.microsoft.com/en-us/microsoft-cloud)\\n        *   [Microsoft Security](https://www.microsoft.com/en-us/security)\\n        *   [Dynamics 365](https://www.microsoft.com/en-us/dynamics-365)\\n        *   [Microsoft 365 for business](https://www.microsoft.com/en-us/microsoft-365/business)\\n        *   [Microsoft Power Platform](https://www.microsoft.com/en-us/power-platform)\\n        *   [Windows 365](https://www.microsoft.com/en-us/windows-365)\\n        *   [Microsoft Industry](https://www.microsoft.com/en-us/industry)\\n        *   [Small Business](https://www.microsoft.com/en-us/store/b/business?icid=CNavBusinessStore)\\n\\n    *   Developer & IT Developer & IT \\n        *   [Azure](https://azure.microsoft.com/en-us/)\\n        *   [Microsoft Developer](https://developer.microsoft.com/en-us/)\\n        *   [Microsoft Learn](https://learn.microsoft.com/)\\n        *   [Support for AI marketplace apps](https://www.microsoft.com/isv/isv-success?ocid=cmm3atxvn98)\\n        *   [Microsoft Tech Community](https://techcommunity.microsoft.com/)\\n        *   [Azure Marketplace](https://azuremarketplace.microsoft.com/en-us/)\\n        *   [AppSource](https://appsource.microsoft.com/en-us/)\\n        *   [Visual Studio](https://visualstudio.microsoft.com/)\\n\\n    *   Other Other\\n        *   [Microsoft Rewards](https://www.microsoft.com/rewards)\\n        *   [Free downloads & security](https://www.microsoft.com/en-us/download)\\n        *   [Education](https://www.microsoft.com/en-us/education)\\n        *   [Licensing](https://www.microsoft.com/licensing/)\\n        *   [Unlocked stories](https://unlocked.microsoft.com/)\\n\\n    *   [View Sitemap](https://www.microsoft.com/en-us/sitemap)\\n\\nSearch Search or ask a question\\n\\n*   No results\\n\\nCancel\\n\\nEarnings Release FY25 Q1\\n========================\\n=================================================\\n\\nPerformance\\n-----------\\n\\nRevenue increased $9.1 billion or 16% driven by growth across each of our segments. Intelligent Cloud revenue increased driven by Azure. Productivity and Business Processes revenue increased driven by Microsoft 365 Commercial cloud. More Personal Computing revenue increased driven by Gaming.\\n\\nCost of revenue increased $3.8 billion or 23% driven by growth in Microsoft Cloud and Gaming.\\n\\nGross margin increased $5.3 billion or 13% driven by growth across each of our segments.\\n\\n• Gross margin percentage decreased driven by Intelligent Cloud.\\n\\n• Microsoft Cloud gross margin percentage decreased to 71% driven by scaling our AI infrastructure.\\n\\nOperating expenses increased $1.6 billion or 12% driven by Gaming, with 9 points of growth from the Activision Blizzard acquisition, and investments in cloud engineering.\\n\\nOperating income increased $3.7 billion or 14% driven by growth in Productivity and Business Processes and Intelligent Cloud.\\n\\n_IMPORTANT NOTICE TO USERS (summary only, [click here](https://www.microsoft.com/en-us/Investor/long-disclaimer.html) for full text of notice)_ All information is unaudited unless otherwise noted or accompanied by an audit opinion and is subject to the more comprehensive information contained in our SEC reports and filings. We do not endorse third-party information. All information speaks as of the last fiscal quarter or year for which we have filed a Form 10-K or 10-Q, or for historical information the date or period expressly indicated in or with such information. We undertake no duty to update the information. Forward-looking statements are subject to risks and uncertainties described in our [Forms 10-Q and 10-K.](https://www.microsoft.com/en-us/Investor/sec-filings.aspx)\\n\\n### Download Earnings Related Files\\n\\nInformation contained in these documents is current as of the earnings date, and not restated for new accounting standards\\n\\n*   Earnings Call Slides \\n*   Earnings Call Transcript \\n*   Financial Statements \\n*   Outlook \\n*   Press Release \\n*   10Q \\n*   FY25Q1 Product Release List \\n ASSET PACKAGE \\n\\n#### Earnings Release Pages\\n\\n*   [Metrics](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/metrics)\\n\\n*   [Performance](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/performance)\\n\\n*   [Press Release & Webcast](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/press-release-webcast)\\n\\n*   [Financial Statements](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/income-statements)\\n\\n*   [Segment Results](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/productivity-and-business-processes-performance)\\n\\n*   [Customer & Partner Highlights](https://aka.ms/FY25Q1Blog)\\n\\n#### Related Information\\n\\n*   [Webcast](https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q1)\\n\\n*   [SEC Filings](https://www.microsoft.com/en-us/investor/sec-filings)\\n\\n*   [XBRL](https://www.microsoft.com/en-us/investor/sec-filings?year=2025&filing=xbrl)\\n\\nMicrosoft Corp (MSFT)\\n---------------------\\n\\n[![Image 3: ar2024](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/Ar2024-2-600X400)](https://www.microsoft.com/investor/reports/ar24/index.html)\\n###### 2024 ANNUAL REPORT\\n\\n[VIEW ONLINE](https://www.microsoft.com/investor/reports/ar24/index.html)\\n\\n[DOWNLOAD NOW](https://www.microsoft.com/investor/reports/ar24/download-center/)\\n\\n Follow us \\n\\n*   [![Image 4: Facebook](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/Icon_Facebook_2x-1?scl=1)](https://www.facebook.com/Microsoft)\\n*   [![Image 5: X](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/Accessibility_Icon_X_40x40_v1?scl=1)](https://x.com/Microsoft?mx=2)\\n*   [![Image 6: LinkedIn](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/LinkedIn_64x64?scl=1)](https://www.linkedin.com/company/microsoft)\\n*   [![Image 7: youtube](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/youtube-flat-64x64?scl=1)](https://www.youtube.com/microsoft)\\n\\n Share this page \\n\\n*   [![Image 8: Facebook](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/Icon_Facebook_2x-1?scl=1)](http://www.facebook.com/sharer.php?u=https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/performance)\\n*   [![Image 9: LinkedIn](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/LinkedIn_64x64?scl=1)](http://www.linkedin.com/shareArticle?url=https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/performance)\\n*   [![Image 10: Email](https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/email-8?scl=1)](mailto:?subject=Microsoft%20Investor%20Relations%20%20Link&body=Here%20is%20some%20information%20from%20the%20Microsoft%20Investor%20Relations%20website%20that%20I%20thought%20you%27d%20be%20interested%20in:%20%0A%0Ahttps://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/performance)\\n\\nWhat's new\\n\\n*   [Surface Pro](https://www.microsoft.com/surface/devices/surface-pro)\\n*   [Surface Laptop](https://www.microsoft.com/surface/devices/surface-laptop)\\n*   [Surface Laptop Studio 2](https://www.microsoft.com/en-us/d/Surface-Laptop-Studio-2/8rqr54krf1dz)\\n*   [Copilot for organizations](https://www.microsoft.com/en-us/microsoft-copilot/organizations?icid=DSM_Footer_CopilotOrganizations)\\n*   [Copilot for personal use](https://www.microsoft.com/en-us/microsoft-copilot/for-individuals?icid=DSM_Footer_CopilotPersonal)\\n*   [AI in Windows](https://www.microsoft.com/en-us/windows/copilot-ai-features)\\n*   [Explore Microsoft products](https://www.microsoft.com/en-us/microsoft-products-and-apps)\\n*   [Windows 11 apps](https://www.microsoft.com/windows/windows-11-apps)\\n\\nMicrosoft Store\\n\\n*   [Account profile](https://account.microsoft.com/)\\n*   [Download Center](https://www.microsoft.com/en-us/download)\\n*   [Microsoft Store support](https://go.microsoft.com/fwlink/?linkid=2139749)\\n*   [Returns](https://www.microsoft.com/en-us/store/b/returns)\\n*   [Order tracking](https://www.microsoft.com/en-us/store/b/order-tracking)\\n*   [Certified Refurbished](https://www.microsoft.com/en-us/store/b/certified-refurbished-products)\\n*   [Microsoft Store Promise](https://www.microsoft.com/en-us/store/b/why-microsoft-store?icid=footer_why-msft-store_7102020)\\n*   [Flexible Payments](https://www.microsoft.com/en-us/store/b/payment-financing-options?icid=footer_financing_vcc)\\n\\nEducation\\n\\n*   [Microsoft in education](https://www.microsoft.com/en-us/education)\\n*   [Devices for education](https://www.microsoft.com/en-us/education/devices/overview)\\n*   [Microsoft Teams for Education](https://www.microsoft.com/en-us/education/products/teams)\\n*   [Microsoft 365 Education](https://www.microsoft.com/en-us/education/products/microsoft-365)\\n*   [How to buy for your school](https://www.microsoft.com/education/how-to-buy)\\n*   [Educator training and development](https://education.microsoft.com/)\\n*   [Deals for students and parents](https://www.microsoft.com/en-us/store/b/education)\\n*   [AI for education](https://www.microsoft.com/en-us/education/ai-in-education)\\n\\nBusiness\\n\\n*   [Microsoft Cloud](https://www.microsoft.com/en-us/microsoft-cloud)\\n*   [Microsoft Security](https://www.microsoft.com/en-us/security)\\n*   [Dynamics 365](https://www.microsoft.com/en-us/dynamics-365)\\n*   [Microsoft 365](https://www.microsoft.com/en-us/microsoft-365/business)\\n*   [Microsoft Power Platform](https://www.microsoft.com/en-us/power-platform)\\n*   [Microsoft Teams](https://www.microsoft.com/en-us/microsoft-teams/group-chat-software)\\n*   [Microsoft 365 Copilot](https://www.microsoft.com/en-us/microsoft-365/copilot/copilot-for-work)\\n*   [Small Business](https://www.microsoft.com/en-us/store/b/business?icid=CNavBusinessStore)\\n\\nDeveloper & IT\\n\\n*   [Azure](https://azure.microsoft.com/en-us/)\\n*   [Microsoft Developer](https://developer.microsoft.com/en-us/)\\n*   [Microsoft Learn](https://learn.microsoft.com/)\\n*   [Support for AI marketplace apps](https://www.microsoft.com/isv/isv-success?ocid=cmm3atxvn98)\\n*   [Microsoft Tech Community](https://techcommunity.microsoft.com/)\\n*   [Azure Marketplace](https://azuremarketplace.microsoft.com/)\\n*   [AppSource](https://appsource.microsoft.com/en-us/)\\n*   [Visual Studio](https://visualstudio.microsoft.com/)\\n\\nCompany\\n\\n*   [Careers](https://careers.microsoft.com/)\\n*   [About Microsoft](https://www.microsoft.com/about)\\n*   [Company news](https://news.microsoft.com/)\\n*   [Privacy at Microsoft](https://privacy.microsoft.com/en-us)\\n*   [Investors](https://www.microsoft.com/investor/default.aspx)\\n*   [Diversity and inclusion](https://www.microsoft.com/en-us/diversity/)\\n*   [Accessibility](https://www.microsoft.com/en-us/accessibility)\\n*   [Sustainability](https://www.microsoft.com/en-us/sustainability/)\\n\\n[English (United States)](http://www.microsoft.com/en-us/locale.aspx)[Your Privacy Choices](https://aka.ms/yourcaliforniaprivacychoices)[Consumer Health Privacy](https://go.microsoft.com/fwlink/?linkid=2259814)\\n*   [Sitemap](https://www.microsoft.com/en-us/sitemap1.aspx)\\n*   [Contact Microsoft](https://support.microsoft.com/contactus)\\n*   [Privacy](https://go.microsoft.com/fwlink/?LinkId=521839)\\n*   [Manage cookies](https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/performance#)\\n*   [Terms of use](https://go.microsoft.com/fwlink/?LinkID=206977)\\n*   [Trademarks](https://go.microsoft.com/fwlink/?linkid=2196228)\\n*   [Safety & eco](https://go.microsoft.com/fwlink/?linkid=2196227)\\n*   [Recycling](https://www.microsoft.com/en-us/legal/compliance/recycling)\\n*   [About our ads](https://choice.microsoft.com/)\\n*   © Microsoft 2025\\n\"},\n",
              " {'title': 'Microsoft Fiscal Year 2025 First Quarter Earnings Conference Call',\n",
              "  'url': 'https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q1',\n",
              "  'content': 'Thank you, Satya, and good afternoon everyone. This quarter, revenue was $65.6 billion, up 16%, and earnings per share was $3.30, an increase of 10%.\\n\\nWith strong execution by our sales teams and partners, we delivered a solid start to our fiscal year with double-digit top and bottom-line growth. We also saw continued share gains across many of our businesses. In our commercial business, increased demand and growth in long-term commitments to our Microsoft Cloud platform drove our results. [...] This quarter, other income and expense was negative $283 million, significantly more favorable than anticipated due to foreign currency remeasurement and net gains on investments. Our losses on investments accounted for under the equity method were as expected.\\n\\nOur effective tax rate was approximately 19%.\\n\\nAnd finally, we returned $9 billion to shareholders through dividends and share repurchases. [...] And in Gaming, revenue increased 43% and 44% in constant currency, with 43 points of net impact from the Activision acquisition. Results were ahead of expectations driven by stronger-than-expected performance in both first- and third-party content as well as consoles. Xbox content and services revenue increased 61% with 53 points of net impact from the Activision acquisition.',\n",
              "  'score': 0.9231018,\n",
              "  'raw_content': \"This is the Trace Id: 97e495e25a0326c748aff9a994a37e40\\n\\n\\n\\n[Skip to main content](javascript:void(0))\\n\\n\\n[Microsoft](https://www.microsoft.com)\\n\\nInvestor Relations\\n\\n[Investor Relations](/en-us/investor/default)\\n\\nMicrosoft Fiscal Year 2025 First Quarter Earnings Conference Call\\n\\n*Wednesday, October 30, 2024*  \\nSatya Nadella, Chairman and CEO and Amy Hood, EVP & CFO\\n\\n# Microsoft FY25 First Quarter Earnings Conference Call\\n\\nBrett Iversen, Satya Nadella, Amy Hood\\n\\nWednesday October 30, 2024\\n\\n**BRETT IVERSEN:**\\n\\nGood afternoon and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer, Amy Hood, chief financial officer, Alice Jolla, chief accounting officer, and Keith Dolliver, corporate secretary and deputy general counsel.\\n\\nOn the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today’s call and provides the reconciliation of differences between GAAP and non-GAAP financial measures. We have recast certain prior period amounts to reflect the FY25 changes to the composition of our segments announced in August 2024. Additional details including FY23 and FY24 recast segment revenue, operating income, and product and servicelevel revenue can be found in the financial statements file on the Investor Relations website. More detailed outlook slides will also be available on the Microsoft Investor Relations website when we provide outlook commentary on today’s call.\\n\\nOn this call we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a\\xa0substitute for or superior to the measures of financial performance prepared in accordance with GAAP.\\xa0They are included as additional clarifying items to aid investors in further understanding the company's first quarter performance in addition to the impact these items and events have on the financial results.\\n\\nAll growth comparisons we make on the call today relate to the corresponding period of last year unless otherwise noted. We will also provide growth rates in constant currency, when available, as a framework for assessing how our underlying businesses performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only.\\n\\nWe will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript, and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website.\\n\\nDuring this call, we will be making forward-looking statements which are predictions, projections, or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call, and in the risk factor section of our Form 10-K, Forms 10-Q, and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement.\\n\\nAnd with that, I’ll turn the call over to Satya.\\n\\n**SATYA NADELLA:**\\n\\nThank you, Brett.\\n\\nWe are off to a solid start to our fiscal year, driven by continued strength of the Microsoft Cloud, which surpassed $38.9 billion in revenue, up 22%.\\n\\nAI-driven transformation is changing work, work artifacts, and workflow across every role, function, and business process, helping customers drive new growth and operating leverage.\\n\\nAll-up, our AI business is on track to surpass an annual revenue run rate of $10 billion next quarter, which will make it the fastest business in our history to reach this milestone.\\n\\nNow, I will highlight examples of our progress, starting with infrastructure.\\n\\nAzure took share this quarter.\\n\\nWe are seeing continued growth in cloud migration.\\n\\nAzure Arc now has over 39,000 customers across every industry, including American Tower, CTT, L’Oreal, up more than 80% year-over-year.\\n\\nWe now have datacenters in over 60 regions around the world, and this quarter we announced new cloud and AI infrastructure investments in Brazil, Italy, Mexico, and Sweden, as we expand our capacity in line with long-term demand signals.\\n\\nAt the silicon layer, our new Cobalt 100 VMs are being used by companies like Databricks, Elastic, Siemens, Snowflake, and Synopsys to power their general-purpose workloads at up to 50% better price-performance than previous generations.\\n\\nOn top of this, we are building out our next generation AI infrastructure, innovating across the full stack to optimize our fleet for AI workloads.\\n\\nWe offer the broadest selection of AI accelerators, including our first party accelerator Maia 100, as well as the latest GPUs from AMD and NVIDIA.\\n\\nIn fact, we were the first cloud to bring up NVIDIA’s Blackwell system with GB200-powered AI servers.\\n\\nOur partnership with OpenAI also continues to deliver results.\\n\\nWe have an economic interest in a company that has grown significantly in value.\\n\\nAnd we have built differentiated IP and are driving revenue momentum.\\n\\nMore broadly, with Azure AI, we are building an end-to-end app platform to help customers build their own copilots and agents.\\n\\nAzure OpenAI usage more than doubled over the past six months, as both digital natives like Grammarly and Harvey, as well as established enterprises like Bajaj Finance, Hitachi, KT, and LG, move apps from test to production.\\n\\nGE Aerospace, for example, used Azure OpenAI to build a new digital assistant for all 52,000 of its employees. In just three months, it has been used to conduct over 500,000 internal queries, and process more than 200,000 documents.\\n\\nAnd this quarter, we added support for OpenAI’s newest model family “o1.”\\n\\nWe are also bringing industry-specific models to Azure AI, including a collection of best-in-class multimodal models for medical imaging.\\n\\nAnd, with GitHub Models, we now provide access to our full model catalog directly within the GitHub developer workflow.\\n\\nAzure AI is also increasingly an on-ramp to our data and analytics services.\\n\\nAs developers build new AI apps on Azure, we have seen an acceleration of Azure Cosmos DB and Azure SQL DB Hyperscale usage, as customers like Air India, Novo Nordisk, Telefonica, Toyota Motor North America, and Uniper take advantage of capabilities purpose-built for AI applications.\\n\\nAnd with Microsoft Fabric we provide a single AI-powered platform to help customers like Chanel, EY, KPMG, Swiss Air, and Syndigo unify their data across clouds.\\n\\nWe now have over 16,000 paid Fabric customers, including over 70% of the Fortune 500.\\n\\nNow, on to developers.\\n\\nGitHub Copilot is changing the way the world builds software.\\n\\nCopilot Enterprise customers increased 55% quarter-over-quarter as\\xa0 companies like AMD and Flutter Entertainment tailor Copilot to their own codebase.\\n\\nAnd we are introducing the next phase of AI code generation, making GitHub Copilot agentic across the developer workflow.\\n\\nGitHub Copilot Workspace is a developer environment which leverages agents from start to finish, so developers can go from spec, to plan, to code, all in natural language.\\n\\nCopilot Autofix is an AI agent that helps developers at companies like Asurion and Otto Group fix vulnerabilities in their code over three times faster than it would take them on their own.\\n\\nWe are also continuing to build on GitHub’s open platform ethos by making more models available via GitHub Copilot.\\n\\nAnd we are expanding the reach of GitHub to a new segment of developers, introducing GitHub Spark, which enables anyone to build apps in natural language.\\n\\nAlready, we have brought generative AI to Power Platform to help customers use our low-code/no-code tools to cut costs and development time.\\n\\nTo date, nearly 600,000 organizations have used AI-powered capabilities in Power Platform, up 4X year-over-year.\\n\\nCitizen developers at ZF, for example, build apps simply by describing what they need using natural language.\\n\\nAnd this quarter we introduced new ways for customers to apply AI to streamline complex workflows with Power Automate.\\n\\nNow, on to work.\\n\\nWe launched the next wave of Microsoft 365 Copilot innovation last month, bringing together web, work, and Pages as a new design system for knowledge work.\\n\\nPages is the first new digital artifact for the AI age, and it is designed to help you ideate with AI and collaborate with other people.\\n\\nWe have also made Microsoft 365 Copilot responses 2X faster and improved response quality by nearly 3X.\\n\\nThis innovation is driving accelerated usage, and the number of people who use Microsoft 365 Copilot daily more than doubled quarter-over-quarter.\\n\\nWe are also seeing increased adoption from customers in every industry as they use Microsoft 365 Copilot to drive real business value.\\n\\nVodafone, for example, will roll out Microsoft 365 Copilot to 68,000 employees after a trial showed that on average they saved three hours per person per week. And UBS will deploy 50,000 seats, in our largest FinServ deal to date.\\n\\nAnd we continue to see enterprise customers coming back to buy more seats.\\n\\nAll-up, nearly 70% of the Fortune 500 now use Microsoft 365 Copilot, and customers continue to adopt it at a faster rate than any other new Microsoft 365 suite.\\n\\nCopilot is the UI for AI, and with Microsoft 365 Copilot, Copilot Studio, agents, and now autonomous agents we have built an end-to-end system for AI business transformation.\\n\\nWith Copilot Studio, organizations can build and connect Microsoft 365 Copilot to autonomous agents, which then delegate to Copilot when there is an exception.\\n\\nMore than 100,000 organizations, from Nsure, Standard Bank, and Thomson Reuters, to Virgin Money and Zurich Insurance have used Copilot Studio to date, up over 2X quarter-over-quarter.\\n\\nMore broadly, we are seeing AI drive a fundamental change in the business applications market, as customers shift from legacy apps to AI-first business process.\\n\\nDynamics 365 continues to take share as organizations like Everon, HEINEKEN, and Lexmark choose our apps over other providers.\\n\\nAnd monthly active users of Copilot across our CRM and ERP portfolio increased over 60% quarter-over-quarter.\\n\\nOur Dynamics 365 Contact Center is also winning customers like Currys, Le Creuset, and RXO, as it brings generative AI to every customer engagement channel.\\n\\nAnd just last week, we added 10 out-of-the-box autonomous agents to Dynamics 365 that help customers automatically qualify sales leads, track suppliers, and work hand in hand with service reps to resolve issues.\\n\\nWe are also bringing AI to industry-specific workflows.\\n\\nOne year in, DAX Copilot is now documenting over 1.3 million physician-patient encounters each month at over 500 healthcare organizations like Baptist Medical Group, Baylor Scott & White, Greater Baltimore Medical Center, Novant Health, and Overlake Medical Center.\\n\\nIt is showing faster revenue growth than GitHub Copilot did in its first year.\\n\\nAnd new features extend DAX beyond notes, helping physicians automatically draft referrals, after visit instructions, and diagnostic evidence.\\n\\nOn top of all of this AI innovation, Microsoft Teams usage remains at all-time highs as people use it to streamline all their communications.\\n\\nNearly 75% of our Teams Enterprise customers now buy Premium, Phone, or Rooms.\\n\\nWhen it comes to Windows, our new class of Copilot+ PCs is winning new customers.\\n\\nThey offer best-in-class AI capability, performance, and value.\\n\\nAMD, Intel, and Qualcomm now all support Copilot+ PCs.\\n\\nThis quarter we also introduced new AI experiences only available on Copilot+ PCs, like Click to Do, which places an interactive overlay over your desktop to suggest “next best actions.”\\n\\nAnd, as we approach the end of support for Windows 10 a year from now, we are well positioned to transition our customers to Windows 11, ensuring they benefit from the enhanced features and security improvements we have introduced over the past few years.\\n\\nNow, on to security.\\n\\nWe continue to prioritize security above all else.\\n\\nWith our Secure Future Initiative, we have dedicated the equivalent of 34,000 full-time engineers to address the highest priority security tasks.\\n\\nWe have made significant progress to better protect tenants, identities, networks, and engineering systems, and have created new processes to ensure security is prioritized at every level of the company.\\n\\nAnd we continue to take what we learn and turn it into innovation across our products.\\n\\nSecurity Copilot, for example, is being used by companies in every industry, including Clifford Chance, Intesa Sanpaolo, and Shell, to perform SecOps tasks faster and more accurately.\\n\\nAnd we are helping customers protect their AI deployments too.\\n\\nCustomers have used Defender to discover and secure more than 750,000 GenAI app instances; and used Purview to audit over a billion Copilot interactions to meet their compliance obligations.\\n\\nAnd, all up, we continue to take share across all major categories we serve and are consistently recognized by top analysts as the leader in 20 categories, more than any other vendor.\\n\\nNow, let me turn to our consumer businesses, starting with LinkedIn.\\n\\nMember growth continues to accelerate, with markets like India and Brazil both growing at double digits.\\n\\nWe are also seeing record engagement as we introduce new ways for our more than one billion members to connect, sell services, get hired, and share knowledge.\\n\\nOur investments in rich formats, like video, strengthen our leadership in B2B advertising and amplify the value we deliver to our customers. Weekly immersive video views increased 6x quarter-over-quarter and total video viewership on LinkedIn is up 36% year-over-year.\\n\\nOur AI-powered tools also continue to transform how people sell, learn, and hire.\\n\\nIn sales, new AI features help every team member perform at the level of top sellers and drive more profitable growth.\\n\\nIn learning, just yesterday, we announced updates to our coaching experience, including personalized career development plans.\\n\\nLinkedIn’s first agent, Hiring Assistant, will help hirers find qualified candidates faster by tackling the most time-consuming tasks.\\n\\nAlready, hirers who use AI-assisted messages see a 44% higher acceptance rate compared to those who don’t.\\n\\nAnd, our hiring business continues to take share.\\n\\nNow, on to Search, Advertising and News.\\n\\nWith Copilot, we are taking the first steps towards creating an AI companion for everyone.\\n\\nThe new Copilot experience we introduced earlier this month includes a refreshed design and tone, along with improved speed and fluency across web and mobile.\\n\\nAnd it includes advanced capabilities like Voice and Vision that make it more delightful and useful, and feel more natural. You can both browse and converse with Copilot simultaneously, because Copilot sees what you see.\\n\\nMore broadly, AI is also transforming search, browsers, and digital advertising, and we continue to take share across Bing and Edge.\\n\\nBing ex-TAC revenue growth outpaced the Search market.\\n\\nNow, on to gaming.\\n\\nOne year since we closed our acquisition of Activision Blizzard King, we are focused on building a business positioned for long-term growth, driven by higher-margin content and services.\\n\\nYou already see this transformation in our results, as we diversify the ways that gamers access our content.\\n\\nWe set new records for monthly active users in the quarter, as more players than ever play our games across devices and on the Xbox platform.\\n\\nGame Pass also set a new Q1 record for total revenue and average revenue per subscriber.\\n\\nAnd, as we look ahead, our IP across our studios has never been stronger.\\n\\nLast week’s launch of Black Ops 6 was the biggest Call of Duty release ever, setting a record for day one players, as well as Game Pass subscriber adds on launch day. And unit sales on PlayStation and Steam were also up over 60% year-over-year.\\n\\nThis speaks to our strategy of meeting gamers where they are by enabling them to play more games across the screens they spend their time on.\\n\\nIn closing, we are rapidly innovating to expand our opportunity across our commercial and consumer businesses.\\n\\nIn three weeks time, we will hold our Ignite conference, and I look forward to sharing more then about how we are helping every business function use AI to drive growth in this new era.\\n\\nWith that, let me turn it over to Amy.\\n\\n**AMY HOOD:**\\n\\nThank you, Satya, and good afternoon everyone. This quarter, revenue was $65.6 billion, up 16%, and earnings per share was $3.30, an increase of 10%.\\n\\nWith strong execution by our sales teams and partners, we delivered a solid start to our fiscal year with double-digit top and bottom-line growth. We also saw continued share gains across many of our businesses. In our commercial business, increased demand and growth in long-term commitments to our Microsoft Cloud platform drove our results.\\n\\nCommercial bookings were ahead of expectations and increased 30% and 23% in constant currency. Results were driven by strong execution across our core annuity sales motions and growth in the number of 10-million-dollar-plus contracts for both Azure and Microsoft 365. Additionally, we also saw an increase in the number of 100-million-dollar-plus contracts for Azure.\\n\\nCommercial remaining performance obligation increased 22% and 21% in constant currency to $259 billion. Roughly 40% will be recognized in revenue in the next 12 months, up 17% year-over-year. The remaining portion, recognized beyond the next 12 months, increased 27%. And this quarter, our annuity mix increased to 98%.\\n\\nIn addition to commercial results that were in line with expectations, we also saw some benefit from in-period revenue recognition across Microsoft 365 commercial, Azure, and our on-premises server business.\\n\\nAt a company level, Activision contributed a net impact of approximately 3 points to revenue growth, was a 2 point drag on operating income growth, and had a negative 5 cent impact to earnings per share. A reminder that this net impact includes adjusting for the movement of Activision content from our prior relationship as a third-party partner to first-party and includes $911 million from purchase accounting adjustments, integration, and transaction-related costs.\\n\\nFX did not have a significant impact on our results and was roughly in line with expectations on total company revenue, segment level revenue, COGS, and operating expense growth.\\n\\nMicrosoft Cloud revenue was $38.9 billion and grew 22%, roughly in line with expectations. Microsoft Cloud gross margin percentage decreased 2 points year-over-year to 71%. This was slightly better than expected due to improvement in Azure, although the gross margin percentage decrease year-over-year continues to be driven by scaling our AI infrastructure.\\n\\nCompany gross margin dollars increased 13% and 14% in constant currency and gross margin percentage was 69%, down 2 points year-over-year driven by the lower Microsoft Cloud gross margin noted earlier, as well as the impact from purchase accounting adjustments, integration, and transaction-related costs from the Activision acquisition.\\n\\nOperating expenses increased 12%, lower than expected due to our focus on cost efficiencies and ongoing prioritization work. Operating expense growth included 9 points from the Activision acquisition.\\n\\nAt a total company level, headcount at the end of September was 8% higher than a year ago. Excluding the growth from the Activision acquisition, headcount was 2% higher.\\n\\nOperating income increased 14% and operating margins were 47%, down 1 point year-over-year. Excluding the net impact from the Activision acquisition, operating margins were up 1 point as we continue to drive efficiencies across our businesses as we invest in AI infrastructure and capabilities.\\n\\nNow to our segment results.\\n\\nRevenue from Productivity and Business Processes was $28.3 billion and grew 12% and 13% in constant currency, ahead of expectations driven by better-than-expected results across all businesses.\\n\\nM365 commercial cloud revenue increased 15% and 16% in constant currency with business trends that were as expected. The better-than-expected result was due to a small benefit from the in-period revenue recognition noted earlier. ARPU growth was primarily driven by E5 as well as M365 Copilot. Paid M365 commercial seats grew 8% year-over-year with installed base expansion across all customer segments. Seat growth was driven by our small and medium business and frontline worker offerings. M365 commercial cloud revenue represents nearly 90% of total M365 commercial products and cloud services.\\n\\nM365 commercial products revenue increased 2% and 3% in constant currency, ahead of expectations primarily due to the benefit from in-period revenue recognition noted earlier.\\n\\nM365 consumer products and cloud services revenue increased 5% and 6% in constant currency. M365 consumer cloud revenue increased 6% and 7% in constant currency with continued momentum in M365 consumer subscriptions, which grew 10% to 84.4 million. M365 consumer cloud revenue represents 85% of total M365 consumer products and cloud services.\\n\\nLinkedIn revenue increased 10% and 9% in constant currency, slightly ahead of expectations, with growth across all lines of business.\\n\\nDynamics revenue grew 14%, driven by Dynamics 365 which grew 18% and 19% in constant currency with continued growth across all workloads and continued share gains. As a reminder, Dynamics 365 represents about 90% of total Dynamics revenue.\\n\\nSegment gross margin dollars increased 11% and 12% in constant currency and gross margin percentage decreased slightly year-over-year driven by scaling our AI infrastructure. Operating expenses increased 2% and operating income increased 16%.\\n\\nNext, the Intelligent Cloud segment. Revenue was $24.1 billion, increasing 20% and 21% in constant currency, in line with expectations.\\n\\nAzure and other cloud services revenue grew 33% and 34% in constant currency, with healthy consumption trends that were in line with expectations. The better-than-expected result was due to the small benefit from in-period revenue recognition noted earlier. Azure growth included roughly 12 points from AI services, similar to last quarter. Demand continues to be higher than our available capacity. Non-AI growth trends were also in line with expectations in total and across regions as customers continue to migrate and modernize on the Azure platform. The non-AI point contribution to Azure growth was sequentially lower by approximately 1 point.\\n\\nIn our on-premises server business, revenue decreased 1%. Lower-than-expected transactional purchasing ahead of the Windows Server 2025 launch, as well as lower purchasing of licenses running in multi-cloud environments, was mostly offset by the benefit from in-period revenue recognition noted earlier.\\n\\nEnterprise and partner services revenue decreased 1% and was relatively unchanged in constant currency.\\n\\nSegment gross margin dollars increased 15% and gross margin percentage decreased 3 points year-over-year driven by scaling our AI infrastructure. Operating expenses increased 8% and operating income grew 18%.\\n\\nNow to More Personal Computing. Revenue was $13.2 billion, increasing 17%, with 15 points of net impact from the Activision acquisition. Results were above expectations driven by Gaming and Search.\\n\\nWindows OEM and Devices revenue increased 2% year-over-year as better-than-expected results in Windows OEM due to mix shift to higher monetizing markets was partially offset by the lower-than-expected results in Devices due to execution challenges in the commercial segment.\\n\\nSearch and news advertising revenue ex-TAC increased 18% and 19% in constant currency, ahead of expectations primarily due to continued execution improvement. We saw rate expansion in addition to healthy volume growth in both Edge and Bing.\\n\\nAnd in Gaming, revenue increased 43% and 44% in constant currency, with 43 points of net impact from the Activision acquisition. Results were ahead of expectations driven by stronger-than-expected performance in both first- and third-party content as well as consoles. Xbox content and services revenue increased 61% with 53 points of net impact from the Activision acquisition.\\n\\nSegment gross margin dollars increased 16% and 17% in constant currency, with 12 points of net impact from the Activision acquisition. Gross margin percentage was relatively unchanged year-over-year. Our strong execution on margin improvement in Gaming and Search was offset by sales mix shift to those businesses.\\n\\nOperating expenses increased 49% with 51 points from the Activision acquisition. Operating income decreased 4%.\\n\\nNow back to total company results.\\n\\nCapital expenditures including finance leases were $20 billion, in line with expectations, and cash paid for P, P, and E was $14.9 billion. Roughly half of our cloud and AI related spend continues to be for long-lived assets that will support monetization over the next 15 years and beyond. The remaining cloud and AI spend is primarily for servers, both CPUs and GPUs, to serve customers based on demand signals.\\n\\nCash flow from operations was $34.2 billion, up 12% driven by strong cloud billings and collections, partially offset by higher supplier, employee, and tax payments. Free cash flow was $19.3 billion, down 7% year-over-year, reflecting higher capital expenditures to support our cloud and AI offerings.\\n\\nThis quarter, other income and expense was negative $283 million, significantly more favorable than anticipated due to foreign currency remeasurement and net gains on investments. Our losses on investments accounted for under the equity method were as expected.\\n\\nOur effective tax rate was approximately 19%.\\n\\nAnd finally, we returned $9 billion to shareholders through dividends and share repurchases.\\n\\nNow, moving to our Q2 outlook, which unless specifically noted otherwise, is on a US dollar basis.\\n\\nFirst, FX. With the weaker US dollar and assuming current rates remain stable, we expect FX to increase total revenue and segment level revenue growth by less than one point. We expect FX to have no meaningful impact to COGS or operating expense growth.\\n\\nOur outlook has many of the trends we saw in Q1 continue thru Q2. Customer demand for our differentiated solutions should drive another quarter of strong growth.\\n\\nIn commercial bookings, we expect strong growth on a growing expiry base driven by increased long-term commitments to our platform and strong execution across core annuity sales motions. As a reminder, larger long-term Azure contracts, which are more unpredictable in their timing, can drive increased quarterly volatility in our bookings growth rate.\\n\\nMicrosoft Cloud gross margin percentage should be roughly 70%, down year-over-year driven by the impact of scaling our AI infrastructure.\\n\\nWe expect capital expenditures to increase on a sequential basis given our cloud and AI demand signals. As I said last quarter, we will stay aligned, and if needed adjust, to the demand signals we see. As a reminder, there can be quarterly spend variability from cloud infrastructure buildouts and the timing of delivery of finance leases.\\n\\nNext to segment guidance, starting with Productivity and Business Processes.\\n\\nWe are the market leader when it comes to knowledge-based copilots and agents in the enterprise space, and we are focused on continuing to gain share across our productivity solutions. Therefore, we expect revenue in Productivity and Business Processes to grow between 10% and 11% in constant currency, or $28.7 to $29 billion.\\n\\nM365 commercial cloud revenue growth should be approximately 14% in constant currency with moderating seat growth across customer segments and ARPU growth thru E5 and M365 Copilot. For H2, we expect revenue growth to remain relatively stable compared to Q2. We continue to see growth in M365 Copilot seats and we expect the related revenue to continue to grow gradually over time.\\n\\nFor M365 commercial products, we expect revenue to decline in the low single digits. As a reminder, M365 commercial products include on-premises components of M365 suites so our quarterly revenue growth can have variability primarily from in-period revenue recognition depending on the mix of contracts.\\n\\nM365 consumer cloud revenue growth should be in the mid-single digits driven by M365 subscriptions.\\n\\nFor LinkedIn, we expect revenue growth of approximately 10% driven by continued growth across all businesses.\\n\\nAnd in Dynamics 365, we expect revenue growth to be in the mid to high teens driven by continued growth across all workloads.\\n\\nNext, Intelligent Cloud. Helping our customers transform and grow with innovative cloud and AI solutions is driving continued growth in Azure. Therefore, we expect revenue in Intelligent Cloud to grow between 18% and 20% in constant currency, or $25.55 to $25.85 billion.\\n\\nRevenue will continue to be driven by Azure which, as a reminder, can have quarterly variability primarily from in-period revenue recognition depending on the mix of contracts.\\n\\nIn Azure, we expect Q2 revenue growth to be 31% to 32% in constant currency driven by strong demand for our portfolio of services. We expect consumption growth to be stable compared to Q1 and we expect to add more sequential dollars to Azure than any other quarter in history. We expect the contribution from AI services to be similar to last quarter given the continued capacity constraints, as well as some capacity that shifted out of Q2. And in H2, we still expect Azure growth to accelerate from H1 as our capital investments create an increase in available AI capacity to serve more of the growing demand.\\n\\nAnd in our on-premises server business, we expect revenue to decline in the low to mid-single digits on a prior year comparable that benefited from purchasing ahead of Windows Server 2012 end of support.\\n\\nAnd in Enterprise and partner services, we expect revenue growth to be in the low single digits.\\n\\nNow to More Personal Computing. We continue to make decisions to prioritize strategic higher margin opportunities within each of our consumer businesses. Our outlook reflects the improvement in gross and operating margins from this prioritization work across Gaming, Search, and Devices. We expect revenue in More Personal Computing to be $13.85 to $14.25 billion.\\n\\nWindows OEM and Devices revenue should decline in the low to mid-single digits. We expect Windows OEM revenue growth, in line with the PC market, to be more than offset by a decline in Devices as the trends from Q1 continue.\\n\\nSearch and news advertising ex-TAC revenue growth should be in the high teens with continued growth in both volume and revenue per search. This will be higher than overall Search and news advertising revenue growth, which we expect to be in the high single digits.\\n\\nAnd in Gaming, we expect revenue to decline in the high single digits due to hardware. We expect Xbox content and services revenue growth to be relatively flat. We’re excited about last week’s launch of Call of Duty where we saw the most Game Pass subscriber adds we’ve ever seen on a launch day. There are two things about the launch that are different than the Call of Duty launch a year ago where revenue was mostly recognized in the quarter of purchase. First, the game is available on Game Pass so for players who play through Game Pass, the subscription revenue is recognized over time. Second, the game requires an online connection to play so even for players who purchase the standalone game, revenue recognition will also occur ratably over time.\\n\\nNow back to company guidance.\\n\\nWe expect COGS to grow between 11% and 13% in constant currency or to be between $21.9 to $22.1 billion and operating expense to grow approximately 7% in constant currency or to be between $16.4 and $16.5 billion. This should result in another quarter of operating margin expansion.\\n\\nOther income and expense is expected to be roughly negative $1.5 billion primarily driven by our share of the expected loss from OpenAI which is accounted for under the equity method. As a reminder, we do not recognize mark-to-market gains or losses on equity method investments. As you heard from Satya, our strategic partnership and investment in OpenAI has been pivotal in building and scaling our AI business, and positioning us as the leader in the AI platform wave.\\n\\nAnd lastly, we expect our Q2 effective tax rate to be approximately 19%.\\n\\nIn closing, we remain focused on strategically investing in the long-term opportunities that we believe drive shareholder value. Monetization from these investments continues to grow and we’re excited that only two and half years in, our AI business is on track to surpass $10 billion of annual revenue run rate in Q2. This will be the fastest business in our history to reach this milestone. We are committed to growing this leadership position across our entire Microsoft Cloud while maintaining our disciplined focus on cost management and prioritization across every team.\\n\\nWith that, let’s go to Q&A, Brett.\\n\\n**BRETT IVERSEN:** Thanks, Amy. We’ll now move over to Q&A. Out of respect for others of the call, we request the participants please only ask one question.\\n\\nOperator, can you please repeat your instructions?\\n\\n(Operator Direction.)\\n\\n**KEITH WEISS, Morgan Stanley:** Excellent. Thank you, guys, for taking the question, and congratulations on a really solid quarter.\\n\\nSatya, the expansion of capabilities, the speed of innovation, the magnitude of the opportunities ahead for generative AI makes this the most exciting period for software I’ve seen in my 25 years of covering this space. And based upon this call, it seems like you share that excitement.\\n\\nBut in my investor conversation, that excitement also feeds two related questions, and they both have to do with constraints. And the first is what are the internal constraints or guardrails that Microsoft has when it comes to investing behind these innovations, particularly in relation to the funding of a future generations of foundational models, where people are talking about price tags growing to tens of billions or even $100 billion plus.\\n\\nAnd then on the other side of the spectrum, what are the external constraints that Microsoft sees in building out this capacity to meet the demand and capture the opportunity, particularly constraints in your ability to power all these new data centers being built out and power it in an environmentally sustainable fashion? I’d love to get the Microsoft perspective on both those questions.\\n\\n**SATYA NADELLA:** Thank you, Keith, for those questions. I think on the first point, ultimately when you think about, let’s say, a capital outlay for training, because that’s essentially what you’re asking, it is going to be very limited by your monetization of inference in a given generation. Just like in the past, we would allocate capital to build out cloud based on the demand signal we were seeing, and then we would then project the demand, and that’s what we would build for.\\n\\nYou can think of training essentially as that, which is you’re building the next generation model so that then, you have a more capable model that then drives more inference demand. Ultimately, even with all the scaling laws and what have you, I think you ultimately will normalize to having a pace.\\n\\nIn fact, I think the best way to think about even, is given the Moore’s Law effectively is working on the silicon and system side, it’s just not compute, it’s efficiencies in compute, it’s data as well as algorithms, you will want to keep on that curve, which is you really want to refresh your fleet with the Moore’s Law every year and then effectively depreciate it over the period of the life cycle of it. And then the inference demand ultimately will govern how much we invest in training, because that’s, I think, at the end of the day, you’re all subject to ultimately demand.\\n\\nThe second piece of the external constraints, we have run into, obviously, lots of external constraints because this demand all showed up pretty fast. I mean, if you think about even the most hit products of this generation, all are in our cloud, whether it’s ChatGPT, whether it’s Copilot, whether it’s GitHub Copilot or even DAX Copilot. I mean, pick the top 4 or 5 products of this generation, they’re all in and around our ecosystem.\\n\\nAnd so, therefore, we ran into a set of constraints which are everything because DCs don’t get built overnight. There is DCs. There is power. And so, that’s been the short-term constraint. Even in Q2, for example, some of the demand issues we have, or rather our ability to fulfill demand is because of, in fact, external third-party stuff that we leased moving up. That’s the constraints we have.\\n\\nBut in the long run, we do need effectively power, and we need DCs. And some of these things are more long lead, but I feel pretty good that going into the second half of even this fiscal year, that some of that supply demand will match up.\\n\\n**KEITH WEISS:** Excellent. Thank you, guys.\\n\\n**BRETT IVERSEN:** Thanks, Keith. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**BRENT THILL, Jefferies:** Thanks. Amy, good to hear the acceleration in the back half for Azure. I guess many are asking 34% growth in Q1 falling to low 30s, I know the comp is a couple of points harder, but is there anything else you’re contemplating in that guide for Q2 to see that deceleration other than a tougher comp? Thank you.\\n\\n**AMY HOOD:** Thanks, Brent. Maybe, this is a great question, because I can reiterate some of the points I made and tie them together a little bit.\\n\\nIn Q1, the 34 in CC, as we talked about, that upside versus the 33 that we had guided to was primarily due to some revenue recognition benefits. And so, I think about that on a pure consumption basis and AI as being 33. And you think about a point or two of decel that we guided to and the majority of that is due to, unfortunately, some supply push outs that I mentioned, and then Satya reiterated, in terms of AI supply coming online that we counted on.\\n\\nThe underlying consumption growth is stable Q1 to Q2. And so, to your question on some ins and outs, it is certainly some ins and outs. I do, as you heard, have confidence as we get a good influx of supply across the second half of the year, particularly on the AI side, that we’ll be better able to do some supply demand matching.\\n\\nAnd hence, while we’re talking about acceleration in the back half, I’ll also take the opportunity to say when you see usage in AI workloads, we always intend to think about that as just a GPU exercise. The importance of having GPUs and CPUs be able to run these workloads is also important. That’s a piece of the acceleration H2 as well.\\n\\n**BRETT IVERSEN:** Thanks, Brent. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**MARK MOERDLER, Bernstein:** Thank you very much for taking my question, and congratulations on the quarter. The question every investor obviously asks is the question on the CapEx growth and the CapEx spend. Obviously, half of that’s facilities and equivalent that have a longer life, but the other half is the rest of the components.\\n\\nCan you give any color on how you think of that growth? Does it return to the traditional approach, where basically CapEx is going to grow in line with slightly slower than cloud revenue? And if so, any sense of the timing? Do we do we have enough facilities online by some time next year, etcetera? Any color would be appreciated.\\n\\n**AMY HOOD:** Thanks, Mark. I think in some ways, it’s helpful to go back to the cloud transitions that we worked on over a decade ago, I think, in the early stages. And what you did see and you’ll see us do in the same time is you have to build to meet demand. Unlike the cloud transition, we’re doing it on a global basis in parallel, as opposed to sequential, given the nature of the demand.\\n\\nAnd then as long as we continue to see that demand grow, you’re right, the growth in CapEx will slow and the revenue growth will increase. And those two things, to your point, get closer and closer together over time. The pace of that entirely depends really on the pace of adoption. And to Satya’s point, some of that spend goes toward building the next training infrastructure, so you won’t see all of it in COGS. Some of it goes to OpEx when you’re spending it on training. But in general, that’s a healthy way to think about the balance as it over time, those do and should, like the last cycle, get closer together.\\n\\n**MARK MOERDLER** Thank you very much. That’s very helpful.\\n\\n**BRETT IVERSEN:** Thanks, Mark. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**KARL KEIRSTEAD, UBS:** Okay, great. Thank you. I’m actually not going out to a question about the numbers, but Satya and Amy, I’d love to ask a question about OpenAI.\\n\\nSince the print three months ago, we investors have been hit with a torrent of media stories about OpenAI and Microsoft. And I’d love to give Microsoft an opportunity to frame the relationship. It seems to me it’s critically important, but we have been, I think, everyone on the line, picking up signals that perhaps Microsoft wants to diversify somewhat at the model layer and offer customers choice. Satya, I’d love to get your framing of the relationship.\\n\\nAnd then in terms of the numbers, maybe this is a little bit more for you, Amy, but how does Microsoft manage the demands on CapEx from helping OpenAI with its scaling ambitions? And how do you manage the impact on other income that you just gave us some color on? Thank you so much.\\n\\n**SATYA NADELLA:** Sure. Thanks, Karl. I’d say first, the partnership for both sides, that’s OpenAI and Microsoft, has been super beneficial. After all, we effectively sponsored what is one of the most, highest valued private companies today when we invested in them, and really took a bet on them and their innovation four or five years ago. And that has led to great success for Microsoft. That’s led to great success for OpenAI. And we continue to build on it.\\n\\nWe serve them with world-class infrastructure on which they do their innovation in terms of models, on top of which we innovate on both the model layer with some of the post-training stuff we do, as well as some of the small models we build, and then, of course, all of the product innovation. One of the things that my own conviction of OpenAI and what they were doing came about when I started seeing something like GitHub Copilot as a product get built or DAX Copilot get built or M365 Copilot get built, we have a fantastic portfolio of innovation that we build on top of that.\\n\\nAnd at the same, also, I would say we are investors. We feel very, very good about our investment stake in OpenAI. And so, our focus and we’re always in constant dialogue with them. In a partnership like this, when both sides have achieved mutual success at the pace at which we’ve achieved it, that means we need to push each other to do more to capture the moment. And that’s what we plan to do, and we intend to keep building on it.\\n\\n**AMY HOOD:** And maybe to your other two questions, Karl, listen, I’m thrilled with their success and need for supply from Azure and infrastructure and really, what it’s meant in terms of being able to also serve other customers for us. It’s important that we continue to invest capital to meet not only their demand signal and needs for compute, but also from our broader customers. That’s partially why you’ve seen us committing the amounts of capital we’ve seen over the past few quarters, is our commitment to both grow together and for us to continue to grow the Azure platform for customers beyond them.\\n\\nAnd so, I don’t really think of it as how do you balance it? It’s just we have customers who have needs and real use cases and delivering value today. And if we can’t meet that, we need to work to meet it. And that means working harder and faster to make sure we do that, which is what the team is committed to do.\\n\\nThe second piece of your question, I think, was on the impact to other income. And not to get to accounting heavy on the earnings phone call, but I would say just a reminder, this is under the equity method, which means we just take our percentage of losses every quarter. And those losses, of course, are capped by the amount of investment we make in total, which we did talk about in Q this quarter as being $13 billion.\\n\\nAnd so, over time, that’s just the constraint. And it’s a bit of a mechanical entry. And so, I don’t really think about managing that. That’s the investment and acceleration that OpenAI is making in themselves, and we take a percentage of that.\\n\\n**KARL KEIRSTEAD** Got it. Okay, very helpful. Thank you both.\\n\\n**BRETT IVERSEN:** Thanks, Karl. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**KASH RANGAN, Goldman Sachs:** Hi, thank you very much. Satya, when you talked about the investment cycle, these models are getting bigger and more expensive, but you also pointed out to how in the inference phase, we’re likely to get paid. How does that cycle look like an inference from Microsoft? Where are the products and the applications that will show up on the Microsoft P&L as a result of the inference phase of AI kicking in? Thank you very much.\\n\\n**SATYA NADELLA:** Thanks, Kash. I mean, the good news for us is that we’re not waiting for that inference to show up. If you think about the point we even made, that this is going to be the fastest growth to $10 billion of any business in our history, it’s all inference.\\n\\nOne of the things that may not be as evident is that we are not actually selling raw GPUs for other people to train. In fact, that’s a business we turn away, because we have so much demand on inference that we are not taking what I would – in fact, there’s a huge adverse selection problem today where people, it’s just a bunch of tech companies still using VC money to buy a bunch of GPUs. We really are not even participating in most of that, because we are literally going to the real demand, which is in the enterprise space, or our own products like GitHub Copilot or M365 Copilot.\\n\\nI feel the quality of our revenue is also pretty superior in that context. And that’s what gives us even the conviction, to even Amy’s answers previously about our capital spend, is if this was just all about a bunch of people training large models and that was all we got, then that would be, ultimately still waiting, to your point, for someone to actually have demand, which is real. And in our case, the good news here is we have a diversified portfolio. We’re seeing real demand across all of that portfolio.\\n\\n**AMY HOOD:** And Kash, maybe just to add a little bit to what Satya is saying, I think a part of his two answers is that what you’re seeing is this number we’re talking about, the $10 billion across inference and our apps is already what that momentum, and that investment, and that progress and that revenue is what builds the next cycle of training. And so, it’s that circle as opposed to, oh, we’re doing training now and then inference. Much of the training investments that fueled this revenue growth came before, and we already funded that work. And so, that’s an important point.\\n\\n**KASH RANGAN:** Got it. And that’s to your point that you invest now and you can get the growth later, even if you slow down the CapEx. That’s what you’re trying to tell us.\\n\\n**AMY HOOD:** That’s the cycle that is important to understand.\\n\\n**KASH RANGAN:** Got it. Thank you so much.\\n\\n**BRETT IVERSEN:** Thanks, Kash. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**MARK MURPHY, JP Morgan:** Thank you very much. I’m wondering if you can shed any more light just on the nature of the supply limitations that you’re mentioning, that are impacting Azure and Q2, where that impact might be incrementally, just a touch more than we expected. Is it more the GPU supply? Is there some element of power cooling or the ability to wire up the networks?\\n\\nAnd, Amy, should we infer that the supply is constraining Azure growth by roughly a couple of few points in Q2, or am I overestimating that?\\n\\n**AMY HOOD:** Maybe to answer both those questions, Mark, very directly, I wouldn’t think about it component logic in my Q2 answer. The supply push out, as Satya said, with third parties that are delivering later than we had expected. That gets pushed mainly into the second half of the year and in general, Q3. That’s third parties where we have tended to buy supply inclusive of kits. It’s complete end-to-end, third-party deliveries.\\n\\nIn terms of the impact, as I was saying, when you think about having flat consumption Q1 to Q2, there really are only two things that impact that difference. And one was the help we got in Q1 from the revenue and revenue in accounting help. And then Q2 has been the supply push out.\\n\\n**MARK MURPHY:** Thank you.\\n\\n**BRETT IVERSEN:** Thanks, Mark. Operator, next question, please.\\n\\n(Operator Direction.)\\n\\n**RAIMO LENSCHOW, Barclays:** Perfect. Thank you. If you talk about the market at the moment, because you were first with Copilot, you had identified along with Copilot, and now we’re talking agents.\\n\\nSatya, how do you think about that? To me, it looks like an evolution that we’re discovering how to productize AI better, etcetera. How do you think about that journey between Copilot agents and maybe what’s coming next? Thank you.\\n\\n**SATYA NADELLA:** Sure. The system we have built is Copilot, Copilot Studio, agents and autonomous agents. You should think of that as the spectrum of things. Ultimately, the way we think about how this all comes together is you need humans to be able to interface with AI. The UI layer for AI is Copilot. You can then use the Copilot Studio to extend Copilot. For example, you want to connect it to your CRM system, to your Office system, to your HR system. You do that through Copilot Studio by building agents, effectively.\\n\\nYou also build autonomous agents, so you can use even – that’s the announcement we made a couple of weeks ago, is you can even use Copilot Studio to build autonomous agents. Now, these autonomous agents are working independently, but from time to time, they need to raise an exception. Autonomous agents are not fully autonomous because at some point, they need to either notify someone or have someone input something. And when they need to do that, they need a UI layer. And that’s where, again, it’s Copilot.\\n\\nCopilot, Copilot agents, built in Copilot Studio, autonomous agents built in Copilot Studio, that’s the full system, we think, that comes together. And we feel very, very good about the positioning.\\n\\nAnd then, of course, we are taking the underlying system services across that entire stack that I just talked about and are making it available in Azure. You have the raw infrastructure if you want it. You have the model layer independent of it. You have the AI app server in Azure AI. Everything is also a building block service in Azure for you to be able to build. In fact, if you want to build everything that we have built in the Copilot Stack, you can build it yourself using the AI platform. That’s in simple terms, our strategy, and that’s how it all comes together.\\n\\n**RAIMO LENSCHOW:** Okay, perfect. Very clear.\\n\\n**BRETT IVERSEN:** Thanks, Raimo. Operator, we have time for one last question.\\n\\n(Operator Direction.)\\n\\n**RISHI JALURIA, RBC:** Oh, wonderful. Thanks. Hi, Satya. Hi, Amy. I appreciate the question. I want to go and think a little bit about Copilot, how we should be thinking about numbers here with the recategorization. It seems like that was maybe softer in the past than expected, but maybe with the numbers this quarter starting to pick up.\\n\\nCan you maybe walk us through what you’re seeing on that, and maybe more importantly, how we should be thinking about your overall AI strategy on consumer versus enterprise, especially now with Mustafa in the fold. Thanks so much.\\n\\n**SATYA NADELLA:** Yeah. On the first part, Rishi, to your question, I think we feel very, very good about the momentum we have in the Commercial Copilot. As I said in my remarks, and Amy talked about, this is the fastest growth of a new suite in M365. If I compare it to what we saw even back, way back in E3 or E5, or the transition from O to M, this is really much faster. It’s the numbers of penetration of the Fortune 500 and then the fact that they’re coming back for more seats and what have you. It’s very strong in that context.\\n\\nThe other thing I’ll also mention is that we want this to be something that is systemic, because people need to be able to put the security controls. Then they need to deploy. Then there’s skilling and then there’s change management. This is not like you’re just – it’s not a tool.\\n\\nWhen I talk about Copilot, Copilot Studio, agents, it’s really as much about a new way to work. And sometimes I describe it as what happened throughout the ‘90s with PC penetration. After all, if you take a business process like forecasting, what was it like pre-email and Excel and post-email and Excel. That’s the type of change that you see with Copilot. But overall we feel great about the rate of progress and the penetration.\\n\\nAnd then on the consumer side, look, for us, the exciting part here is to be able to use the same investment we are making in the commercial, where we have structural strength, and then be on the offense. One of the things that I think I hope you all catch in our earnings is ex-TAC our revenue, when it comes to what we describe as search, news and ads, is growing faster than market.\\n\\nIt’s fantastic to see that. And so, that’s what consumer business, which in Microsoft’s large scope, it’s even a $10+ billion business sometimes goes missing. But in our case, it is actually a fantastic growth business that’s growing faster than market.\\n\\nWe feel good about how we will use AI in LinkedIn. In fact, LinkedIn is a consumer business, as you know. You saw even today, this week, they announced some new capabilities for both consumers, and in their case, even recruiting. We think that AI, the same investment gets monetized even through LinkedIn’s innovation.\\n\\nAnd Gaming, of course, is another place where you’ll will see some of these things apply, and Windows. The place where I think I’m excited about is Copilot+ PCs. For us, it’s not about having a disconnected edge. It’s about having hybrid AI where the rebirth of the PC as the edge of AI is going to be one of the most exciting things for developers.\\n\\nWe feel well positioned, quite frankly with the same investments. That’s the thing. We’re not a conglomerate here. We are one company. That means we invest once, and then we have all these categories that benefit from that. And that’s the theory of the firm here for us. And so, we feel good about all of that coming together.\\n\\n**AMY HOOD:** And maybe just to add one piece, because I think, Rishi, now that I’m listening and thinking through the question, it feels like you’re wondering, why am I not seeing the Copilot if you’ve made all this progress and the results. And the answer is you already are.\\n\\nIn that M365 Commercial number. we’ve seen that seat growth, but those seats that we’re adding, the majority of them are driven by frontline worker and small businesses. Those have a lower RPU point. And so, it masks some of the RPU that we’re already seeing, not just from E5, which continues to contribute, but also this quarter, additional impact from Copilot. As we go forward, that is where you’re going to see the impact will be in RPU in M365 Commercial. And as Satya said, I think you’ll see the impact of Copilot engagement, frankly, across the same exact number.\\n\\n**RISHI JALURIA:** Wonderful. Thank you.\\n\\n**BRETT IVERSEN:** Thanks, Rishi. That wraps up the Q&A portion of today’s earnings call. Thank you for joining us today, and we look forward to speaking with all of you again soon.\\n\\n**AMY HOOD:** Thanks.\\n\\n(Operator Direction.)\\n\\n## Microsoft Corp (MSFT)\\n\\n###### 2024 ANNUAL REPORT\\n\\n[VIEW ONLINE](https://www.microsoft.com/investor/reports/ar24/index.html)\\n\\n[DOWNLOAD NOW](https://www.microsoft.com/investor/reports/ar24/download-center/)\\n\\nFollow us\\n\\nShare this page\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[0]['url']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xZ-WELThiwjK",
        "outputId": "e2058928-4a45-4517-a0cb-9ef9414381f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.fool.com/earnings/call-transcripts/2024/10/30/microsoft-msft-q1-2025-earnings-call-transcript/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from markitdown import MarkItDown\n",
        "\n",
        "md = MarkItDown()\n",
        "doc_content = md.convert(result[0]['url'])"
      ],
      "metadata": {
        "id": "IXfm6C2UizLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_content = md.convert(result[0]['url'])"
      ],
      "metadata": {
        "id": "cK2iU3buYDsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc_content.title.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iNDFm3qk-Em",
        "outputId": "39f39ebb-e7db-480e-92cd-3b8d3b63dcfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft (MSFT) Q1 2025 Earnings Call Transcript | The Motley Fool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc_content.text_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7ok0mAqi9Oz",
        "outputId": "4171be32-edcf-4c36-bfcd-f314942c15b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search\n",
            "\n",
            "[▲ S&P 500\n",
            "**+---%**\n",
            "|\n",
            "▲ Stock Advisor\n",
            "**+---%**\n",
            "Join The Motley Fool](https://www.fool.com/mms/mark/e-foolcom-sa-top-nav-returns)\n",
            "\n",
            "Accessibility\n",
            "[Log In](/auth/authenticate/)\n",
            "[Help](https://support.fool.com/)\n",
            "\n",
            "Accessibility Menu\n",
            "\n",
            "[![The Motley Fool](https://g.foolcdn.com/misc-assets/logo-tmf-primary-1-magenta-purple-reversed.svg)](/)\n",
            "\n",
            "Our Services\n",
            "angle-down\n",
            "\n",
            "Our Purpose:\n",
            "\n",
            "To make the world smarter, happier, and richer.\n",
            "\n",
            "Founded in 1993, The Motley Fool is a financial services company dedicated to making the world smarter, happier, and richer. The Motley Fool reaches millions of people every month through our premium investing solutions, free guidance and market analysis on Fool.com, top-rated podcasts, and non-profit The Motley Fool Foundation.\n",
            "\n",
            "Motley Fool Services\n",
            "\n",
            "* [All Services](/services/)\n",
            "* [Stock Advisor](/services/stock-advisor/)\n",
            "* [Epic](/services/epic/)\n",
            "* [Epic Plus](/services/epic-plus/)\n",
            "* [Fool Portfolios](/services/fool-portfolios/)\n",
            "* [Fool One](/services/one/)\n",
            "\n",
            "Fool Podcasts\n",
            "\n",
            "* [Podcasts Home](/podcasts/)\n",
            "* [Motley Fool Money](/podcasts/motley-fool-money/)\n",
            "* [Rule Breaker Investing](/podcasts/rule-breaker-investing/)\n",
            "\n",
            "Foolish Features\n",
            "\n",
            "* [The Motley Fool Foundation](https://foolfoundation.org/)\n",
            "\n",
            "Stock Market News\n",
            "angle-down\n",
            "\n",
            "Stock News\n",
            "\n",
            "* [Trending News](/trending-news/)\n",
            "* [Stock Market News](/investing-news/)\n",
            "* [Market Movers](/market-movers/)\n",
            "* [Tech Stock News](/tech-stock-news/)\n",
            "* [Market Trends](/market-trends/)\n",
            "* [Consumer Stock News](/consumer-stock-news/)\n",
            "* [Crypto News](/crypto-news/)\n",
            "\n",
            "Markets\n",
            "\n",
            "* [Stock Market Indexes Today](/markets/)\n",
            "* [Most Active Stocks Today](/markets/most-active-stocks/)\n",
            "* [Today's Biggest Stock Gainers](/markets/top-stock-gainers/)\n",
            "* [Today's Biggest Stock Losers](/markets/top-stock-losers/)\n",
            "* [Largest Market Cap Companies](/research/largest-companies-by-market-cap/)\n",
            "* [Market Research](/research/)\n",
            "* [📨 Breakfast News](/investing/breakfast-news/)\n",
            "\n",
            "Best Buys\n",
            "\n",
            "* [Top Stocks to Buy Now](/investing/top-stocks-to-buy-and-hold/)\n",
            "* [Best ETFs to Buy](/investing/how-to-invest/etfs/etfs-to-buy/)\n",
            "* [Best AI Stocks](/investing/stock-market/market-sectors/information-technology/ai-stocks/)\n",
            "* [Best Growth Stocks](/investing/stock-market/types-of-stocks/growth-stocks/)\n",
            "* [Dividend Kings](/investing/stock-market/types-of-stocks/dividend-stocks/dividend-kings/)\n",
            "* [Best Index Funds](/investing/how-to-invest/index-funds/best-index-funds/)\n",
            "* [Next Cryptos to Explode](/investing/stock-market/market-sectors/financials/cryptocurrency-stocks/next-crypto-to-explode/)\n",
            "\n",
            "Industries to Invest In\n",
            "\n",
            "* [Technology](/investing/stock-market/market-sectors/information-technology/)\n",
            "* [Energy](/investing/stock-market/market-sectors/energy/)\n",
            "* [Real Estate](/investing/stock-market/market-sectors/real-estate-investing/)\n",
            "* [Healthcare](/investing/stock-market/market-sectors/healthcare/)\n",
            "* [Consumer Goods](/investing/stock-market/market-sectors/consumer-staples/)\n",
            "* [Materials](/investing/stock-market/market-sectors/materials/)\n",
            "* [Industrials](/investing/stock-market/market-sectors/industrials/)\n",
            "\n",
            "How to Invest\n",
            "angle-down\n",
            "\n",
            "Investing 101\n",
            "\n",
            "* [How to Invest Money](/investing/how-to-invest/)\n",
            "* [What to Invest In](/investing/how-to-invest/what-to-invest-in/)\n",
            "* [How to Invest in Stocks](/investing/how-to-invest/stocks/)\n",
            "* [How to Invest in ETFs](/investing/how-to-invest/etfs/)\n",
            "* [How to Invest in Index Funds](/investing/how-to-invest/index-funds/)\n",
            "* [How to Invest in Bonds](/investing/how-to-invest/bonds/)\n",
            "* [Financial Dictionary](/terms/)\n",
            "\n",
            "Stock Market Basics\n",
            "\n",
            "* [Stock Market 101](/investing/stock-market/)\n",
            "* [Types of Stocks](/investing/stock-market/types-of-stocks/)\n",
            "* [Stock Market Sectors](/investing/stock-market/market-sectors/)\n",
            "* [Stock Market Indexes](/investing/stock-market/indexes/)\n",
            "* [What Are Stock Splits?](/terms/s/stock-split/)\n",
            "* [What Is Compound Interest?](/investing/how-to-invest/stocks/compound-interest-accounts/)\n",
            "* [After Hours Trading](/terms/a/after-hours-trading/)\n",
            "\n",
            "Start Investing\n",
            "\n",
            "* [How to Buy Stock](/investing/how-to-invest/stocks/how-to-buy-stock/)\n",
            "* [Best Brokers for Beginners](https://www.fool.com/money/buying-stocks/best-online-stock-brokers-for-beginners/)\n",
            "* [Best Brokerage Accounts](https://www.fool.com/money/buying-stocks/)\n",
            "* [Good Time to Buy Stocks](/investing/how-to-invest/stocks/good-time-to-buy-stocks/)\n",
            "* [How Many Shares to Buy?](/investing/how-to-invest/stocks/how-many-shares-buy-stock/)\n",
            "* [Portfolio Diversification](/investing/how-to-invest/portfolio-diversification/)\n",
            "* [How to Invest $100](/investing/how-to-invest/how-to-invest-100-dollars/)\n",
            "\n",
            "Companies to Invest In\n",
            "\n",
            "* [Magnificent Seven Companies](/investing/how-to-invest/stocks/magnificent-seven/)\n",
            "* [Warren Buffett Investments](/investing/how-to-invest/famous-investors/warren-buffett-investments/)\n",
            "* [Investing in ChatGPT](/investing/stock-market/market-sectors/information-technology/ai-stocks/chatgpt/)\n",
            "* [Investing in SpaceX](/investing/how-to-invest/stocks/how-to-invest-in-spacex-stock/)\n",
            "* [Investing in OpenAI](/investing/how-to-invest/stocks/how-to-invest-in-openai-stock/)\n",
            "* [Investing in Nvidia](/investing/how-to-invest/stocks/how-to-invest-in-nvidia-stock/)\n",
            "* [Investing in Databricks](/investing/how-to-invest/stocks/how-to-invest-in-databricks/)\n",
            "\n",
            "Retirement\n",
            "angle-down\n",
            "\n",
            "Retirement Essentials\n",
            "\n",
            "* [Retirement 101](/retirement/)\n",
            "* [Types of Retirement Accounts](/retirement/plans/)\n",
            "* [How to Contribute to 401k/IRA?](/retirement/plans/401k/contribute-to-401k-and-ira/)\n",
            "* [Strategies to Save for Retirement](/retirement/strategies/)\n",
            "* [Asset Allocation for My Age](/retirement/strategies/asset-allocation-by-age/)\n",
            "* [Best IRA Brokerage Accounts](/money/buying-stocks/best-ira-accounts/)\n",
            "* [Withdrawal Rules for 401(k) Plans](/retirement/plans/401k/withdrawal/)\n",
            "\n",
            "Social Security Benefits\n",
            "\n",
            "* [Social Security 101](/retirement/social-security/)\n",
            "* [How to Maximize Social Security?](/retirement/social-security/how-to-maximize-social-security/)\n",
            "* [Full Retirement Age](/retirement/social-security/full-retirement-age/)\n",
            "* [COLAs](/retirement/social-security/colas/)\n",
            "* [Calculate Your SS Benefits](/retirement/social-security/benefits-formula/)\n",
            "* [Collecting Spousal Benefits](/retirement/social-security/spousal-benefits/)\n",
            "* [Maximize Social Security Benefit](/retirement/social-security/how-to-maximize-social-security/)\n",
            "\n",
            "Planning for Retirement\n",
            "\n",
            "* [How Much Do I Need to Retire?](/retirement/how-much-do-i-need/)\n",
            "* [When To Retire](/retirement/strategies/when-can-i-retire/)\n",
            "* [401(k) Plans](/retirement/plans/401k/)\n",
            "* [403(b) Plans](/retirement/plans/403b/)\n",
            "* [Roth IRA Plans](/retirement/plans/roth-ira/)\n",
            "* [IRA Plans](/retirement/plans/ira/)\n",
            "* [HSA Plans](/retirement/plans/hsa/)\n",
            "\n",
            "Retired: What Now?\n",
            "\n",
            "* [Complete Retirement Guide](/retirement/complete-guide/)\n",
            "* [Best & Worst States to Retire](/research/best-states-to-retire/)\n",
            "* [Average Retirement Savings](/research/average-retirement-savings/)\n",
            "* [Moving for Retirement](/retirement/relocation/)\n",
            "* [Healthcare in Retirement](/retirement/healthcare-in-retirement/)\n",
            "* [Understanding Taxes in Retirement](/retirement/taxes/)\n",
            "* [401(k) Minimum Distributions](/retirement/plans/401k/required-minimum-distributions/)\n",
            "\n",
            "Personal Finance\n",
            "angle-down\n",
            "\n",
            "Credit Cards\n",
            "\n",
            "* [Best Credit Cards](https://www.fool.com/money/credit-cards/best-credit-cards/)\n",
            "* [Compare Credit Cards](https://www.fool.com/money/credit-cards/compare-cards/)\n",
            "* [Credit Card Reviews](https://www.fool.com/money/credit-cards/reviews/)\n",
            "* [Credit Card Guides and Tools](https://www.fool.com/money/credit-cards/guides-tools/)\n",
            "\n",
            "Bank & Loans\n",
            "\n",
            "* [Best Savings Accounts](https://www.fool.com/money/banks/savings-accounts/best-savings-accounts/)\n",
            "* [Bank Reviews](https://www.fool.com/money/banks/reviews/)\n",
            "* [Best Personal Loans](https://www.fool.com/money/personal-loans/)\n",
            "* [Personal Loan Reviews](https://www.fool.com/money/personal-loans/reviews/)\n",
            "\n",
            "Homebuying\n",
            "\n",
            "* [Best Mortgage Lenders](https://www.fool.com/money/mortgages/best-mortgage-lenders/)\n",
            "* [Current Mortgage Rates](https://www.fool.com/money/mortgages/rates/)\n",
            "* [Mortgage Lender Reviews](https://www.fool.com/money/mortgages/reviews/)\n",
            "* [Guide to Mortgages](https://www.fool.com/money/mortgages/)\n",
            "\n",
            "Insurance\n",
            "\n",
            "* [Auto Insurance](https://www.fool.com/money/insurance/auto/)\n",
            "* [Home Insurance](https://www.fool.com/money/insurance/homeowners/)\n",
            "* [Life Insurance](https://www.fool.com/money/insurance/life/)\n",
            "\n",
            "About Us\n",
            "angle-down\n",
            "\n",
            "Our Purpose:\n",
            "\n",
            "To make the world smarter, happier, and richer.\n",
            "\n",
            "Founded in 1993, The Motley Fool is a financial services company dedicated to making the world smarter, happier, and richer. The Motley Fool reaches millions of people every month through our premium investing solutions, free guidance and market analysis on Fool.com, personal finance education, top-rated podcasts, and non-profit The Motley Fool Foundation.\n",
            "\n",
            "Who Is the Motley Fool?\n",
            "\n",
            "* [About Us](/about/)\n",
            "* [Contact Us](/contact/customer-service/)\n",
            "* [Investing Philosophy](/about/investing-philosophy/)\n",
            "* [Motley Fool Money](/money/)\n",
            "* [The Motley Fool Foundation](https://foolfoundation.org/)\n",
            "* [Reviews](/about/reviews/)\n",
            "* [Newsroom](/contact/newsroom/)\n",
            "\n",
            "Social Media\n",
            "\n",
            "* [Facebook](https://www.facebook.com/themotleyfool/)\n",
            "* [Twitter](https://twitter.com/themotleyfool)\n",
            "* [YouTube](https://www.youtube.com/channel/UCpRQuynBX9Qy9tPrcswpPag)\n",
            "* [Discussion Boards](https://discussion.fool.com/)\n",
            "* [CAPS - Stock Picking Community](https://caps.fool.com/)\n",
            "\n",
            "Partner & Contribute\n",
            "\n",
            "* [Advertise With Us](/advertising/)\n",
            "* [Become an Affiliate Partner](/affiliates/)\n",
            "* [Publishing Standards](/about/the-motley-fools-publishing-standards/)\n",
            "\n",
            "Our Products & Services\n",
            "\n",
            "* [All Services](/services/)\n",
            "* [Stock Advisor](/services/stock-advisor/)\n",
            "* [Epic](/services/epic/)\n",
            "* [Epic Plus](/services/epic-plus/)\n",
            "* [Fool Portfolios](/services/fool-portfolios/)\n",
            "* [Fool One](/services/one/)\n",
            "\n",
            "[Top 10 Stocks](https://api.fool.com/infotron/splitter/route/article-template-button?apikey=5c8e52dd-1bea-455e-87f5-d5506e590f21)\n",
            "\n",
            "Bars\n",
            "\n",
            "Times\n",
            "\n",
            "Search\n",
            "\n",
            "* Our Services\n",
            "\n",
            "  angle-down\n",
            "\n",
            "  angle-up\n",
            "\n",
            "  Motley Fool Services\n",
            "\n",
            "  - [All Services](/services/)\n",
            "  - [Stock Advisor](/services/stock-advisor/)\n",
            "  - [Epic](/services/epic/)\n",
            "  - [Epic Plus](/services/epic-plus/)\n",
            "  - [Fool Portfolios](/services/fool-portfolios/)\n",
            "  - [Fool One](/services/one/)\n",
            "\n",
            "  Fool Podcasts\n",
            "\n",
            "  - [Podcasts Home](/podcasts/)\n",
            "  - [Motley Fool Money](/podcasts/motley-fool-money/)\n",
            "  - [Rule Breaker Investing](/podcasts/rule-breaker-investing/)\n",
            "\n",
            "  Foolish Features\n",
            "\n",
            "  - [The Motley Fool Foundation](https://foolfoundation.org/)\n",
            "\n",
            "  Our Purpose:\n",
            "\n",
            "  To make the world smarter, happier, and richer.\n",
            "\n",
            "  Founded in 1993, The Motley Fool is a financial services company dedicated to making the world smarter, happier, and richer. The Motley Fool reaches millions of people every month through our premium investing solutions, free guidance and market analysis on Fool.com, top-rated podcasts, and non-profit The Motley Fool Foundation.\n",
            "* Stock Market News\n",
            "\n",
            "  angle-down\n",
            "\n",
            "  angle-up\n",
            "\n",
            "  Stock News\n",
            "\n",
            "  - [Trending News](/trending-news/)\n",
            "  - [Stock Market News](/investing-news/)\n",
            "  - [Market Movers](/market-movers/)\n",
            "  - [Tech Stock News](/tech-stock-news/)\n",
            "  - [Market Trends](/market-trends/)\n",
            "  - [Consumer Stock News](/consumer-stock-news/)\n",
            "  - [Crypto News](/crypto-news/)\n",
            "\n",
            "  Markets\n",
            "\n",
            "  - [Stock Market Indexes Today](/markets/)\n",
            "  - [Most Active Stocks Today](/markets/most-active-stocks/)\n",
            "  - [Today's Biggest Stock Gainers](/markets/top-stock-gainers/)\n",
            "  - [Today's Biggest Stock Losers](/markets/top-stock-losers/)\n",
            "  - [Largest Market Cap Companies](/research/largest-companies-by-market-cap/)\n",
            "  - [Market Research](/research/)\n",
            "  - [📨 Breakfast News](/investing/breakfast-news/)\n",
            "\n",
            "  Best Buys\n",
            "\n",
            "  - [Top Stocks to Buy Now](/investing/top-stocks-to-buy-and-hold/)\n",
            "  - [Best ETFs to Buy](/investing/how-to-invest/etfs/etfs-to-buy/)\n",
            "  - [Best AI Stocks](/investing/stock-market/market-sectors/information-technology/ai-stocks/)\n",
            "  - [Best Growth Stocks](/investing/stock-market/types-of-stocks/growth-stocks/)\n",
            "  - [Dividend Kings](/investing/stock-market/types-of-stocks/dividend-stocks/dividend-kings/)\n",
            "  - [Best Index Funds](/investing/how-to-invest/index-funds/best-index-funds/)\n",
            "  - [Next Cryptos to Explode](/investing/stock-market/market-sectors/financials/cryptocurrency-stocks/next-crypto-to-explode/)\n",
            "\n",
            "  Industries to Invest In\n",
            "\n",
            "  - [Technology](/investing/stock-market/market-sectors/information-technology/)\n",
            "  - [Energy](/investing/stock-market/market-sectors/energy/)\n",
            "  - [Real Estate](/investing/stock-market/market-sectors/real-estate-investing/)\n",
            "  - [Healthcare](/investing/stock-market/market-sectors/healthcare/)\n",
            "  - [Consumer Goods](/investing/stock-market/market-sectors/consumer-staples/)\n",
            "  - [Materials](/investing/stock-market/market-sectors/materials/)\n",
            "  - [Industrials](/investing/stock-market/market-sectors/industrials/)\n",
            "* How to Invest\n",
            "\n",
            "  angle-down\n",
            "\n",
            "  angle-up\n",
            "\n",
            "  Investing 101\n",
            "\n",
            "  - [How to Invest Money](/investing/how-to-invest/)\n",
            "  - [What to Invest In](/investing/how-to-invest/what-to-invest-in/)\n",
            "  - [How to Invest in Stocks](/investing/how-to-invest/stocks/)\n",
            "  - [How to Invest in ETFs](/investing/how-to-invest/etfs/)\n",
            "  - [How to Invest in Index Funds](/investing/how-to-invest/index-funds/)\n",
            "  - [How to Invest in Bonds](/investing/how-to-invest/bonds/)\n",
            "  - [Financial Dictionary](/terms/)\n",
            "\n",
            "  Stock Market Basics\n",
            "\n",
            "  - [Stock Market 101](/investing/stock-market/)\n",
            "  - [Types of Stocks](/investing/stock-market/types-of-stocks/)\n",
            "  - [Stock Market Sectors](/investing/stock-market/market-sectors/)\n",
            "  - [Stock Market Indexes](/investing/stock-market/indexes/)\n",
            "  - [What Are Stock Splits?](/terms/s/stock-split/)\n",
            "  - [What Is Compound Interest?](/investing/how-to-invest/stocks/compound-interest-accounts/)\n",
            "  - [After Hours Trading](/terms/a/after-hours-trading/)\n",
            "\n",
            "  Start Investing\n",
            "\n",
            "  - [How to Buy Stock](/investing/how-to-invest/stocks/how-to-buy-stock/)\n",
            "  - [Best Brokers for Beginners](https://www.fool.com/money/buying-stocks/best-online-stock-brokers-for-beginners/)\n",
            "  - [Best Brokerage Accounts](https://www.fool.com/money/buying-stocks/)\n",
            "  - [Good Time to Buy Stocks](/investing/how-to-invest/stocks/good-time-to-buy-stocks/)\n",
            "  - [How Many Shares to Buy?](/investing/how-to-invest/stocks/how-many-shares-buy-stock/)\n",
            "  - [Portfolio Diversification](/investing/how-to-invest/portfolio-diversification/)\n",
            "  - [How to Invest $100](/investing/how-to-invest/how-to-invest-100-dollars/)\n",
            "\n",
            "  Companies to Invest In\n",
            "\n",
            "  - [Magnificent Seven Companies](/investing/how-to-invest/stocks/magnificent-seven/)\n",
            "  - [Warren Buffett Investments](/investing/how-to-invest/famous-investors/warren-buffett-investments/)\n",
            "  - [Investing in ChatGPT](/investing/stock-market/market-sectors/information-technology/ai-stocks/chatgpt/)\n",
            "  - [Investing in SpaceX](/investing/how-to-invest/stocks/how-to-invest-in-spacex-stock/)\n",
            "  - [Investing in OpenAI](/investing/how-to-invest/stocks/how-to-invest-in-openai-stock/)\n",
            "  - [Investing in Nvidia](/investing/how-to-invest/stocks/how-to-invest-in-nvidia-stock/)\n",
            "  - [Investing in Databricks](/investing/how-to-invest/stocks/how-to-invest-in-databricks/)\n",
            "* Retirement\n",
            "\n",
            "  angle-down\n",
            "\n",
            "  angle-up\n",
            "\n",
            "  Retirement Essentials\n",
            "\n",
            "  - [Retirement 101](/retirement/)\n",
            "  - [Types of Retirement Accounts](/retirement/plans/)\n",
            "  - [How to Contribute to 401k/IRA?](/retirement/plans/401k/contribute-to-401k-and-ira/)\n",
            "  - [Strategies to Save for Retirement](/retirement/strategies/)\n",
            "  - [Asset Allocation for My Age](/retirement/strategies/asset-allocation-by-age/)\n",
            "  - [Best IRA Brokerage Accounts](/money/buying-stocks/best-ira-accounts/)\n",
            "  - [Withdrawal Rules for 401(k) Plans](/retirement/plans/401k/withdrawal/)\n",
            "\n",
            "  Social Security Benefits\n",
            "\n",
            "  - [Social Security 101](/retirement/social-security/)\n",
            "  - [How to Maximize Social Security?](/retirement/social-security/how-to-maximize-social-security/)\n",
            "  - [Full Retirement Age](/retirement/social-security/full-retirement-age/)\n",
            "  - [COLAs](/retirement/social-security/colas/)\n",
            "  - [Calculate Your SS Benefits](/retirement/social-security/benefits-formula/)\n",
            "  - [Collecting Spousal Benefits](/retirement/social-security/spousal-benefits/)\n",
            "  - [Maximize Social Security Benefit](/retirement/social-security/how-to-maximize-social-security/)\n",
            "\n",
            "  Planning for Retirement\n",
            "\n",
            "  - [How Much Do I Need to Retire?](/retirement/how-much-do-i-need/)\n",
            "  - [When To Retire](/retirement/strategies/when-can-i-retire/)\n",
            "  - [401(k) Plans](/retirement/plans/401k/)\n",
            "  - [403(b) Plans](/retirement/plans/403b/)\n",
            "  - [Roth IRA Plans](/retirement/plans/roth-ira/)\n",
            "  - [IRA Plans](/retirement/plans/ira/)\n",
            "  - [HSA Plans](/retirement/plans/hsa/)\n",
            "\n",
            "  Retired: What Now?\n",
            "\n",
            "  - [Complete Retirement Guide](/retirement/complete-guide/)\n",
            "  - [Best & Worst States to Retire](/research/best-states-to-retire/)\n",
            "  - [Average Retirement Savings](/research/average-retirement-savings/)\n",
            "  - [Moving for Retirement](/retirement/relocation/)\n",
            "  - [Healthcare in Retirement](/retirement/healthcare-in-retirement/)\n",
            "  - [Understanding Taxes in Retirement](/retirement/taxes/)\n",
            "  - [401(k) Minimum Distributions](/retirement/plans/401k/required-minimum-distributions/)\n",
            "* Personal Finance\n",
            "\n",
            "  angle-down\n",
            "\n",
            "  angle-up\n",
            "\n",
            "  Credit Cards\n",
            "\n",
            "  - [Best Credit Cards](https://www.fool.com/money/credit-cards/best-credit-cards/)\n",
            "  - [Compare Credit Cards](https://www.fool.com/money/credit-cards/compare-cards/)\n",
            "  - [Credit Card Reviews](https://www.fool.com/money/credit-cards/reviews/)\n",
            "  - [Credit Card Guides and Tools](https://www.fool.com/money/credit-cards/guides-tools/)\n",
            "\n",
            "  Bank & Loans\n",
            "\n",
            "  - [Best Savings Accounts](https://www.fool.com/money/banks/savings-accounts/best-savings-accounts/)\n",
            "  - [Bank Reviews](https://www.fool.com/money/banks/reviews/)\n",
            "  - [Best Personal Loans](https://www.fool.com/money/personal-loans/)\n",
            "  - [Personal Loan Reviews](https://www.fool.com/money/personal-loans/reviews/)\n",
            "\n",
            "  Homebuying\n",
            "\n",
            "  - [Best Mortgage Lenders](https://www.fool.com/money/mortgages/best-mortgage-lenders/)\n",
            "  - [Current Mortgage Rates](https://www.fool.com/money/mortgages/rates/)\n",
            "  - [Mortgage Lender Reviews](https://www.fool.com/money/mortgages/reviews/)\n",
            "  - [Guide to Mortgages](https://www.fool.com/money/mortgages/)\n",
            "\n",
            "  Insurance\n",
            "\n",
            "  - [Auto Insurance](https://www.fool.com/money/insurance/auto/)\n",
            "  - [Home Insurance](https://www.fool.com/money/insurance/homeowners/)\n",
            "  - [Life Insurance](https://www.fool.com/money/insurance/life/)\n",
            "* About Us\n",
            "\n",
            "  angle-down\n",
            "\n",
            "  angle-up\n",
            "\n",
            "  Who Is the Motley Fool?\n",
            "\n",
            "  - [About Us](/about/)\n",
            "  - [Contact Us](/contact/customer-service/)\n",
            "  - [Investing Philosophy](/about/investing-philosophy/)\n",
            "  - [Motley Fool Money](/money/)\n",
            "  - [The Motley Fool Foundation](https://foolfoundation.org/)\n",
            "  - [Reviews](/about/reviews/)\n",
            "  - [Newsroom](/contact/newsroom/)\n",
            "\n",
            "  Social Media\n",
            "\n",
            "  - [Facebook](https://www.facebook.com/themotleyfool/)\n",
            "  - [Twitter](https://twitter.com/themotleyfool)\n",
            "  - [YouTube](https://www.youtube.com/channel/UCpRQuynBX9Qy9tPrcswpPag)\n",
            "  - [Discussion Boards](https://discussion.fool.com/)\n",
            "  - [CAPS - Stock Picking Community](https://caps.fool.com/)\n",
            "\n",
            "  Partner & Contribute\n",
            "\n",
            "  - [Advertise With Us](/advertising/)\n",
            "  - [Become an Affiliate Partner](/affiliates/)\n",
            "  - [Publishing Standards](/about/the-motley-fools-publishing-standards/)\n",
            "\n",
            "  Our Products & Services\n",
            "\n",
            "  - [All Services](/services/)\n",
            "  - [Stock Advisor](/services/stock-advisor/)\n",
            "  - [Epic](/services/epic/)\n",
            "  - [Epic Plus](/services/epic-plus/)\n",
            "  - [Fool Portfolios](/services/fool-portfolios/)\n",
            "  - [Fool One](/services/one/)\n",
            "\n",
            "  Our Purpose:\n",
            "\n",
            "  To make the world smarter, happier, and richer.\n",
            "\n",
            "  Founded in 1993, The Motley Fool is a financial services company dedicated to making the world smarter, happier, and richer. The Motley Fool reaches millions of people every month through our premium investing solutions, free guidance and market analysis on Fool.com, personal finance education, top-rated podcasts, and non-profit The Motley Fool Foundation.\n",
            "* [Log In](/auth/authenticate/?source=ilgsittph0000001)\n",
            "* [Help](https://support.fool.com)\n",
            "* [Join The Motley Fool](https://api.fool.com/infotron/splitter/route/article-template-button?apikey=5c8e52dd-1bea-455e-87f5-d5506e590f21)\n",
            "\n",
            "[Top 10 Stocks](https://api.fool.com/infotron/splitter/route/article-template-button?apikey=5c8e52dd-1bea-455e-87f5-d5506e590f21)\n",
            "\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "S&P 500\n",
            "\n",
            "6,584.29\n",
            "\n",
            "-0.0%\n",
            "\n",
            "-$3.18](/quote/snpindex/%5Egspc/)\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "DJI\n",
            "\n",
            "45,834.22\n",
            "\n",
            "-0.6%\n",
            "\n",
            "-$273.78](/quote/djindices/%5Edji/)\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "NASDAQ\n",
            "\n",
            "22,141.10\n",
            "\n",
            "+0.4%\n",
            "\n",
            "+$98.03](/quote/nasdaqindex/%5Eixic/)\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "Bitcoin\n",
            "\n",
            "114,745.00\n",
            "\n",
            "-0.9%\n",
            "\n",
            "-1,022.90](/quote/crypto/btc/)\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "AAPL\n",
            "\n",
            "$234.22\n",
            "\n",
            "+1.8%\n",
            "\n",
            "+$4.19](/quote/nasdaq/aapl/)\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "AMZN\n",
            "\n",
            "$228.24\n",
            "\n",
            "-0.7%\n",
            "\n",
            "-$1.71](/quote/nasdaq/amzn/)\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "GOOG\n",
            "\n",
            "$241.44\n",
            "\n",
            "+0.3%\n",
            "\n",
            "+$0.66](/quote/nasdaq/goog/)\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "META\n",
            "\n",
            "$756.15\n",
            "\n",
            "+0.7%\n",
            "\n",
            "+$5.25](/quote/nasdaq/meta/)\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "MSFT\n",
            "\n",
            "$510.11\n",
            "\n",
            "+1.8%\n",
            "\n",
            "+$9.10](/quote/nasdaq/msft/)\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "NVDA\n",
            "\n",
            "$177.94\n",
            "\n",
            "+0.4%\n",
            "\n",
            "+$0.77](/quote/nasdaq/nvda/)\n",
            "[Arrow-Thin-Down\n",
            "\n",
            "TSLA\n",
            "\n",
            "$395.39\n",
            "\n",
            "+7.2%\n",
            "\n",
            "+$26.58](/quote/nasdaq/tsla/)\n",
            "\n",
            "[Daily Stock Gainers](https://www.fool.com/markets/top-stock-gainers/)\n",
            "[Daily Stock Losers](https://www.fool.com/markets/top-stock-losers/)\n",
            "[Most Active Stocks](https://www.fool.com/markets/most-active-stocks/)\n",
            "\n",
            "arrow-left\n",
            "\n",
            "arrow-right\n",
            "\n",
            "[Daily Stock Gainers](https://www.fool.com/markets/top-stock-gainers/)\n",
            "[Daily Stock Losers](https://www.fool.com/markets/top-stock-losers/)\n",
            "[Most Active Stocks](https://www.fool.com/markets/most-active-stocks/)\n",
            "\n",
            "Free Article\n",
            "\n",
            "You're reading a free article with opinions that may differ\n",
            "from The Motley Fool's Premium Investing Services. Become a Motley Fool member today to\n",
            "**get instant access to our top analyst recommendations, in-depth research, investing resources,**\n",
            "and more. [Learn More](https://www.fool.com/mms/mark/op-free-tbox-art)\n",
            "\n",
            "# Microsoft (MSFT) Q1 2025 Earnings Call Transcript\n",
            "\n",
            "By [Motley Fool Transcribing](/author/20032/)\n",
            "–\n",
            "Oct 30, 2024 at 9:30PM\n",
            "\n",
            "## [NASDAQ: MSFT](/quote/nasdaq/msft/)\n",
            "\n",
            "### Microsoft\n",
            "\n",
            "![Microsoft Stock Quote](https://g.foolcdn.com/art/companylogos/mark/MSFT.png)\n",
            "\n",
            "Market Cap\n",
            "\n",
            "$3.8T\n",
            "\n",
            "Today's Change\n",
            "\n",
            "Arrow-Thin-Down\n",
            "\n",
            "(1.82%) $9.10\n",
            "\n",
            "Current Price\n",
            "\n",
            "$510.11\n",
            "\n",
            "Price as of September 12, 2025, 3:58 p.m. ET\n",
            "\n",
            "MSFT earnings call for the period ending September 30, 2024.\n",
            "\n",
            "![Logo of jester cap with thought bubble.](https://g.foolcdn.com/misc-assets/fool-transcripts-logo.png)\n",
            "\n",
            "Image source: The Motley Fool.\n",
            "\n",
            "**Microsoft** ([MSFT](/quote/nasdaq/msft/) 1.82%)\n",
            "Q1 2025 Earnings Call\n",
            "Oct 30, 2024, *5:30 p.m. ET*\n",
            "\n",
            "## Contents:\n",
            "\n",
            "* Prepared Remarks\n",
            "* Questions and Answers\n",
            "* Call Participants\n",
            "\n",
            "## Prepared Remarks:\n",
            "\n",
            "**Operator**\n",
            "\n",
            "Greetings, and welcome to the Microsoft Fiscal Year 2025 first-quarter earnings conference call. [Operator instructions] As a reminder, this conference is being recorded. It is now my pleasure to introduce your host, Brett Iversen, vice president of investor relations. Please go ahead.\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "Good afternoon, and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer; Amy Hood, chief financial officer; Alice Jolla, chief accounting officer; and Keith Dolliver, corporate secretary and deputy general counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today's call and provides the reconciliation of differences between GAAP and non-GAAP financial measures. We have recast certain prior period amounts to reflect the FY '25 changes to the composition of our segments announced in August 2024.\n",
            "\n",
            "Additional details, including FY '23 and FY '24 recast segment revenue, operating income, and product and service level revenue can be found in the financial statements filed on the Investor Relations website. More detailed outlook slides will also be available on the Microsoft Investor Relations website when we provide outlook commentary on today's call. On this call, we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP.\n",
            "\n",
            "They are included as additional clarifying items to aid investors in further understanding the company's first quarter performance in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year, unless otherwise noted. We will also provide growth rates in constant currency when available as a framework for assessing how our underlying businesses performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only.\n",
            "\n",
            "We will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website.\n",
            "\n",
            "During this call, we'll be making forward-looking statements, which are predictions, projections, or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call, and in the Risk Factors section of our Form 10-K, Forms 10-Q and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement.\n",
            "\n",
            "And with that, I'll turn the call over to Satya.\n",
            "\n",
            "**Satya Nadella** -- *Chair and Chief Executive Officer*\n",
            "\n",
            "Thank you, Brett. We are off to a solid start to our fiscal year, driven by continued strength of Microsoft Cloud, which surpassed $38.9 billion in revenue, up 22%. AI-driven transformation is changing work, work artifacts and workflow across every role, function, and business process, helping customers drive new growth and operating leverage. All up, our AI business is on track to surpass an annual revenue run rate of $10 billion next quarter, which will make it the fastest business in our history to reach this milestone.\n",
            "\n",
            "Now I'll highlight examples of our progress starting with infrastructure. Azure took share this quarter. We are seeing continued growth in cloud migration. Azure Arc now has over 39,000 customers across every industry, including American Tower, CTT, L'Oréal, up more than 80% year-over-year.\n",
            "\n",
            "We now have data centers in over 60 regions around the world. And this quarter, we announced new cloud and AI infrastructure investments in Brazil, Italy, Mexico, and Sweden as we expand our capacity in line with our long-term demand signals. At the silicon layer, our new Cobalt 100 VMs are being used by companies like Databricks, Elastic, Siemens, Snowflake and Synopsys to power their general-purpose workloads at up to 50% better price performance than previous generations. On top of this, we are building out our next-generation AI infrastructure, innovating across the full stack to optimize our fleet for AI workloads.\n",
            "\n",
            "We offer the broadest selection of AI accelerators, including our first-party accelerator, Maia 100 as well as the latest GPUs from AMD and NVIDIA. In fact, we are the first cloud to bring up NVIDIA's Blackwell system with GB200-powered AI servers. Our partnership with OpenAI also continues to deliver results. We have an economic interest in a company that has grown significantly in value, and we have built differentiated IP and are driving revenue momentum.\n",
            "\n",
            "More broadly with Azure AI, we are building an end-to-end app platform to help customers build their own copilots and agents. Azure OpenAI usage more than doubled over the past 6 months as both digital natives like Grammarly and Harvey as well as established enterprises like Bajaj Finance, Hitachi, KT, and LG move apps from test to production. GE Aerospace, for example, used Azure OpenAI to build a new digital assistant for all 52,000 of its employees. In just 3 months, it has been used to conduct over 500,000 internal queries and process more than 200,000 documents.\n",
            "\n",
            "And this quarter, we added support for OpenAI's newest model family, o1. We're also bringing industry-specific models through Azure AI, including a collection of best-in-class multimodal models for medical imaging. And with the GitHub models, we now provide access to our full model catalog directly within the GitHub developer workflow. Azure AI is also increasingly an on-ramp to our data and analytics services.\n",
            "\n",
            "As developers build new AI apps on Azure, we have seen an acceleration of Azure Cosmos DB and Azure SQL DB hyperscale usage as customers like Air India, Novo Nordisk, Telefonica, Toyota Motor North America and Uniper take advantage of capabilities purpose built for AI applications. And with Microsoft Fabric, we provide a single AI-powered platform to help customers like Chanel, EY, KPMG, Swissair and Syndigo unify their data across clouds. We now have over 16,000 paid Fabric customers, over 70% of the Fortune 500. Now on to developers.\n",
            "\n",
            "GitHub Copilot is changing the way the world builds software. Copilot enterprise customers increased 55% quarter-over-quarter as companies like AMD and Flutter Entertainment tailor Copilot to their own code base. And we are introducing the next phase of AI code generation, making GitHub Copilot agentic across the developer workflow. GitHub Copilot Workspace is a developer environment, which leverages agents from start to finish so developers can go from spec to plan to code all in natural language.\n",
            "\n",
            "Copilot Autofix is an AI agent that helps developers at companies like Asurion and Auto Group fix vulnerabilities in their code over three times faster than it would take them on their own. We're also continuing to build on GitHub's open platform ethos by making more models available via GitHub Copilot. And we are expanding the reach of GitHub to a new segment of developers introducing GitHub Spark, which enables anyone to build apps in natural language. Already, we have brought generative AI to Power Platform to help customers use low-code, no-code tools to cut costs and development time.\n",
            "\n",
            "To date, nearly 600,000 organizations have used AI-powered capabilities in Power Platform, up four times year-over-year. Citizen developers at ZF, for example, built apps simply by describing what they need using natural language. And this quarter, we introduced new ways for customers to apply AI to streamline complex workflows with Power Automate. Now on to work.\n",
            "\n",
            "We launched the next wave of Microsoft 365 Copilot innovation last month, bringing together web, work, and Pages as the new design system for knowledge work. Pages is the first new digital artifact for the AI age, and it's designed to help you ideate with AI and collaborate with other people. We've also made Microsoft 365 Copilot responses two times faster and improved response quality by nearly 3x. This innovation is driving accelerated usage, and the number of people using Microsoft 365 daily more than doubled quarter-over-quarter.\n",
            "\n",
            "We are also seeing increased adoption from customers in every industry as they use Microsoft 365 Copilot to drive real business value. Vodafone, for example, will roll out Microsoft 365 Copilot to 68,000 employees after a trial showed that, on average, they save 3 hours per person per week. And UBS will deploy 50,000 seats in our largest finserve deal to date. And we continue to see enterprise customers coming back to buy more seats.\n",
            "\n",
            "All up, nearly 70% of the Fortune 500 now use Microsoft 365 Copilot, and customers continue to adopt it at a faster rate than any other new Microsoft 365 suite. Copilot is the UI for AI, and with Microsoft 365 Copilot, Copilot Studio and agents and now autonomous agents, we have built an end-to-end system for AI business transformation. With Copilot Studio, organizations can build and connect Microsoft 365 Copilot to autonomous agents, which then delegate to Copilot when there is an exception. More than 100,000 organizations from Nsure, Standard Bank and Thomson Reuters to Virgin Money and Zurich Insurance have used Copilot Studio to date, up over two times quarter-over-quarter.\n",
            "\n",
            "More broadly, we are seeing AI drive a fundamental change in the business applications market as customers shift from legacy apps to AI-first business processes. Dynamics 365 continues to take share as organizations like Evron, Heineken and Lexmark chose our apps over other providers. And monthly active users of Copilot across our CRM and ERP portfolio increased over 60% quarter-over-quarter. Our Dynamics 365 contact center is also winning customers like Currys, Le Creuset and RXO as it brings generative AI to every customer engagement channel.\n",
            "\n",
            "And just last week, we added 10 out-of-the-box autonomous agents to Dynamics 365 that helps customers automatically qualify sales leads, track suppliers and work hand in hand with service reps to resolve issues. We're also bringing AI to industry-specific workflows. One year in, DAX Copilot is now documenting over 1.3 million physician-patient encounters each month at over 500 healthcare organizations like Baptist Medical Group, Baylor Scott & White, Greater Baltimore Medical Center, Novant Health and Overlake Medical Center. It is showing faster revenue growth than GitHub Copilot did in this first year.\n",
            "\n",
            "And new features extend DAX beyond notes, helping physicians automatically draft referrals, after-visit instructions, and diagnostic evidence. On top of all this AI innovation, Microsoft Teams usage remains at all-time highs as people use it to streamline all their communications. Nearly 75% of our Teams Enterprise customers now buy Premium, Phone or Rooms. When it comes to Windows, our new class of Copilot+ PCs is winning new customers.\n",
            "\n",
            "They offer best-in-class AI capability, performance, and value. AMD, Intel, and Qualcomm now all support Copilot+ PCs. This quarter, we also introduced new AI experience only available on Copilot+ PCs like Click to Do, which places an interactive overlay over your desktop to suggest next best actions. And as we approach the end of support for Windows 10 a year from now, we are well positioned to transition our customers to Windows 11, ensuring they benefit from enhanced features and security improvements we've introduced over the past few years.\n",
            "\n",
            "Now on to security. We continue to prioritize security above all else. With our Secure Future Initiative, we have dedicated the equivalent of 34,000 full-time engineers to address the highest-priority security tasks. We have made significant progress to better protect tenants' identities, networks, and engineering systems, and we have created new processes to ensure security is prioritized at every level of the company.\n",
            "\n",
            "And we continue to take what we learn and turn it into innovations across our products. Security Copilot, for example, is being used by companies in every industry, including Clifford Chance, Intesa Sanpaolo, and Shell to perform SecOps tasks faster and more accurately. And we are now helping customers protect their AI deployments, too. Customers have used Defender to discover and secure more than 750,000 GenAI app instances and used Purview to audit over 1 billion Copilot interactions to meet their compliance obligations.\n",
            "\n",
            "And all up, we continue to take share across all major categories we serve and are consistently recognized by top analysts as a leader in 20 categories more than any other vendor. Now let me turn to our consumer businesses, starting with LinkedIn. Member growth continues to accelerate with markets in India and Brazil both growing at double digits. We are also seeing record engagement as we introduce new ways for our more than 1 billion members to connect, sell services, get hired and share knowledge.\n",
            "\n",
            "Our investments in rich formats like video strengthen our leadership in B2B advertising and amplify the value we deliver to our customers. Weekly immersive video views increased six times quarter-over-quarter, and total video viewership on LinkedIn is up 36% year-over-year. Our AI-powered tools also continue to transform how people sell, learn and hire. In Sales, new AI features help every team member perform at the level of top sellers and drive more profitable growth.\n",
            "\n",
            "In Learning, just yesterday, we announced updates to our coaching experience, including personalized career development plans. LinkedIn's first agent hiring assistant will help hirers find qualified candidates faster by tackling the most time-consuming task. Already hirers who use AI assistant messages see a 44% higher acceptance rate compared to those who don't. And our hiring business continues to take share.\n",
            "\n",
            "Now on to Search, Advertising and News. With Copilot, we are seeing the first step toward creating a new AI companion for everyone with new Copilot experience we introduced earlier this month, includes a refreshed design and tone along with improved speed and fluency across the web and mobile. And it includes advanced capabilities like voice and vision that make it more delightful and useful and feel more natural. You can both browse and converse with Copilot simultaneously because Copilot sees what you see.\n",
            "\n",
            "More broadly, AI is also transforming search, browsers, and digital advertising, and we continue to take share across Bing and Edge. Bing ex TAC revenue growth outpaced the search market. Now on to Gaming. One year since we closed our acquisition of Activision Blizzard King, we are focused on building a business positioned for long-term growth, driven by higher-margin content and services.\n",
            "\n",
            "You already see this transformation in our results as we diversify the ways that gamers access our content. We set new records for monthly active users in the quarter as more players than ever play our games across devices and on the Xbox platform. Game Pass also set a new Q1 record for total revenue and average revenue per subscriber. And as we look ahead, our IP across our studios has never been stronger.\n",
            "\n",
            "Last week's launch of Black Ops 6 was the biggest Call of Duty release ever, setting a record for day 1 players as well as Game Pass subscriber adds on launch day. And unit sales on PlayStation and Steam were also up over 60% year-over-year. This speaks to our strategy of meeting gamers where they are by enabling them to play more games across the screens they spend their time on. In closing, we are rapidly innovating to expand our opportunity across our commercial and consumer businesses.\n",
            "\n",
            "In 3 weeks' time, we will hold our Ignite Conference, and I look forward to sharing more then about how we are helping every business function use AI to drive growth in this new era. With that, let me turn it over to Amy.\n",
            "\n",
            "**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\n",
            "\n",
            "Thank you, Satya. And good afternoon, everyone. This quarter, revenue was $65.6 billion, up 16%, and earnings per share was $3.30, an increase of 10%. With strong execution by our sales teams and partners, we delivered a solid start to our fiscal year with double-digit top and bottom line growth.\n",
            "\n",
            "We also saw continued share gains across many of our businesses. In our commercial business, increased demand, and growth in long-term commitments to our Microsoft Cloud platform drove our results. Commercial bookings were ahead of expectations and increased 30% and 23% in constant currency. Results were driven by strong execution across our core annuity sales motions and growth in the number of $10 million-plus contracts for both Azure and Microsoft 365.\n",
            "\n",
            "Additionally, we also saw an increase in the number of $100-million-plus contracts for Azure. Commercial remaining performance obligation increased 22% and 21% in constant currency to $259 billion. Roughly 40% will be recognized in revenue in the next 12 months, up 17% year-over-year. The remaining portion, recognized beyond the next 12 months, increased 27%.\n",
            "\n",
            "And this quarter, our annuity mix increased to 98%. In addition to commercial results that were in line with expectations, we also saw some benefit from in-period revenue recognition across Microsoft 365 commercial, Azure, and our on-premises server business. At a company level, Activision contributed a net impact of approximately 3 points to revenue growth with a 2 point drag on operating income growth and had a negative $0.05 impact to earnings per share. A reminder that this net impact includes adjusting for the movement of Activision content from our prior relationship as a third-party partner to first-party and includes $911 million from purchase accounting adjustments, integration, and transaction-related cost.\n",
            "\n",
            "FX did not have a significant impact on our results and was roughly in line with expectations on total company revenue, segment-level revenue, COGS, and operating expense growth. Microsoft Cloud revenue was $38.9 billion and grew 22%, roughly in line with expectations. Microsoft Cloud gross margin percentage decreased 2 points year-over-year to 71%. This was slightly better than expected due to improvement in Azure, although the gross margin percentage decrease year-over-year continues to be driven by scaling our AI infrastructure.\n",
            "\n",
            "Company gross margin dollars increased 13% and 14% in constant currency, and gross margin percentage was 69%, down 2 points year-over-year, driven by the lower Microsoft Cloud gross margin noted earlier as well as the impact from purchase accounting adjustments, integration, and transaction-related costs from the Activision acquisition. Operating expenses increased 12%, lower than expected due to our focus on cost efficiencies and ongoing prioritization work. Operating expense growth included 9 points from the Activision acquisition. At a total company level, headcount at the end of September was 8% higher than a year ago.\n",
            "\n",
            "Excluding the growth from the Activision acquisition, headcount was 2% higher. Operating income increased 14% and operating margins were 47%, down 1 point year-over-year. Excluding the net impact from the Activision acquisition, operating margins were up 1 point as we continue to drive efficiencies across our businesses as we invest in AI infrastructure and capabilities. Now to our segment results.\n",
            "\n",
            "Revenue from Productivity and Business Processes was $28.3 billion and grew 12% and 13% in constant currency, ahead of expectations, driven by better-than-expected results across all businesses. M365 commercial cloud revenue increased 15% and 16% in constant currency with business trends that were as expected. The better-than-expected result was due to a small benefit from the in-period revenue recognition noted earlier. ARPU growth was primarily driven by E5 as well as M365 Copilot.\n",
            "\n",
            "Paid M365 commercial seats grew 8% year-over-year with installed base expansion across all customer segments. Seat growth was driven by our small and medium business and frontline worker offerings. M365 commercial cloud revenue represents nearly 90% of total M365 commercial products and cloud services. M365 commercial products revenue increased 2% and 3% in constant currency, ahead of expectations, primarily due to the benefit from in-period revenue recognition noted earlier.\n",
            "\n",
            "M365 consumer products and cloud services revenue increased 5% and 6% in constant currency. M365 consumer cloud revenue increased 6% and 7% in constant currency, with continued momentum in M365 consumer subscriptions, which grew 10% to 84.4 million. M365 consumer cloud revenue represents 85% of total M365 consumer products and cloud services. LinkedIn revenue increased 10% and 9% in constant currency, slightly ahead of expectations with growth across all lines of business.\n",
            "\n",
            "Dynamics revenue grew 14%, driven by Dynamics 365, which grew 18% and 19% in constant currency with continued growth across all workloads and continued share gains. As a reminder, Dynamics 365 represents about 90% of total Dynamics revenue. Segment gross margin dollars increased 11% and 12% in constant currency, and gross margin percentage decreased slightly year-over-year, driven by scaling our AI infrastructure. Operating expenses increased 2%, and operating income increased 16%.\n",
            "\n",
            "Next, the Intelligent Cloud segment. Revenue was $24.1 billion, increasing 20% and 21% in constant currency, in line with expectations. Azure and other cloud services revenue grew 33% and 34% in constant currency, with healthy consumption trends that were in line with expectations. The better-than-expected result was due to the small benefit from in-period revenue recognition noted earlier.\n",
            "\n",
            "Azure growth included roughly 12 points from AI services similar to last quarter. Demand continues to be higher than our available capacity. Non-AI growth trends were also in line with expectations in total and across regions as customers continued to migrate and modernize on the Azure platform. The non-AI point contribution to Azure growth was sequentially lower by approximately 1 point.\n",
            "\n",
            "In our on-premises server business, revenue decreased 1%. Lower-than-expected transactional purchasing ahead of the Windows Server 2025 launch as well as lower purchasing of licenses running in multi-cloud environments was mostly offset by the benefit from in-period revenue recognition noted earlier. Enterprise and partner services revenue decreased 1% and was relatively unchanged in constant currency. Segment gross margin dollars increased 15%, and gross margin percentage decreased 3 points year-over-year, driven by scaling our AI infrastructure.\n",
            "\n",
            "Operating expenses increased 8% and operating income grew 18%. Now to More Personal Computing. Revenue was $13.2 billion, increasing 17% with 15 points of net impact from the Activision acquisition. Results were above expectations, driven by Gaming and Search.\n",
            "\n",
            "Windows OEM and Devices revenue increased 2% year-over-year as better-than-expected results in Windows OEM due to mix shift to higher monetizing markets was partially offset by the lower-than-expected results in devices due to execution challenges in the commercial segment. Search and news advertising revenue ex TAC increased 18% and 19% in constant currency ahead of expectations, primarily due to continued execution improvement. We saw rate expansion in addition to healthy volume growth in both Edge and Bing. And in Gaming, revenue increased 43% and 44% in constant currency with 43 points of net impact from the Activision acquisition.\n",
            "\n",
            "Results were ahead of expectations, driven by stronger-than-expected performance in both first- and third-party content as well as consoles. Xbox content and services revenue increased 61% with 53 points of net impact from the Activision acquisition. Segment gross margin dollars increased 16% and 17% in constant currency with 12 points of net impact from the Activision acquisition. Gross margin percentage was relatively unchanged year-over-year.\n",
            "\n",
            "Our strong execution on margin improvement in gaming and search was offset by sales mix shift to those businesses. Operating expenses increased 49% with 51 points from the Activision acquisition. Operating income decreased 4%. Now back to total company results.\n",
            "\n",
            "Capital expenditures including finance leases were $20 billion, in line with expectations, and cash paid for PP&E was $14.9 billion. Roughly half of our cloud and AI-related spend continues to be for long-lived assets that will support monetization over the next 15 years and beyond. The remaining cloud and AI spend is primarily for servers, both CPUs and GPUs, to serve customers based on demand signals. Cash flow from operations was $34.2 billion, up 12%, driven by strong cloud billings and collections, partially offset by higher supplier employee and tax payments.\n",
            "\n",
            "Free cash flow was $19.3 billion, down 7% year-over-year, reflecting higher capital expenditures to support our cloud and AI offerings. This quarter, other income expense was negative $283 million, significantly more favorable than anticipated due to foreign currency remeasurement and net gains on investments. Our losses on investments accounted for under the equity method were as expected. Our effective tax rate was approximately 19%.\n",
            "\n",
            "And finally, we returned $9 billion to shareholders through dividends and share repurchases. Now moving to our Q2 outlook, which, unless specifically noted otherwise, is on a U.S. dollar basis. First, FX.\n",
            "\n",
            "With the weaker U.S. dollar and assuming current rates remain stable, we expect FX to increase total revenue and segment level revenue growth by less than 1 point. We expect FX to have no meaningful impact to COGS or operating expense growth. Our outlook has many of the trends we saw in Q1 continue through Q2.\n",
            "\n",
            "Customer demand for our differentiated solutions should drive another quarter of strong growth. In commercial bookings, we expect strong growth on a growing expiry base driven by increased long-term commitments to our platform and strong execution across core annuity sales motions. As a reminder, larger long-term Azure contracts, which are more unpredictable in their timing, can drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 70%, down year-over-year, driven by the impact of scaling our AI infrastructure.\n",
            "\n",
            "We expect capital expenditures to increase on a sequential basis given our cloud and AI demand signals. As I said last quarter, we will stay aligned and if needed, adjust to the demand signals we see. As a reminder, there can be quarterly spend variability from cloud infrastructure build-outs and the timing of delivery of finance leases. Next, segment guidance, starting with Productivity and Business Processes.\n",
            "\n",
            "We are the market leader when it comes to knowledge-based copilots and agents in the enterprise space, and we are focused on continuing to gain share across our productivity solutions. Therefore, we expect revenue in Productivity and Business Processes to grow between 10% and 11% in constant currency or USD 28.7 billion to USD 29 billion. M365 commercial cloud revenue growth should be approximately 14% in constant currency with moderating seat growth across customer segments and ARPU growth through E5 and M365 Copilot. For H2, we expect revenue growth to remain relatively stable compared to Q2.\n",
            "\n",
            "We continue to see growth in M365 Copilot seats, and we expect the related revenue to continue to grow gradually over time. For M365 commercial products, we expect revenue to decline in the low single digits. As a reminder, M365 commercial products include on-premises components of M365 suites, so our quarterly revenue growth can have variability primarily from in-period revenue recognition depending on the mix of contracts. M365 consumer cloud revenue growth should be in the mid-single digits driven by M365 subscriptions.\n",
            "\n",
            "For LinkedIn, we expect revenue growth of approximately 10%, driven by continued growth across all businesses. And in Dynamics 365, we expect revenue growth to be in the mid- to high teens, driven by continued growth across all workloads. Next, Intelligent Cloud. Helping our customers transform and grow with innovative cloud and AI solutions is driving continued growth in Azure.\n",
            "\n",
            "Therefore, we expect revenue in Intelligent Cloud to grow between 18% and 20% in constant currency or USD 25.55 billion to USD 25.85 billion. Revenue will continue to be driven by Azure, which, as a reminder, can have quarterly variability primarily from in-period revenue recognition depending on the mix of contracts. In Azure, we expect Q2 revenue growth to be 31% to 32% in constant currency, driven by strong demand for our portfolio of services. We expect consumption growth to be stable compared to Q1, and we expect to add more sequential dollars to Azure than any other quarter in history.\n",
            "\n",
            "We expect the contribution from AI services to be similar to last quarter, given the continued capacity constraints as well as some capacity that shifted out of Q2. And in H2, we still expect Azure growth to accelerate from H1 as our capital investments create an increase in available AI capacity to serve more of the growing demand. And in our on-premises server business, we expect revenue to decline in the low to mid-single digits on a prior year comparable that benefited from purchasing ahead of Windows Server 2012 end of support. And in Enterprise and partner services, we expect revenue growth to be in the low single digits.\n",
            "\n",
            "Now to More Personal Computing. We continue to make decisions to prioritize strategic higher-margin opportunities within each of our consumer businesses. Our outlook reflects the improvement in gross and operating margins from this prioritization work across gaming, search, and devices. We expect revenue in More Personal Computing to be USD 13.85 billion to USD 14.25 billion.\n",
            "\n",
            "Windows OEM and devices revenue should decline in the low to mid-single digits. We expect Windows OEM revenue growth in line with the PC market to be more than offset by a decline in devices as the trends from Q1 continue. Search and news advertising ex TAC revenue growth should be in the high teens, with continued growth in both volume and revenue per search. This will be higher than overall search and news advertising revenue growth, which we expect to be in the high single digits.\n",
            "\n",
            "And in Gaming, we expect revenue to decline in the high single digits due to hardware. We expect Xbox content and services revenue growth to be relatively flat. We're excited about last week's launch of Call of Duty, where we saw the most Game Pass subscriber adds we've ever seen on a launch day. There are two things about the launch that are different than the Call of Duty launch a year ago, where revenue was mostly recognized in the quarter of purchase.\n",
            "\n",
            "First, the game is available on Game Pass, so for players who play through Game Pass, the subscription revenue is recognized over time. Second, the game requires an online connection to play, so even for players who purchased the stand-alone game, revenue recognition will also occur ratably over time. Now back to company guidance. We expect COGS to grow between 11% and 13% in constant currency or to be between USD 21.9 billion to USD 22.1 billion, and operating expense to grow approximately 7% in constant currency or to be between USD 16.4 billion and USD 16.5 billion.\n",
            "\n",
            "This should result in another quarter of operating margin expansion. Other income and expense is expected to be roughly negative $1.5 billion, primarily driven by our share of the expected loss from OpenAI, which is accounted for under the equity method. As a reminder, we do not recognize mark-to-market gains or losses on equity method investments. As you heard from Satya, our strategic partnership and investment in OpenAI has been pivotal in building and scaling our AI business and positioning us as the leader in the AI platform wave.\n",
            "\n",
            "And lastly, we expect our Q2 effective tax rate to be approximately 19%. In closing, we remain focused on strategically investing in the long-term opportunities that we believe drive shareholder value. Monetization from these investments continues to grow, and we're excited that only 2.5 years in, our AI business is on track to surpass $10 billion of annual revenue run rate in Q2. This will be the fastest business in our history to reach this milestone.\n",
            "\n",
            "We are committed to growing this leadership position across our entire Microsoft Cloud while maintaining our disciplined focus on cost management and prioritization across every team. With that, let's go to Q&A, Brett.\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "Thanks, Amy. We'll now move over to Q&A. [Operator instructions] Operator, can you please repeat your instructions?\n",
            "\n",
            "## Questions & Answers:\n",
            "\n",
            "**Operator**\n",
            "\n",
            "[Operator instructions] Our first question comes from the line of Keith Weiss with Morgan Stanley. Please go ahead.\n",
            "\n",
            "**Keith Weiss** -- *Analyst*\n",
            "\n",
            "Excellent. Thank you, guys, for taking the questions. Congratulations on a really solid quarter. So Satya, the expansion of capabilities, the speed of innovation, the magnitude of the opportunities ahead for generative AI makes this the most exciting period for software I've seen in my 25 years of covering this space.\n",
            "\n",
            "And based upon this call, it seems like you share that excitement. But in my investor conversation, that excitement also feeds two related questions, and they both have to do with constraints. And the first is like what are the internal constraints or guardrails that Microsoft has when it comes to investing behind these innovations, particularly in relation to the funding of future generations of foundational models, where people are talking about price tags using the tens of billions or even $100 billion plus. And then on the other side of the spectrum, what are the external constraints that Microsoft sees in building out this capacity to meet the demand and capture the opportunity, particularly constraints in your ability to power all these new data centers being built out and power it in an environmentally sustainable fashion? I'd love to get the Microsoft perspective on both those questions.\n",
            "\n",
            "**Satya Nadella** -- *Chair and Chief Executive Officer*\n",
            "\n",
            "Thank you, Keith, for those questions. I think on the first point, ultimately, when you think about, let's say, capital outlay for training because that's essentially what you're asking, it is going to be rate limited by your monetization of inference in a given generation, right? So just like in the past, we would allocate capital to build out cloud based on the demand signal we were seeing and then we would then project the demand, and that's what we would build it for. So you can think of training essentially as that, right, which is you're building the next-generation model so that then you have a more capable model that then drives more inference demand, right? So ultimately -- even with all the scaling laws and what have you, I think you ultimately will normalize to having a pace. In fact, I think the best way to think about even is given that Moore's Law effectively is working on the sort of silicon and system side, so it's just not compute, right? It's efficiencies in compute.\n",
            "\n",
            "It's data as well as algorithms. You will want to sort of keep on that curve, which is you really want to refresh your fleet with the Moore's Law every year and then effectively depreciate it over the period of the life cycle of it. And then the inference demand ultimately will govern how much we invest in training because that's, I think, at the end of the day, you're all subject to ultimately demand. The second piece of the external constraints, we have run into obviously lots of external constraints because this demand all showed up pretty fast, right? I mean if you think about even the most hit product of this generation, all are in our cloud, right, whether it's ChatGPT, whether it's Copilot, whether it's GitHub Copilot or even DAX Copilot.\n",
            "\n",
            "I mean pick the top 4 or 5 products of this generation. They're all sort of in and around our ecosystem. And so therefore, we ran into a set of constraints, which are everything because DCs don't get built overnight. So there is DCs.\n",
            "\n",
            "There is power. And so that's sort of been the short-term constraint. Even in Q2, for example, some of the demand issues we have -- or our ability to fulfill demand is because of, in fact, external third-party stuff that we leased moving out. So that's the constraints we have.\n",
            "\n",
            "But in the long run, we do need effectively power and we need DCs. And some of these things are more long lead. But I feel pretty good that going into the second half of even this fiscal year, that some of that supply/demand will match up.\n",
            "\n",
            "**Keith Weiss** -- *Analyst*\n",
            "\n",
            "Excellent. Thank you, guys.\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "Thanks, Keith. Operator, next question please.\n",
            "\n",
            "**Operator**\n",
            "\n",
            "The next question comes from the line of Brent Thill with Jefferies.\n",
            "\n",
            "**Brent Thill** -- *Analyst*\n",
            "\n",
            "Thanks, Amy. Good to hear the reacceleration in the back half for Azure. I guess many are asking, 34% growth in Q1 falling to low 30s. I know the comp is a couple of points harder.\n",
            "\n",
            "But is there anything else you're contemplating in that guide for Q2 to see that deceleration other than a tougher comp? Thank you.\n",
            "\n",
            "**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\n",
            "\n",
            "Thanks, Brent. Maybe this is a great question because I can sort of reiterate some of the points I made and tie them together a little bit. In Q1, the 34% in CC, we talked about that upside versus the 33% that we had guided to was primarily due to some revenue recognition benefits. And so I think about that on a sort of a pure consumption basis and AI as being 33%.\n",
            "\n",
            "And you think about 1 point or 2 of decel that we've guided to, and the majority of that is due to, unfortunately, some supply pushouts that I mentioned and then Satya reiterated in terms of AI supply coming online that we counted on. The underlying consumption growth is stable Q1 to Q2. And so to your question on some ins and outs, it is certainly some ins and outs. I do, as you heard, have confidence, as we get a good influx of supply across the second half of the year particularly on the AI side, that we'll be better able to do some supply demand matching and hence, while we're talking about acceleration in the back half.\n",
            "\n",
            "I'll also take the opportunity to say, when you see usage in AI workloads, we always intend to think about that as just a GPU exercise. The importance of having GPUs and CPUs be able to run these workloads is also important. So that's a piece of the acceleration in H2 as well.\n",
            "\n",
            "**Brent Thill** -- *Analyst*\n",
            "\n",
            "Thanks.\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "Thanks, Brant. Operator, next question please.\n",
            "\n",
            "**Operator**\n",
            "\n",
            "The next question comes from the line of Mark Moerdler with Bernstein. Please proceed.\n",
            "\n",
            "**Mark Moerdler** -- *Analyst*\n",
            "\n",
            "Thank you very much for taking my question. Congratulations on the quarter. The question every investor obviously asks is a question on the capex growth and the capex spend. Obviously, half of that facility is an equivalent that have a longer life, but the other half is the rest of the components.\n",
            "\n",
            "Can you give any color on how you think of that growth? Does it return to the traditional approach, where basically capex is going to grow in line or slightly slower than cloud revenue? And if so, any sense of the timing? Do we have enough facilities online by sometime next year, et cetera? Any color would be appreciated.\n",
            "\n",
            "**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\n",
            "\n",
            "Thanks, Mark. I think in some ways, it's helpful to go back to the cloud transition that we worked on over a decade ago, I think, in the early stages. And what you did see, and you'll see us do in the same time is you have to build to meet demand. Unlike the cloud transition, we're doing it on a global basis in parallel as opposed to sequential given the nature of the demand.\n",
            "\n",
            "And then as long as we continue to see that demand grow, you're right, the growth in capex will slow and the revenue growth will increase. And those 2 things, to your point, get closer and closer together over time. The pace of that entirely depends really on the pace of adoption. And to Satya's point, some of that spend goes toward building the next training infrastructure so you won't see all of it in COGS.\n",
            "\n",
            "Some of it goes to opex when you're spending it on training. But in general, that's a healthy way to think about the balance as that over time does do and should, like the last cycle, get closer together.\n",
            "\n",
            "**Mark Moerdler** -- *Analyst*\n",
            "\n",
            "Thank you very much. That's very helpful.\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "Thanks, Mark. Operator, next question please.\n",
            "\n",
            "**Operator**\n",
            "\n",
            "The next question comes from the line of Karl Keirstead with UBS. Please proceed.\n",
            "\n",
            "**Karl Keirstead** -- *Analyst*\n",
            "\n",
            "OK. Great. Thank you. I'm actually not going to ask a question about the numbers, but Satya and Amy, I'd love to ask a question about OpenAI.\n",
            "\n",
            "Since the print 3 months ago, we, investors have been hit with a torrent of media stories about OpenAI and Microsoft. And I'd love to give Microsoft an opportunity to frame the relationship. It seems to me it's critically important. But we have been, I think, everyone on the line, picking up signals that perhaps Microsoft wants to diversify somewhat at the model layer and offer customers choice.\n",
            "\n",
            "So Satya, I'd love to get your framing of the relationship. And then in terms of the numbers, maybe this is a little bit more for you, Amy. But how does Microsoft manage the demands on capex from helping OpenAI with its scaling ambitions? And how do you manage the impact on other income that you just gave us some color on?\n",
            "\n",
            "**Satya Nadella** -- *Chair and Chief Executive Officer*\n",
            "\n",
            "Sure. Thanks, Karl. So I'd say, first, the partnership for both sides, that's OpenAI and Microsoft, has been super beneficial. After all, we were the -- we effectively sponsored what is one of the most highest-valued private companies today when we invested in them and really took a bet on them and their innovation 4, 5 years ago.\n",
            "\n",
            "And that has led to great success for Microsoft. That's led to great success for OpenAI. And we continue to build on it, right? So we serve them with world-class infrastructure on which they do their innovation in terms of models, on top of which we innovate on both the model layer with some of the post-training stuff we do as well as some of the small models we build and then, of course, all of the product innovation, right? One of the things that my own sort of conviction of OpenAI and what they were doing came about when I started seeing something like GitHub Copilot as a product get built or DAX Copilot get built or M365 Copilot get built. So we have a fantastic portfolio of innovation that we build on top of that.\n",
            "\n",
            "And the same also, I would say, we are investors. We feel very, very good about sort of our investment stake in OpenAI. And so our focus -- and we're always in constant dialogue with them in a partnership like this where both sides have achieved mutual success at the pace at which we've achieved it. That means we need to kind of push each other to do more, to capture the moment, and that's what we plan to do, and we intend to keep building on it.\n",
            "\n",
            "**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\n",
            "\n",
            "And maybe to your other two questions, Karl, listen, I'm thrilled with their success and need for supply from Azure and infrastructure and really what it's meant in terms of being able to also serve other customers for us. It's important that we continue to invest capital to meet not only their demand signal and needs for compute but also from our broader customers. That's partially why you've seen us committing the amount of capital we've seen over the past few quarters, is our commitment to both grow together and for us to continue to grow the Azure platform for customers beyond them. And so I don't really think of it as how do you balance it.\n",
            "\n",
            "It's just we have customers who have needs and real use cases and delivering value today. And if we can't meet that, we need to work to meet it. And that means working harder and faster to make sure we do that, which is what the team is committed to do. Second piece of your question, I think, was on the impact to other income.\n",
            "\n",
            "And not to get too accounting heavy on the earnings phone call, but I would say, just a reminder, this is under the equity method, which means we just take our percentage of losses every quarter. And those losses, of course, are capped by the amount of investment we make in total, which we did talk about in the Q this quarter as being $13 billion. And so over time, that's just the constraint, and it's a bit of a mechanical entry. And so I don't really think about managing that.\n",
            "\n",
            "That's the investment and acceleration that OpenAI is making in themselves, and we take a percentage of that.\n",
            "\n",
            "**Karl Keirstead** -- *Analyst*\n",
            "\n",
            "Got it. OK. Very helpful. Thank you both.\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "Thanks, Karl. Operator, next question please.\n",
            "\n",
            "**Operator**\n",
            "\n",
            "The next question comes from the line of Kash Rangan with Goldman Sachs. Please proceed.\n",
            "\n",
            "**Kash Rangan** -- *Analyst*\n",
            "\n",
            "Hi. Thank you very much. Satya, when you talked about the investment cycle, these models are getting bigger, more expensive, but you also pointed out to how in the inference phase, we're likely to get paid. How does that cycle look like in inference for Microsoft? Where are the products and the applications that will show up on the Microsoft P&L as a result of the inference phase of AI kicking in?\n",
            "\n",
            "**Satya Nadella** -- *Chair and Chief Executive Officer*\n",
            "\n",
            "Thanks, Kash. I mean the good news for us is that we're not waiting for that inference to show up, right? If you sort of think about the point we even made that this is going to be the fastest growth to $10 billion of any business in our history, it's all inference, right? One of the things that may not be as evident is that we're not actually selling raw GPUs for other people to train. In fact, that's sort of a business we turn away because we have so much demand on inference that we are not taking what I would -- in fact, there's a huge adverse selection problem today where people -- it's just a bunch of tech companies still using VC money to buy a bunch of GPUs. We kind of really are not even participating in most of that because we are literally going to the real demand, which is in the enterprise space or our own products like GitHub Copilot or M365 Copilot.\n",
            "\n",
            "So I feel the quality of our revenue is also pretty superior in that context. And that's what gives us even the conviction, to even Amy's answers previously, about our capital spend, is if this was just all about sort of a bunch of people training large models and that was all we got, then that would be ultimately still waiting, to your point, for someone to actually have demand, which is real. And in our case, the good news here is we have a diversified portfolio. We're seeing real demand across all of that portfolio.\n",
            "\n",
            "**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\n",
            "\n",
            "And Kash, maybe just to add a little bit to what Satya is saying. I think a part of his 2 answers is that what you're seeing is this number we're talking about, the $10 billion, across inference and our apps is already what that momentum and that investment and that progress and that revenue is what builds the next cycle of training, right? And so it's that circle as opposed to, oh, we're doing training now and then inference. Much of the training investments that are -- that fuel this revenue growth came before, and we already funded that work. And so that's an important part.\n",
            "\n",
            "**Kash Rangan** -- *Analyst*\n",
            "\n",
            "That's, to your point, that you invest now, and you can get the growth later even if you slow down the capex, right? That's what you're trying to tell us.\n",
            "\n",
            "**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\n",
            "\n",
            "That's the cycle that is important to understand.\n",
            "\n",
            "**Kash Rangan** -- *Analyst*\n",
            "\n",
            "Got it. Thank you so much.\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "Thanks, Kash. Operator, next question please.\n",
            "\n",
            "**Operator**\n",
            "\n",
            "The next question comes from the line of Mark Murphy with J.P. Morgan. Please proceed.\n",
            "\n",
            "**Mark Murphy** -- *Analyst*\n",
            "\n",
            "Thank you very much. I'm wondering if you can shed any more light just on the nature of the supply limitations that you're mentioning that are impacting Azure in Q2, where that impact might be incrementally just a touch more than we expected. Is it more the GPU supply? Is there some element of power cooling or the ability to wire up the networks? And Amy, should we infer that the supply is constraining Azure growth by roughly a couple of few points in Q2? Or am I overestimating that?\n",
            "\n",
            "**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\n",
            "\n",
            "Maybe to answer both those questions, Mark, very directly, I wouldn't think about it component logic in my Q2 answer. The supply pushout, as Satya said, was third parties that are delivering later than we had expected, that get pushed mainly into the second half of the year and in general, Q3. So that's third parties where we have tended to buy supply inclusive of kits, so it's complete end-to-end third-party delivery. In terms of the impact, as I was saying, when you think about having flat consumption Q1 to Q2, there really are only 2 things that impact that difference, and 1 was the help we got in Q1 from the revenue and accounting help.\n",
            "\n",
            "And then Q2 has been the supply pushout.\n",
            "\n",
            "**Mark Murphy** -- *Analyst*\n",
            "\n",
            "Thank you.\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "Thanks, Mark. Operator, next question please.\n",
            "\n",
            "**Operator**\n",
            "\n",
            "The next question comes from the line of Raimo Lenschow with Barclays. Please proceed.\n",
            "\n",
            "**Raimo Lenschow** -- *Analyst*\n",
            "\n",
            "Thank you. If you talk about the market at the moment -- because you were first with Copilot, you had identified a lot with copilots and now we're talking agents. Can you kind of -- Satya, how do you think about that? And to me, it looks like an evolution that we're discovering how to kind of productize AI better, et cetera. So how do you think about that journey between copilots, agents and maybe what's coming next?\n",
            "\n",
            "**Satya Nadella** -- *Chair and Chief Executive Officer*\n",
            "\n",
            "Sure. The system we have built is Copilot, Copilot Studio, agents, and autonomous agents. You should think of that as the spectrum of things, right? So ultimately, the way we think about how this all comes together is you need humans to be able to interface with AI. So the UI layer for AI is Copilot.\n",
            "\n",
            "You can then use Copilot Studio to extend Copilot. For example, you want to connect it to your CRM system, to your office system, to your HR system. You do that through Copilot Studio by building agents effectively. You also build autonomous agents.\n",
            "\n",
            "So you can use even -- that's the announcement we made a couple of weeks ago, is you can even use Copilot Studio to build autonomous agents. Now these autonomous agents are working independently, but from time to time, they need to raise an exception, right? So autonomous agents are not fully autonomous because, at some point, they need to either notify someone or have someone input something. And when they need to do that, they need a UI layer, and that's where, again, it's Copilot. So Copilot, Copilot agents built-in Copilot Studio, autonomous agents built in Copilot Studio, that's the full system, we think, that comes together, and we feel very, very good about the position.\n",
            "\n",
            "And then, of course, we are taking the underlying system services across that entire stack that I just talked about, making it available in Azure, right? So you have the raw infrastructure if you wanted. You have the model layer independent of it. You have the AI app server in Azure AI, right? So everything is also a building block service in Azure for you to be able to build. In fact, if you want to build everything that we have built in the Copilot stack, you can build it yourself using the AI platform.\n",
            "\n",
            "So that's sort of, in simple terms, our strategy, and that's kind of how it all comes together.\n",
            "\n",
            "**Raimo Lenschow** -- *Analyst*\n",
            "\n",
            "OK. Perfect. Very clear.\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "Thanks, Raimo. Operator, we have time for one last question.\n",
            "\n",
            "**Operator**\n",
            "\n",
            "And the last question will come from the line of Rishi Jaluria with RBC. Please proceed.\n",
            "\n",
            "**Rishi Jaluria** -- *Analyst*\n",
            "\n",
            "Wonderful. Thanks. Hi, Satya. Hi, Amy.\n",
            "\n",
            "Appreciate the question. I want to go and think a little bit about Copilot, how we should be thinking about kind of numbers here with the recategorization. It seems like that was maybe softer in the past than expected or maybe with the numbers this quarter starting to pick up. Can you maybe walk us through what you're seeing on that and maybe more importantly, how we should be thinking about your overall AI strategy on consumer versus enterprise, especially now with Moustafa on the fold?\n",
            "\n",
            "**Satya Nadella** -- *Chair and Chief Executive Officer*\n",
            "\n",
            "Yes. On the first part, Rishi, to your question, I think we feel very, very good about the momentum we have in the commercial Copilot, right? As I said in my remarks and Amy talked about, this is the fastest growth of a new suite in M365. If I compare it to what we saw even back -- way back in E3 or E5 or the transition from O to M, this is really much faster, right? It's the numbers of penetration of the Fortune 500 and then the fact that they're coming back for more seats and what have you. So it's very strong in that context.\n",
            "\n",
            "The other thing I'd also mention is that we want this to be something that is systemic, right, because people need to be able to put the security controls. Then they need to deploy. Then there's skilling, and then there's change management. So this is not like you just -- it's not a tool.\n",
            "\n",
            "Like when I talk about Copilot, Copilot Studio, agents, it's really as much about a new way to work. And sometimes I describe it as what happened throughout the '90s with PC penetration. After all, if you take a business process like forecasting, what was it like pre email and Excel and post email and Excel? That's the type of change that you see with Copilot. But overall, we feel great about the rate of progress and the penetration.\n",
            "\n",
            "And then on the consumer side, look, for us, the exciting part here is to be able to use the same investment we are making in the commercial where we have structural strength and then beyond the offense. One of the things that, I think, I hope you all catch in our earnings is ex TAC. Our revenue, when it comes to what we describe as search, news, and ads, is growing faster than market. So that's -- it's fantastic to see that.\n",
            "\n",
            "And so that's kind of our consumer business, which in Microsoft's large scope, it's sort -- even a $10-plus billion business sort of sometimes go missing. But in our case, it is actually a fantastic growth business that's growing faster than market. We feel good about how we will use AI in LinkedIn. In fact, LinkedIn is a consumer business as you know.\n",
            "\n",
            "You saw even this week, they announced some new capabilities for both consumers and in their case, even recruiting. So we think that AI, the same investment gets monetized even through LinkedIn's innovation. And gaming, of course, is another place where you'll see some of these things apply and Windows, right? So the place where I think I'm excited about is Copilot+ PCs. For us, it's not about having a disconnected edge.\n",
            "\n",
            "It's about having hybrid AI where the rebirth of sort of the PC as the edge of AI is going to be one of the most exciting things for developers. So we feel well positioned, quite frankly, with the same investment. So this is -- that's the thing. We're not a conglomerate here.\n",
            "\n",
            "We are sort of one company. That means we invest once, and then we have all these categories that benefit from that. And that's the theory of the firm for us. And so we feel good about all of that coming together.\n",
            "\n",
            "**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\n",
            "\n",
            "And maybe just to add one piece because I think, Rishi, now that I'm listening and thinking through the question, it feels like you're wondering, like why am I not seeing the Copilot, if you've made all this progress and the results, and the answer is you already are. In that M365 commercial number, we've seen that seat growth, but those seats that we're adding, the majority of them are driven by frontline worker and small businesses. Those have a lower ARPU point. And so it masks some of the ARPU that we're already seeing not just from E5, which continues to contribute, but also this quarter, additional impact from Copilot.\n",
            "\n",
            "So as we go forward, being able -- that is where you're going to see the impact will be in ARPU in M365 commercial, and as Satya said, I think you'll see the impact of Copilot engagement, frankly, across the same ex TAC number.\n",
            "\n",
            "**Rishi Jaluria** -- *Analyst*\n",
            "\n",
            "OK. Wonderful. Thank you.\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "Thanks, Rishi. That wraps up the Q&A portion of today's earnings call. Thank you for joining us today, and we look forward to speaking with all of you again soon.\n",
            "\n",
            "**Operator**\n",
            "\n",
            "[Operator signoff]\n",
            "\n",
            "**Duration: 0 minutes**\n",
            "\n",
            "## Call participants:\n",
            "\n",
            "**Brett Iversen** -- *Vice President, Investor Relations*\n",
            "\n",
            "**Satya Nadella** -- *Chair and Chief Executive Officer*\n",
            "\n",
            "**Amy E. Hood** -- *Executive Vice President, Chief Financial Officer*\n",
            "\n",
            "**Keith Weiss** -- *Analyst*\n",
            "\n",
            "**Brent Thill** -- *Analyst*\n",
            "\n",
            "**Amy Hood** -- *Executive Vice President, Chief Financial Officer*\n",
            "\n",
            "**Mark Moerdler** -- *Analyst*\n",
            "\n",
            "**Karl Keirstead** -- *Analyst*\n",
            "\n",
            "**Kash Rangan** -- *Analyst*\n",
            "\n",
            "**Mark Murphy** -- *Analyst*\n",
            "\n",
            "**Raimo Lenschow** -- *Analyst*\n",
            "\n",
            "**Rishi Jaluria** -- *Analyst*\n",
            "\n",
            "[More MSFT analysis](https://www.fool.com/quote/msft)\n",
            "\n",
            "[All earnings call transcripts](https://www.fool.com/earnings-call-transcripts/)\n",
            "\n",
            "*This article is a transcript of this conference call produced for The Motley Fool. While we strive for our Foolish Best, there may be errors, omissions, or inaccuracies in this transcript. As with all our articles, The Motley Fool does not assume any responsibility for your use of this content, and we strongly encourage you to do your own research, including listening to the call yourself and reading the company's SEC filings. Please see our* [*Terms and Conditions*](https://www.fool.com/legal/terms-and-conditions/fool-rules) *for additional details, including our Obligatory Capitalized Disclaimers of Liability.*\n",
            "\n",
            "*The Motley Fool has positions in and recommends Microsoft. The Motley Fool recommends the following options: long January 2026 $395 calls on Microsoft and short January 2026 $405 calls on Microsoft. The Motley Fool has a [disclosure policy](https://www.fool.com/legal/fool-disclosure-policy/).*\n",
            "\n",
            "Stocks Mentioned\n",
            "\n",
            "[![Microsoft Stock Quote](https://g.foolcdn.com/art/companylogos/mark/MSFT.png)\n",
            "\n",
            "Microsoft\n",
            "\n",
            "MSFT\n",
            "\n",
            "$510.11\n",
            "\n",
            "(1.82%)\n",
            "$9.10](/quote/nasdaq/msft/)\n",
            "\n",
            "\\*Average returns of all recommendations since inception. Cost basis and return based on previous market day close.\n",
            "\n",
            "Related Articles\n",
            "\n",
            "[![Growth 32](https://g.foolcdn.com/image/?url=https%3A%2F%2Fg.foolcdn.com%2Feditorial%2Fimages%2F833505%2Fgrowth-32.jpg&op=resize&w=92&h=52)\n",
            "\n",
            "2 Artificial Intelligence (AI) Stocks to Buy Before They Soar to $5 Trillion, According to a Wall Street Expert](/investing/2025/09/14/2-ai-stocks-buy-before-soar-5-trillion-wall-street/)\n",
            "[![dividend-stock-to-buy-now](https://g.foolcdn.com/image/?url=https%3A%2F%2Fg.foolcdn.com%2Feditorial%2Fimages%2F833145%2Fdividend-stock-to-buy-now.jpg&op=resize&w=92&h=52)\n",
            "\n",
            "3 Reasons to Love Microsoft's Dividend](/investing/2025/09/13/3-reasons-to-love-microsofts-dividend/)\n",
            "[![Stock market graph and currency](https://g.foolcdn.com/image/?url=https%3A%2F%2Fg.foolcdn.com%2Feditorial%2Fimages%2F832423%2Fstock-market-graph-and-currency.jpg&op=resize&w=92&h=52)\n",
            "\n",
            "Got $5,000? 2 Tech Stocks to Buy and Hold for the Long Term](/investing/2025/09/12/got-5000-2-tech-stocks-buy-hold-long-term/)\n",
            "[![AI written on cloud silhoutte](https://g.foolcdn.com/image/?url=https%3A%2F%2Fg.foolcdn.com%2Feditorial%2Fimages%2F831899%2Fai-written-on-cloud-silhoutte.jpg&op=resize&w=92&h=52)\n",
            "\n",
            "Prediction: This Artificial Intelligence (AI) Stock Could Surpass Nvidia's Market Cap by 2030](/investing/2025/09/12/predict-artificial-intelligence-ai-stock-nvidia/)\n",
            "[![AI artificial intelligence in circle on keyboard](https://g.foolcdn.com/image/?url=https%3A%2F%2Fg.foolcdn.com%2Feditorial%2Fimages%2F831920%2Fai-artificial-intelligence-in-circle-on-keyboard.jpg&op=resize&w=92&h=52)\n",
            "\n",
            "Apple vs. Microsoft: Which AI Stock Is the Better Buy Right Now?](/investing/2025/09/11/apple-vs-microsoft-which-ai-stock-is-the-better-bu/)\n",
            "\n",
            "## Premium Investing Services\n",
            "\n",
            "Invest better with The Motley Fool. Get stock recommendations, portfolio guidance, and more from The Motley Fool's premium services.\n",
            "\n",
            "[View Premium Services](/services/?ftm_cam=footer-services-sitewide-prospects)\n",
            "\n",
            "[![The Motley Fool](https://g.foolcdn.com/misc-assets/logo-tmf-primary-1-magenta-purple.svg)](/)\n",
            "\n",
            "Making the world smarter, happier, and richer.\n",
            "\n",
            "* [Facebook\n",
            "\n",
            "  Facebook](https://www.facebook.com/themotleyfool?fref=ts)\n",
            "* [X\n",
            "\n",
            "  X](https://x.com/TheMotleyFool)\n",
            "* [Linked In\n",
            "\n",
            "  LinkedIn](https://www.linkedin.com/company/the-motley-fool/)\n",
            "* [Pinterest\n",
            "\n",
            "  Pinterest](https://www.pinterest.com/themotleyfool/)\n",
            "* [YouTube\n",
            "\n",
            "  YouTube](https://www.youtube.com/user/TheMotleyFool)\n",
            "* [Instagram\n",
            "\n",
            "  Instagram](https://www.instagram.com/themotleyfoolofficial/)\n",
            "* [Tiktok\n",
            "\n",
            "  TikTok](https://www.tiktok.com/%40themotleyfoolofficial)\n",
            "\n",
            "© 1995 - 2025 The Motley Fool. All rights reserved.\n",
            "\n",
            "Market data powered by [Xignite](https://xignite.com/) and [Polygon.io](https://polygon.io/).\n",
            "\n",
            "About The Motley Fool\n",
            "\n",
            "* [About Us](/about/)\n",
            "* [Careers](https://careers.fool.com/)\n",
            "* [Research](/research/)\n",
            "* [Newsroom](/contact/newsroom/)\n",
            "* [Contact](/legal/contact-us/)\n",
            "* [Advertise](/cdn-cgi/l/email-protection#8eefeae7e0fffbe7fce7ebfdcee8e1e1e2a0ede1e3)\n",
            "\n",
            "Our Services\n",
            "\n",
            "* [All Services](/services/)\n",
            "* [Stock Advisor](/services/stock-advisor/)\n",
            "* [Epic](/services/epic/)\n",
            "* [Epic Plus](/services/epic-plus/)\n",
            "* [Fool Portfolios](/services/fool-portfolios/)\n",
            "* [Fool One](/services/one/)\n",
            "* [Motley Fool Money](/money/)\n",
            "\n",
            "Around the Globe\n",
            "\n",
            "* [Fool UK](https://www.fool.co.uk/)\n",
            "* [Fool Australia](https://www.fool.com.au/)\n",
            "* [Fool Canada](https://www.fool.ca)\n",
            "\n",
            "Free Tools\n",
            "\n",
            "* [CAPS Stock Ratings](https://caps.fool.com/Index.aspx)\n",
            "* [Discussion Boards](https://discussion.fool.com/)\n",
            "* [Calculators](/calculators/index/)\n",
            "* [Financial Dictionary](/terms/)\n",
            "\n",
            "Affiliates & Friends\n",
            "\n",
            "* [Motley Fool Asset Management](/affiliates/mfam/)\n",
            "* [Motley Fool Wealth Management](/affiliates/mfwm/)\n",
            "* [Motley Fool Ventures](/affiliates/ventures/)\n",
            "* [Fool Community Foundation](/affiliates/foundation/)\n",
            "* [Become an Affiliate Partner](/affiliates/)\n",
            "\n",
            "* [Terms of Use](/legal/terms-and-conditions/fool-rules/ \"Terms of Use\")\n",
            "* [Privacy Policy](/legal/privacy-statement/ \"Privacy Policy\")\n",
            "* [Disclosure Policy](/legal/fool-disclosure-policy/ \"Disclosure Policy\")\n",
            "* [Accessibility Policy](/legal/accessibility-policy/ \"Accessibility Policy\")\n",
            "* [Copyright, Trademark and Patent Information](/legal/stuff-we-own/ \"Copyright, Trademark and Patent Information\")\n",
            "* [Terms and Conditions](/legal/terms-and-conditions/ \"Terms and Conditions\")\n",
            "* [Do Not Sell My Personal Information](/data-protection/ccpa-update/ \"Do Not Sell My Personal Information\")\n",
            "\n",
            "Current\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from markitdown import MarkItDown\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_answer=False,\n",
        "                                  include_raw_content=True)\n",
        "md = MarkItDown()\n",
        "\n",
        "@tool\n",
        "def search_web_extract_info(query: str) -> list:\n",
        "    \"\"\"Search the web for a query and extracts useful information from the search links\"\"\"\n",
        "    results = tavily_tool.invoke(query)\n",
        "    docs = []\n",
        "    for result in tqdm(results):\n",
        "        # Extracting all text content from the URL\n",
        "        try:\n",
        "            extracted_info = md.convert(result['url'])\n",
        "            text_title = extracted_info.title.strip()\n",
        "            text_content = extracted_info.text_content.strip()\n",
        "            docs.append(text_title + '\\n' + text_content)\n",
        "        except:\n",
        "            print('Extraction blocked for url: ', result['url'])\n",
        "            pass\n",
        "\n",
        "    return docs"
      ],
      "metadata": {
        "id": "0G6V3Kv1jwU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = search_web_extract_info('Model Context Protocol')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qNB0fSmlhLQ",
        "outputId": "54e01157-89ba-4cfa-e786-f40ed95116da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [00:00<00:00,  6.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction blocked for url:  https://en.wikipedia.org/wiki/Model_Context_Protocol\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction blocked for url:  https://medium.com/@nimritakoul01/the-model-context-protocol-mcp-a-complete-tutorial-a3abe8a7f4ef\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(docs[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jHJb63LQm2If",
        "outputId": "bfbe0e13-b8a6-472f-c4cb-2ea5f6cbbf11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "What is the Model Context Protocol (MCP)? - Model Context Protocol\n[Model Context Protocol home page![light logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/light.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=4498cb8a57d574005f3dca62bdd49c95)![dark logo](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/logo/dark.svg?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=c0687c003f8f2cbdb24772ab4c8a522c)](/)\n\nSearch...\n\n⌘K\n\n* [Blog](https://blog.modelcontextprotocol.io)\n* [GitHub](https://github.com/modelcontextprotocol)\n\nSearch...\n\nNavigation\n\nGet started\n\nWhat is the Model Context Protocol (MCP)?\n\n[Documentation](/docs/getting-started/intro)[Specification](/specification/2025-06-18)[Community](/community/communication)[About MCP](/about)\n\n##### Get started\n\n* [What is MCP?](/docs/getting-started/intro)\n\n##### About MCP\n\n* [Architecture](/docs/learn/architecture)\n* [Servers](/docs/learn/server-concepts)\n* [Clients](/docs/learn/client-concepts)\n* [Versioning](/specification/versioning)\n\n##### Develop with MCP\n\n* [Connect to local MCP servers](/docs/develop/connect-local-servers)\n* [Connect to remote MCP Servers](/docs/develop/connect-remote-servers)\n* [Build an MCP server](/docs/develop/build-server)\n* [Build an MCP client](/docs/develop/build-client)\n* [SDKs](/docs/sdk)\n\n##### Developer tools\n\n* [MCP Inspector](/legacy/tools/inspector)\n\nOn this page\n\n* [What can MCP enable?](#what-can-mcp-enable%3F)\n* [Why does MCP matter?](#why-does-mcp-matter%3F)\n* [Start Building](#start-building)\n* [Learn more](#learn-more)\n\nGet started\n\n# What is the Model Context Protocol (MCP)?\n\nCopy page\n\nCopy page\n\nMCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems.\nUsing MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)—enabling them to access key information and perform tasks.\nThink of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems.\n\n![](https://mintcdn.com/mcp/4ZXF1PrDkEaJvXpn/images/mcp-simple-diagram.png?fit=max&auto=format&n=4ZXF1PrDkEaJvXpn&q=85&s=9337f8096debc55621adcaf8ca563695)\n\n## [​](#what-can-mcp-enable%3F) What can MCP enable?\n\n* Agents can access your Google Calendar and Notion, acting as a more personalized AI assistant.\n* Claude Code can generate an entire web app using a Figma design.\n* Enterprise chatbots can connect to multiple databases across an organization, empowering users to analyze data using chat.\n* AI models can create 3D designs on Blender and print them out using a 3D printer.\n\n## [​](#why-does-mcp-matter%3F) Why does MCP matter?\n\nDepending on where you sit in the ecosystem, MCP can have a range of benefits.\n\n* **Developers**: MCP reduces development time and complexity when building, or integrating with, an AI application or agent.\n* **AI applications or agents**: MCP provides access to an ecosystem of data sources, tools and apps which will enhance capabilities and improve the end-user experience.\n* **End-users**: MCP results in more capable AI applications or agents which can access your data and take actions on your behalf when necessary.\n\n## [​](#start-building) Start Building\n\n[## Build servers\n\nCreate MCP servers to expose your data and tools](/docs/develop/build-server)[## Build clients\n\nDevelop applications that connect to MCP servers](/docs/develop/build-client)\n\n## [​](#learn-more) Learn more\n\n[## Understand concepts\n\nLearn the core concepts and architecture of MCP](/docs/learn/architecture)\n\nWas this page helpful?\n\nYesNo\n\n[Architecture](/docs/learn/architecture)\n\n[github](https://github.com/modelcontextprotocol)\n\nAssistant\n\nResponses are generated using AI and may contain mistakes."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a Weather Tool"
      ],
      "metadata": {
        "id": "3km3-7WcnYk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "    \"\"\"Search weatherapi to get the current weather.\"\"\"\n",
        "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "    response = requests.get(complete_url)\n",
        "    data = response.json()\n",
        "    if data.get(\"location\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\""
      ],
      "metadata": {
        "id": "ZM8R-JgOnXdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather.invoke(\"Mumbai\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12xdLSJ3ZUiv",
        "outputId": "990e422b-d497-468e-ecb7-5a4a5de992f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'location': {'name': 'Mumbai',\n",
              "  'region': 'Maharashtra',\n",
              "  'country': 'India',\n",
              "  'lat': 18.975,\n",
              "  'lon': 72.826,\n",
              "  'tz_id': 'Asia/Kolkata',\n",
              "  'localtime_epoch': 1757942841,\n",
              "  'localtime': '2025-09-15 18:57'},\n",
              " 'current': {'last_updated_epoch': 1757942100,\n",
              "  'last_updated': '2025-09-15 18:45',\n",
              "  'temp_c': 25.3,\n",
              "  'temp_f': 77.5,\n",
              "  'is_day': 0,\n",
              "  'condition': {'text': 'Mist',\n",
              "   'icon': '//cdn.weatherapi.com/weather/64x64/night/143.png',\n",
              "   'code': 1030},\n",
              "  'wind_mph': 10.7,\n",
              "  'wind_kph': 17.3,\n",
              "  'wind_degree': 291,\n",
              "  'wind_dir': 'WNW',\n",
              "  'pressure_mb': 1007.0,\n",
              "  'pressure_in': 29.74,\n",
              "  'precip_mm': 0.05,\n",
              "  'precip_in': 0.0,\n",
              "  'humidity': 89,\n",
              "  'cloud': 75,\n",
              "  'feelslike_c': 27.7,\n",
              "  'feelslike_f': 81.9,\n",
              "  'windchill_c': 26.7,\n",
              "  'windchill_f': 80.0,\n",
              "  'heatindex_c': 30.1,\n",
              "  'heatindex_f': 86.2,\n",
              "  'dewpoint_c': 23.7,\n",
              "  'dewpoint_f': 74.6,\n",
              "  'vis_km': 2.5,\n",
              "  'vis_miles': 1.0,\n",
              "  'uv': 0.0,\n",
              "  'gust_mph': 15.1,\n",
              "  'gust_kph': 24.3,\n",
              "  'short_rad': 0,\n",
              "  'diff_rad': 0,\n",
              "  'dni': 0,\n",
              "  'gti': 0}}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rich\n",
        "\n",
        "result = get_weather.invoke(\"Mumbai\")\n",
        "rich.print_json(data=result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "dyL1L1ifn0mj",
        "outputId": "1c6e276d-d988-4e9e-c521-ba52cafd45de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "  \u001b[1;34m\"location\"\u001b[0m: \u001b[1m{\u001b[0m\n",
              "    \u001b[1;34m\"name\"\u001b[0m: \u001b[32m\"Mumbai\"\u001b[0m,\n",
              "    \u001b[1;34m\"region\"\u001b[0m: \u001b[32m\"Maharashtra\"\u001b[0m,\n",
              "    \u001b[1;34m\"country\"\u001b[0m: \u001b[32m\"India\"\u001b[0m,\n",
              "    \u001b[1;34m\"lat\"\u001b[0m: \u001b[1;36m18.975\u001b[0m,\n",
              "    \u001b[1;34m\"lon\"\u001b[0m: \u001b[1;36m72.826\u001b[0m,\n",
              "    \u001b[1;34m\"tz_id\"\u001b[0m: \u001b[32m\"Asia/Kolkata\"\u001b[0m,\n",
              "    \u001b[1;34m\"localtime_epoch\"\u001b[0m: \u001b[1;36m1757942841\u001b[0m,\n",
              "    \u001b[1;34m\"localtime\"\u001b[0m: \u001b[32m\"2025-09-15 18:57\"\u001b[0m\n",
              "  \u001b[1m}\u001b[0m,\n",
              "  \u001b[1;34m\"current\"\u001b[0m: \u001b[1m{\u001b[0m\n",
              "    \u001b[1;34m\"last_updated_epoch\"\u001b[0m: \u001b[1;36m1757942100\u001b[0m,\n",
              "    \u001b[1;34m\"last_updated\"\u001b[0m: \u001b[32m\"2025-09-15 18:45\"\u001b[0m,\n",
              "    \u001b[1;34m\"temp_c\"\u001b[0m: \u001b[1;36m25.3\u001b[0m,\n",
              "    \u001b[1;34m\"temp_f\"\u001b[0m: \u001b[1;36m77.5\u001b[0m,\n",
              "    \u001b[1;34m\"is_day\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "    \u001b[1;34m\"condition\"\u001b[0m: \u001b[1m{\u001b[0m\n",
              "      \u001b[1;34m\"text\"\u001b[0m: \u001b[32m\"Mist\"\u001b[0m,\n",
              "      \u001b[1;34m\"icon\"\u001b[0m: \u001b[32m\"//cdn.weatherapi.com/weather/64x64/night/143.png\"\u001b[0m,\n",
              "      \u001b[1;34m\"code\"\u001b[0m: \u001b[1;36m1030\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[1;34m\"wind_mph\"\u001b[0m: \u001b[1;36m10.7\u001b[0m,\n",
              "    \u001b[1;34m\"wind_kph\"\u001b[0m: \u001b[1;36m17.3\u001b[0m,\n",
              "    \u001b[1;34m\"wind_degree\"\u001b[0m: \u001b[1;36m291\u001b[0m,\n",
              "    \u001b[1;34m\"wind_dir\"\u001b[0m: \u001b[32m\"WNW\"\u001b[0m,\n",
              "    \u001b[1;34m\"pressure_mb\"\u001b[0m: \u001b[1;36m1007.0\u001b[0m,\n",
              "    \u001b[1;34m\"pressure_in\"\u001b[0m: \u001b[1;36m29.74\u001b[0m,\n",
              "    \u001b[1;34m\"precip_mm\"\u001b[0m: \u001b[1;36m0.05\u001b[0m,\n",
              "    \u001b[1;34m\"precip_in\"\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
              "    \u001b[1;34m\"humidity\"\u001b[0m: \u001b[1;36m89\u001b[0m,\n",
              "    \u001b[1;34m\"cloud\"\u001b[0m: \u001b[1;36m75\u001b[0m,\n",
              "    \u001b[1;34m\"feelslike_c\"\u001b[0m: \u001b[1;36m27.7\u001b[0m,\n",
              "    \u001b[1;34m\"feelslike_f\"\u001b[0m: \u001b[1;36m81.9\u001b[0m,\n",
              "    \u001b[1;34m\"windchill_c\"\u001b[0m: \u001b[1;36m26.7\u001b[0m,\n",
              "    \u001b[1;34m\"windchill_f\"\u001b[0m: \u001b[1;36m80.0\u001b[0m,\n",
              "    \u001b[1;34m\"heatindex_c\"\u001b[0m: \u001b[1;36m30.1\u001b[0m,\n",
              "    \u001b[1;34m\"heatindex_f\"\u001b[0m: \u001b[1;36m86.2\u001b[0m,\n",
              "    \u001b[1;34m\"dewpoint_c\"\u001b[0m: \u001b[1;36m23.7\u001b[0m,\n",
              "    \u001b[1;34m\"dewpoint_f\"\u001b[0m: \u001b[1;36m74.6\u001b[0m,\n",
              "    \u001b[1;34m\"vis_km\"\u001b[0m: \u001b[1;36m2.5\u001b[0m,\n",
              "    \u001b[1;34m\"vis_miles\"\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
              "    \u001b[1;34m\"uv\"\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
              "    \u001b[1;34m\"gust_mph\"\u001b[0m: \u001b[1;36m15.1\u001b[0m,\n",
              "    \u001b[1;34m\"gust_kph\"\u001b[0m: \u001b[1;36m24.3\u001b[0m,\n",
              "    \u001b[1;34m\"short_rad\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "    \u001b[1;34m\"diff_rad\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "    \u001b[1;34m\"dni\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "    \u001b[1;34m\"gti\"\u001b[0m: \u001b[1;36m0\u001b[0m\n",
              "  \u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"location\"</span>: <span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Mumbai\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"region\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Maharashtra\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"country\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"India\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"lat\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.975</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"lon\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72.826</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"tz_id\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Asia/Kolkata\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"localtime_epoch\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1757942841</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"localtime\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2025-09-15 18:57\"</span>\n",
              "  <span style=\"font-weight: bold\">}</span>,\n",
              "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"current\"</span>: <span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"last_updated_epoch\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1757942100</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"last_updated\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2025-09-15 18:45\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"temp_c\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25.3</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"temp_f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.5</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"is_day\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"condition\"</span>: <span style=\"font-weight: bold\">{</span>\n",
              "      <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"text\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Mist\"</span>,\n",
              "      <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"icon\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"//cdn.weatherapi.com/weather/64x64/night/143.png\"</span>,\n",
              "      <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"code\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1030</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"wind_mph\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.7</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"wind_kph\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.3</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"wind_degree\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">291</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"wind_dir\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"WNW\"</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pressure_mb\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1007.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pressure_in\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29.74</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"precip_mm\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"precip_in\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"humidity\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">89</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"cloud\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"feelslike_c\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27.7</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"feelslike_f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81.9</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"windchill_c\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.7</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"windchill_f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"heatindex_c\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30.1</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"heatindex_f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86.2</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"dewpoint_c\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.7</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"dewpoint_f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74.6</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"vis_km\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.5</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"vis_miles\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"uv\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"gust_mph\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.1</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"gust_kph\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.3</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"short_rad\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"diff_rad\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"dni\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"gti\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "  <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore LLM tool calling with custom tools\n",
        "\n",
        "An agent is basically an LLM which has the capability to automatically call relevant functions to perform complex or tool-based tasks based on input human prompts.\n",
        "\n",
        "Tool calling also popularly known as function calling is the ability to reliably enable such LLMs to call external tools and APIs.\n",
        "\n",
        "We will leverage the custom tools we created earlier in the previous section and try to see if the LLM can automatically call the right tools based on input prompts"
      ],
      "metadata": {
        "id": "bIOhB430gpW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool calling for LLMs with native support for tool or function calling"
      ],
      "metadata": {
        "id": "4Y26Ohn3P54j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tool calling allows a model to respond to a given prompt by generating output that matches a user-defined schema. While the name implies that the model is performing some action, this is actually not the case! The model is coming up with the arguments to a tool, and actually running the tool (or not) is up to the user or agent defined by the user.\n",
        "\n",
        "Many LLM providers, including Anthropic, Cohere, Google, Mistral, OpenAI, and others, support variants of a tool calling feature. These features typically allow requests to the LLM to include available tools and their schemas, and for responses to include calls to these tools.\n",
        "\n"
      ],
      "metadata": {
        "id": "1nACq0NgL5yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "s0wCNpzCBvtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [multiply, search_web_extract_info, get_weather]\n",
        "chatgpt_with_tools = chatgpt.bind_tools(tools)"
      ],
      "metadata": {
        "id": "rjKWxFNgB2t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLMs are still not perfect in tool calling so you might need to play around with the following prompt\n",
        "prompt = \"\"\"\n",
        "            Given only the tools at your disposal, mention tool calls for the following tasks:\n",
        "            Do not change the query given for any search tasks\n",
        "            1. What is 2.1 times 3.5\n",
        "            2. What is the current weather in Mumbai today\n",
        "            3. What are the 4 major Agentic AI Design Patterns\n",
        "         \"\"\"\n",
        "\n",
        "results = chatgpt_with_tools.invoke(prompt)"
      ],
      "metadata": {
        "id": "hJ271K_tB9K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "kLoZWknjCNlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4499ddef-ac2b-43aa-91c3-268e7da58398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gy2gQ6ueZcKPyQMe832kJnqT', 'function': {'arguments': '{\"a\": 2.1, \"b\": 3.5}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_G2phZQICWjtVWF918cYTpqOB', 'function': {'arguments': '{\"query\": \"Mumbai\"}', 'name': 'get_weather'}, 'type': 'function'}, {'id': 'call_Vz69LolmZbpG3uk3z9O1QNMB', 'function': {'arguments': '{\"query\": \"4 major Agentic AI Design Patterns\"}', 'name': 'search_web_extract_info'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 182, 'total_tokens': 255, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6d7dcc9a98', 'id': 'chatcmpl-CG3ZSZKOPs9A0JHHf2VDXiexkb3rM', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--706f9dc4-34ce-4411-8514-35b3a6ba5904-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2.1, 'b': 3.5}, 'id': 'call_gy2gQ6ueZcKPyQMe832kJnqT', 'type': 'tool_call'}, {'name': 'get_weather', 'args': {'query': 'Mumbai'}, 'id': 'call_G2phZQICWjtVWF918cYTpqOB', 'type': 'tool_call'}, {'name': 'search_web_extract_info', 'args': {'query': '4 major Agentic AI Design Patterns'}, 'id': 'call_Vz69LolmZbpG3uk3z9O1QNMB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 182, 'output_tokens': 73, 'total_tokens': 255, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.tool_calls"
      ],
      "metadata": {
        "id": "ckZz5pcpCQau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8cffcb-f58c-42e0-f39d-4611b35db755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'multiply',\n",
              "  'args': {'a': 2.1, 'b': 3.5},\n",
              "  'id': 'call_gy2gQ6ueZcKPyQMe832kJnqT',\n",
              "  'type': 'tool_call'},\n",
              " {'name': 'get_weather',\n",
              "  'args': {'query': 'Mumbai'},\n",
              "  'id': 'call_G2phZQICWjtVWF918cYTpqOB',\n",
              "  'type': 'tool_call'},\n",
              " {'name': 'search_web_extract_info',\n",
              "  'args': {'query': '4 major Agentic AI Design Patterns'},\n",
              "  'id': 'call_Vz69LolmZbpG3uk3z9O1QNMB',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLxNMPTegDed",
        "outputId": "950159c3-2fb5-4ad4-f492-57a73779f9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructuredTool(name='multiply', description='use to multiply numbers', args_schema=<class '__main__.CalculatorInput'>, return_direct=True, func=<function multiply at 0x78cde9365d00>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toolkit = {\n",
        "    \"multiply\": multiply,\n",
        "    \"search_web_extract_info\": search_web_extract_info,\n",
        "    \"get_weather\": get_weather\n",
        "}\n",
        "\n",
        "for tool_call in results.tool_calls:\n",
        "    selected_tool = toolkit[tool_call[\"name\"].lower()]\n",
        "    print(f\"Calling tool: {tool_call['name']}\")\n",
        "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
        "    print(tool_output)\n",
        "    print()"
      ],
      "metadata": {
        "id": "POvGp_xZCpSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935738e7-7487-428e-e723-1bae0e0c79ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling tool: multiply\n",
            "7.3500000000000005\n",
            "\n",
            "Calling tool: get_weather\n",
            "{'location': {'name': 'Mumbai', 'region': 'Maharashtra', 'country': 'India', 'lat': 18.975, 'lon': 72.826, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1757943247, 'localtime': '2025-09-15 19:04'}, 'current': {'last_updated_epoch': 1757943000, 'last_updated': '2025-09-15 19:00', 'temp_c': 25.3, 'temp_f': 77.5, 'is_day': 0, 'condition': {'text': 'Mist', 'icon': '//cdn.weatherapi.com/weather/64x64/night/143.png', 'code': 1030}, 'wind_mph': 9.4, 'wind_kph': 15.1, 'wind_degree': 290, 'wind_dir': 'WNW', 'pressure_mb': 1007.0, 'pressure_in': 29.74, 'precip_mm': 0.04, 'precip_in': 0.0, 'humidity': 89, 'cloud': 75, 'feelslike_c': 27.7, 'feelslike_f': 81.9, 'windchill_c': 26.8, 'windchill_f': 80.3, 'heatindex_c': 30.4, 'heatindex_f': 86.7, 'dewpoint_c': 23.8, 'dewpoint_f': 74.8, 'vis_km': 2.5, 'vis_miles': 1.0, 'uv': 0.0, 'gust_mph': 13.2, 'gust_kph': 21.3, 'short_rad': 0, 'diff_rad': 0, 'dni': 0, 'gti': 0}}\n",
            "\n",
            "Calling tool: search_web_extract_info\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction blocked for url:  https://medium.com/@bijit211987/agentic-design-patterns-cbd0aae2962f\n",
            "['- YouTube\\n# YouTube\\n\\n##  - YouTube\\n\\n### Video Metadata\\n- **Keywords:** video, sharing, camera phone, video phone, free, upload\\n\\n### Description\\nThe video explores four foundational design patterns in agentic AI systems: reflection, tool use, planning, and multi-agent collaboration. These patterns represent the evolution of AI from basic problem-solving to sophisticated autonomous systems capable of making complex decisions with minimal human oversight. Through practical examples using Amazon Bedrock, the video demonstrates how AI agents can self-evaluate, utilize external tools, break down complex tasks, and collaborate effectively. The presentation emphasizes how these patterns enable AI systems to work independently and cooperatively while adapting to various challenges, ultimately transforming traditional work processes and industry operations through enhanced decision-making capabilities.\\n\\nSubscribe to AWS: https://go.aws/subscribe\\n\\nSign up for AWS: https://go.aws/signup\\nAWS free tier: https://go.aws/free\\nExplore more: https://go.aws/more\\nContact AWS: https://go.aws/contact\\n\\nNext steps:\\nExplore on AWS in Analyst Research:  https://go.aws/reports\\nDiscover, deploy, and manage software that runs on AWS: https://go.aws/marketplace\\nJoin the AWS Partner Network: https://go.aws/partners\\nLearn more on how Amazon builds and operates software: https://go.aws/library\\n\\nDo you have technical AWS questions?\\nAsk the community of experts on AWS re:Post: https://go.aws/3lPaoPb\\n\\nWhy AWS?\\nAmazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud. Millions of customers—including the fastest-growing startups, largest enterprises, and leading government agencies—use AWS to be more agile, lower costs, and innovate faster.\\n\\n#AWS #AmazonWebServices #CloudComputing', '4 Agentic Design Patterns and 4 Key AI Trends 2024-2025\\n[![The MLnotes Newsletter](https://substackcdn.com/image/fetch/$s_!Kq64!,w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F88ea2641-8482-4fd4-95b6-f0d56d807c5c_1280x1280.png)](/)\\n\\n# [The MLnotes Newsletter](/)\\n\\nSubscribeSign in\\n\\n# 4 Agentic Design Patterns and 4 Key AI Trends 2024-2025\\n\\n### Insights from Andrew Ng at the recent Snowflake Build 2024\\n\\n[![Angelina Yang\\'s avatar](https://substackcdn.com/image/fetch/$s_!dlHO!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F235cf3f4-9e0a-471f-b1ec-234f3e808f9f_1024x1024.jpeg)](https://substack.com/%40oscrai)\\n\\n[Angelina Yang](https://substack.com/%40oscrai)\\n\\nNov 25, 2024\\n\\n∙ Paid\\n\\n2\\n\\nShare\\n\\nAndrew Ng, our beloved machine learning professor and now a prominent figure in the AI community, just delivered a keynote address at Snowflake\\'s BUILD 2024 conference, where he shared his insights on the current state and future prospects of artificial intelligence. He began by reiterating his well-known analogy of AI as \"**the new electricity,**\" emphasizing its nature as a general-purpose technology with wide-ranging applications across various industries.\\n\\n## The AI Stack: Where Opportunities Abound\\n\\nNg presented his view of the AI stack, consisting of layers from semiconductors at the bottom to cloud infrastructure, foundation models, and finally, applications at the top. While much of the media hype has focused on the lower layers, particularly around technologies like generative AI foundation models, Ng argues that the real opportunities lie in the application layer. This is where he believes the most value and revenue will be generated, as innovative AI applications are developed to solve real-world problems.\\n\\n[![](https://substackcdn.com/image/fetch/$s_!VIjG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff14e53de-3208-4f04-b909-157a6c13a882_1982x1200.png)](https://substackcdn.com/image/fetch/%24s_%21VIjG%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/f14e53de-3208-4f04-b909-157a6c13a882_1982x1200.png)\\n\\n[Source](https://www.youtube.com/watch?v=KrRD7r7y7NY) (same below)\\n\\n## Accelerating Machine Learning Development\\n\\nOne of the most significant trends Ng highlighted is the rapid acceleration of machine learning model development, largely thanks to generative AI. What once took skilled AI teams 6-12 months to build can now potentially be prototyped in a matter of days. This shift is enabling faster experimentation and iteration, leading to new paths for invention and innovation.\\n\\nHowever, this speed comes with its own challenges. Ng pointed out that **evaluations** (or \"**evals**\") are becoming a bottleneck in the development process. The need for robust testing and validation is putting pressure on organizations to speed up these aspects of development to keep pace with the rapid prototyping capabilities now available.\\n\\n[![](https://substackcdn.com/image/fetch/$s_!0jS8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d51fbc-a71a-4f61-9aad-ab1a61180b96_2150x1144.png)](https://substackcdn.com/image/fetch/%24s_%210jS8%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/14d51fbc-a71a-4f61-9aad-ab1a61180b96_2150x1144.png)\\n\\n## The Rise of Agentic AI Workflows\\n\\nThe most exciting technical trend Ng discussed is the emergence of agentic AI workflows. He believes this approach to AI development holds the greatest potential for advancing the field.\\n\\nAgentic AI moves beyond the limitations of traditional \"zero-shot prompting\" to create more sophisticated, multi-step processes that mimic human problem-solving approaches.\\n\\nNg outlined four major design patterns for agentic workflows:\\n\\n[![](https://substackcdn.com/image/fetch/$s_!ng37!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa63c96d0-d1ec-4812-81f1-4da9a5281ade_2016x1150.png)](https://substackcdn.com/image/fetch/%24s_%21ng37%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/a63c96d0-d1ec-4812-81f1-4da9a5281ade_2016x1150.png)\\n\\nSpecifically,\\n\\n1. **Reflection**: Where an AI critiques its own output and uses that feedback to improve.\\n\\n   [![](https://substackcdn.com/image/fetch/$s_!EnA5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e1fe855-fe2a-4b0b-a25e-37fdd7355f41_2094x1182.png)](https://substackcdn.com/image/fetch/%24s_%21EnA5%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/3e1fe855-fe2a-4b0b-a25e-37fdd7355f41_2094x1182.png)\\n2. **Tool Use**: Enabling AI to make API calls and interact with external tools and data sources.\\n\\n   [![](https://substackcdn.com/image/fetch/$s_!ENXW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1baa863-ea42-4ea6-b3c6-7e20749b2cdd_2084x1176.png)](https://substackcdn.com/image/fetch/%24s_%21ENXW%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/d1baa863-ea42-4ea6-b3c6-7e20749b2cdd_2084x1176.png)\\n3. **Planning**: Breaking down complex tasks into a sequence of smaller, manageable steps.\\n\\n   [![](https://substackcdn.com/image/fetch/$s_!RwoP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fedebebfa-16cc-4558-9550-83edbfa27964_2084x1196.png)](https://substackcdn.com/image/fetch/%24s_%21RwoP%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/edebebfa-16cc-4558-9550-83edbfa27964_2084x1196.png)\\n4. **Multi-Agent Collaboration**: Simulating multiple specialized agents working together to solve problems.\\n\\n   [![](https://substackcdn.com/image/fetch/$s_!xj-5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd072490d-6cc8-4813-b848-f0edc76f6fcf_2050x1170.png)](https://substackcdn.com/image/fetch/%24s_%21xj-5%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/d072490d-6cc8-4813-b848-f0edc76f6fcf_2050x1170.png)\\n\\nThese patterns allow for the creation of more capable and flexible AI systems that can tackle increasingly complex tasks.\\n\\n## Visual AI: The Next Frontier\\n\\nNg was particularly excited about the potential of **visual AI,** powered by large multimodal models. He demonstrated how agentic workflows can be applied to image and video processing tasks, showcasing impressive capabilities such as counting players on a soccer field, identifying specific moments in video footage, and generating detailed metadata for video content.\\n\\nThese advancements in visual AI have significant implications for businesses with large repositories of image and video data. Ng suggests that many companies are sitting on valuable visual data that has been difficult to utilize until now. The new capabilities of visual AI agents could unlock tremendous value from these previously underutilized assets.\\n\\n## 4 Key AI Trends to Watch\\n\\n## Keep reading with a 7-day free trial\\n\\nSubscribe to The MLnotes Newsletter to keep reading this post and get 7 days of free access to the full post archives.\\n\\n[Start trial](https://mlnotes.substack.com/subscribe?simple=true&next=https%3A%2F%2Fmlnotes.substack.com%2Fp%2F4-agentic-design-patterns-and-4-key&utm_source=paywall-free-trial&utm_medium=web&utm_content=152122553&coupon=41c7303a)\\n\\n[Already a paid subscriber? **Sign in**](https://substack.com/sign-in?redirect=%2Fp%2F4-agentic-design-patterns-and-4-key&for_pub=mlnotes&change_user=false)\\n\\nPreviousNext\\n\\n© 2025 MLnotes\\n\\n[Privacy](https://substack.com/privacy) ∙ [Terms](https://substack.com/tos) ∙ [Collection notice](https://substack.com/ccpa#personal-data-collected)\\n\\n[Start writing](https://substack.com/signup?utm_source=substack&utm_medium=web&utm_content=footer)[Get the app](https://substack.com/app/app-store-redirect?utm_campaign=app-marketing&utm_content=web-footer-button)\\n\\n[Substack](https://substack.com) is the home for great culture\\n\\nThis site requires JavaScript to run correctly. Please [turn on JavaScript](https://enable-javascript.com/) or unblock scripts', \"Unlocking AI Autonomy: The 11 Must-Know Design Patterns in Agentic AI\\nAgree & Join LinkedIn\\n\\nBy clicking Continue to join or sign in, you agree to LinkedIn’s [User Agreement](/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).\\n\\n[Skip to main content](#main-content)\\n\\n[LinkedIn](/?trk=article-ssr-frontend-pulse_nav-header-logo)\\n\\n* [Top Content](https://www.linkedin.com/top-content?trk=article-ssr-frontend-pulse_guest_nav_menu_topContent)\\n* [People](https://www.linkedin.com/pub/dir/%2B/%2B?trk=article-ssr-frontend-pulse_guest_nav_menu_people)\\n* [Learning](https://www.linkedin.com/learning/search?trk=article-ssr-frontend-pulse_guest_nav_menu_learning)\\n* [Jobs](https://www.linkedin.com/jobs/search?trk=article-ssr-frontend-pulse_guest_nav_menu_jobs)\\n* [Games](https://www.linkedin.com/games?trk=article-ssr-frontend-pulse_guest_nav_menu_games)\\n\\n[Join now](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&trk=article-ssr-frontend-pulse_nav-header-join)\\n[Sign in](https://www.linkedin.com/uas/login?session_redirect=%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&fromSignIn=true&trk=article-ssr-frontend-pulse_nav-header-signin)\\n[![]()](https://www.linkedin.com/uas/login?session_redirect=%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&fromSignIn=true&trk=article-ssr-frontend-pulse_nav-header-signin)\\n\\n![Unlocking AI Autonomy: The 11 Must-Know Design Patterns in Agentic AI](https://media.licdn.com/dms/image/v2/D4E12AQFof9CJAGu0Dg/article-cover_image-shrink_720_1280/B4EZVkaT8XGwAM-/0/1741146378445?e=2147483647&v=beta&t=Lqziw5psuV4uE0j_Uf_8GMKyzizJ_F8k0L2cMP94fiQ)\\n\\n# Unlocking AI Autonomy: The 11 Must-Know Design Patterns in Agentic AI\\n\\n* [Report this article](/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&trk=article-ssr-frontend-pulse_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=PONCHO_ARTICLE&_f=guest-reporting)\\n\\n[Manas Mallik](https://in.linkedin.com/in/manaskmallik)\\n![Manas Mallik]()\\n\\n### Manas Mallik\\n\\n#### Driving Innovation Across AI, Fintech & Identity | 24+ Years Leading High-Impact Technology Teams\\n\\nPublished Mar 5, 2025\\n\\n[+ Follow](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&trk=article-ssr-frontend-pulse_publisher-author-card)\\n\\n### Introduction\\n\\nAgentic AI is revolutionizing the way artificial intelligence operates by enabling autonomous decision-making, dynamic reasoning, and adaptive task execution. Instead of relying on simple, rule-based automation, agentic AI structures its workflows using sophisticated **design patterns** that enhance its ability to plan, learn, and act independently.\\n\\nWe will explore **11 essential Agentic AI design patterns** that are shaping industries like finance, healthcare, robotics, and autonomous systems. Understanding these patterns is key to unlocking the full potential of AI-driven solutions.\\n\\n---\\n\\n### The 11 Key Design Patterns in Agentic AI\\n\\n### 1. ReAct Agent – Thinking and Acting in a Loop\\n\\n**Concept:** This pattern merges **reasoning and action** in an iterative loop, allowing AI to think step by step before making decisions. Instead of blindly executing commands, the agent reasons through a problem, retrieves relevant knowledge, and takes actions accordingly.\\n\\n🔹 **Use Cases:** AI-powered research assistants, autonomous planning, real-time problem-solving bots.\\n\\n---\\n\\n### 2. Agentic RAG (Retrieval-Augmented Generation) – AI with a Knowledge Engine\\n\\n**Concept:** Expands standard RAG (Retrieval-Augmented Generation) by allowing an AI agent to plan retrievals, refine queries, and adapt responses dynamically.\\n\\n🔹 **Use Cases:** AI-powered search tools, legal research assistants, medical document summarization.\\n\\n---\\n\\n### 3. Reflexion – AI that Learns from Mistakes\\n\\n**Concept:** AI agents equipped with self-monitoring capabilities analyze their past actions, identify mistakes, and refine their decision-making process over time.\\n\\n🔹 **Use Cases:** AI debugging, self-improving chatbots, automated code review.\\n\\n---\\n\\n### 4. Reasoning Without Observation – Thinking Without External Inputs\\n\\n**Concept:** Unlike standard AI models that depend on external real-time data, this pattern enables AI to make decisions purely based on pre-trained knowledge and internal logic.\\n\\n🔹 **Use Cases:** Theorem solving, legal reasoning, decision-making in data-limited environments.\\n\\n---\\n\\n### 5. Hierarchical Multi-Agent Systems – AI with Structured Autonomy\\n\\n**Concept:** AI agents are organized in a **tiered structure**, where higher-level agents manage strategic decisions while lower-level agents execute specific tasks.\\n\\n🔹 **Use Cases:** Robotics, corporate AI governance, smart traffic control, supply chain optimization.\\n\\n---\\n\\n### 6. Orchestrator-Worker Model – Task Delegation at Scale\\n\\n**Concept:** A **central orchestrator agent** assigns tasks to multiple worker agents, each specializing in a particular function, ensuring efficient task execution.\\n\\n🔹 **Use Cases:** AI-powered workflow automation, large-scale AI task execution, enterprise AI solutions.\\n\\n---\\n\\n### 7. Prompt Chaining – Stepwise Refinement for AI\\n\\n**Concept:** AI outputs dynamically refine subsequent prompts, creating a structured flow of improved responses over multiple iterations.\\n\\n🔹 **Use Cases:** AI-driven content generation, chatbot memory systems, step-by-step problem-solving AI.\\n\\n---\\n\\n### 8. Parallelization – Speeding Up AI Processing\\n\\n**Concept:** AI agents work in parallel on independent subtasks, significantly reducing computation time and improving efficiency.\\n\\n🔹 **Use Cases:** Distributed AI workloads, parallelized content moderation, high-performance AI systems.\\n\\n---\\n\\n### 9. Evaluator-Optimizer – AI that Checks and Improves Itself\\n\\n**Concept:** One agent evaluates the quality of outputs, while another refines and optimizes them based on feedback.\\n\\n🔹 **Use Cases:** AI model fine-tuning, reinforcement learning, AI-driven quality assurance systems.\\n\\n---\\n\\n### 10. Multi-Agent Debate – AI that Argues to Find the Best Answer\\n\\n**Concept:** Multiple AI agents engage in structured debates to refine reasoning and reach the most logical conclusion.\\n\\n🔹 **Use Cases:** AI-powered fact-checking, ethical AI systems, AI-driven policy decision-making.\\n\\n---\\n\\n### 11. Mixture of Agents – AI Specialists Working Together\\n\\n**Concept:** Combines different types of AI models (e.g., vision, language, reasoning) to collaborate and solve problems holistically.\\n\\n🔹 **Use Cases:** Multimodal AI systems, AI-driven creative tools, AI-powered virtual assistants.\\n\\n---\\n\\n### Comparison of Agentic AI Design Patterns\\n\\n![](//:0)\\n\\n---\\n\\n### Why These Design Patterns Matter\\n\\nAgentic AI design patterns provide a **structured, scalable** approach to developing AI systems that can think, act, and learn autonomously. Here’s why they’re crucial:\\n\\n✅ **Scalability & Efficiency:** Parallelization and Orchestrator-Worker models enable AI to handle large-scale operations seamlessly.\\n\\n✅ **Autonomous Learning & Adaptation:** Reflexion and Evaluator-Optimizer ensure AI systems continuously improve.\\n\\n✅ **Collaboration & Specialization:** Hierarchical Multi-Agent and Mixture of Agents patterns create AI teams that specialize in different tasks.\\n\\n---\\n\\n### Final Thoughts\\n\\nMastering these **Agentic AI design patterns** is the key to unlocking **truly intelligent AI systems**. Whether you’re a developer, researcher, or entrepreneur, understanding how these patterns work will help you create AI that is **more powerful, efficient, and adaptable**.\\n\\nReady to start implementing these patterns? Stay tuned for **deep dives into each design pattern**, with detailed implementation strategies and real-world case studies!\\n\\n---\\n\\n[Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&trk=article-ssr-frontend-pulse_x-social-details_like-toggle_like-cta)\\n\\n![Like]()\\nLike\\n\\n![Celebrate]()\\nCelebrate\\n\\n![Support]()\\nSupport\\n\\n![Love]()\\nLove\\n\\n![Insightful]()\\nInsightful\\n\\n![Funny]()\\nFunny\\n\\n[Comment](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&trk=article-ssr-frontend-pulse_comment-cta)\\n\\n* Copy\\n* LinkedIn\\n* Facebook\\n* Twitter\\n\\nShare\\n\\n[![]()\\n![]()\\n\\n10](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&trk=article-ssr-frontend-pulse_x-social-details_likes-count_social-actions-reactions)\\n\\nTo view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&trk=article-ssr-frontend-pulse_x-social-details_feed-cta-banner-cta)\\n\\n## More articles by Manas Mallik\\n\\n* [Voice is the New Identity: Why AI Voice Bots Will Transform Verification in India](https://www.linkedin.com/pulse/voice-new-identity-why-ai-bots-transform-verification-manas-mallik-7zksc)\\n\\n  ![]()\\n\\n  Sep 10, 2025\\n\\n  ### Voice is the New Identity: Why AI Voice Bots Will Transform Verification in India\\n\\n  When most people think of identity verification, they imagine an API call: Enter Aadhaar. Receive OTP.\\n\\n  ![]()\\n  ![]()\\n\\n  16\\n\\n  1 Comment\\n* [Digital India’s Secret Ingredient: Why Every Innovation Begins with Identity](https://www.linkedin.com/pulse/digital-indias-secret-ingredient-why-every-innovation-manas-mallik-uzlzc)\\n\\n  ![]()\\n\\n  Aug 30, 2025\\n\\n  ### Digital India’s Secret Ingredient: Why Every Innovation Begins with Identity\\n\\n  Over the last two decades, India has done something remarkable: it has built one of the world’s most inclusive digital…\\n\\n  ![]()\\n\\n  21\\n\\n  1 Comment\\n* [Onboarding Built on Trust, Not Engineering Debt](https://www.linkedin.com/pulse/onboarding-built-trust-engineering-debt-manas-mallik-c0yhc)\\n\\n  ![]()\\n\\n  May 30, 2025\\n\\n  ### Onboarding Built on Trust, Not Engineering Debt\\n\\n  Why idto.ai is rethinking how companies verify users? A few months ago, we were helping a mid-sized delivery company…\\n\\n  ![]()\\n  ![]()\\n\\n  38\\n* [Unlock the AI Revolution: How OpenAI’s Agent SDK is Transforming Automation Forever!](https://www.linkedin.com/pulse/unlock-ai-revolution-how-openais-agent-sdk-automation-manas-mallik-otb3c)\\n\\n  ![]()\\n\\n  Mar 18, 2025\\n\\n  ### Unlock the AI Revolution: How OpenAI’s Agent SDK is Transforming Automation Forever!\\n\\n  In today’s rapidly evolving tech landscape, intelligent automation isn’t just an advantage—it’s a necessity. The OpenAI…\\n\\n  ![]()\\n\\n  3\\n* [Model Context Protocol (MCP): The Future of AI Integration](https://www.linkedin.com/pulse/model-context-protocol-mcp-future-ai-integration-manas-mallik-3jjhc)\\n\\n  ![]()\\n\\n  Mar 13, 2025\\n\\n  ### Model Context Protocol (MCP): The Future of AI Integration\\n\\n  Introduction AI systems are evolving beyond simple question-answering models. They are becoming agentic, meaning they…\\n\\n  ![]()\\n\\n  11\\n* [Unlocking the Black Box: AI Reasoning and Explainability](https://www.linkedin.com/pulse/unlocking-black-box-ai-reasoning-explainability-manas-mallik-ufguc)\\n\\n  ![]()\\n\\n  Mar 11, 2025\\n\\n  ### Unlocking the Black Box: AI Reasoning and Explainability\\n\\n  Artificial intelligence is no longer just a tool for automation—it’s shaping decisions in finance, healthcare, and…\\n\\n  ![]()\\n\\n  6\\n* [Why Does Generative AI Cost Vary So Much? A Look at Text vs. Video](https://www.linkedin.com/pulse/why-does-generative-ai-cost-vary-so-much-look-text-vs-manas-mallik-1xd9c)\\n\\n  ![]()\\n\\n  Mar 7, 2025\\n\\n  ### Why Does Generative AI Cost Vary So Much? A Look at Text vs. Video\\n\\n  Generative AI is transforming how we create content—whether it’s an AI writing assistant drafting blog posts or a video…\\n\\n  ![]()\\n  ![]()\\n\\n  19\\n\\n  1 Comment\\n* [Generative AI to Agentic AI: 6-Week Learning Path for Beginners](https://www.linkedin.com/pulse/generative-ai-agentic-6-week-learning-path-beginners-manas-mallik-zxqec)\\n\\n  ![]()\\n\\n  Mar 6, 2025\\n\\n  ### Generative AI to Agentic AI: 6-Week Learning Path for Beginners\\n\\n  Week 1: Introduction to AI and Generative AI AI FundamentalsDistinguish between AI, Machine Learning, and Deep…\\n\\n  ![]()\\n  ![]()\\n\\n  16\\n\\n  1 Comment\\n* [Deep Research by OpenAI: Your AI-Powered Research Assistant](https://www.linkedin.com/pulse/deep-research-openai-your-ai-powered-assistant-manas-mallik-fjjsc)\\n\\n  ![]()\\n\\n  Mar 4, 2025\\n\\n  ### Deep Research by OpenAI: Your AI-Powered Research Assistant\\n\\n  Exploring OpenAI's Deep Research: The Future of AI-Powered Analysis Artificial Intelligence has transformed numerous…\\n\\n  ![]()\\n\\n  7\\n* [Small But Mighty: How SLMs Are Reshaping AI](https://www.linkedin.com/pulse/small-mighty-how-slms-reshaping-ai-manas-mallik-wffpc)\\n\\n  ![]()\\n\\n  Mar 3, 2025\\n\\n  ### Small But Mighty: How SLMs Are Reshaping AI\\n\\n  What is a Small Language Model (SLM)? A Small Language Model (SLM) is a compact version of a Large Language Model (LLM)…\\n\\n  ![]()\\n  ![]()\\n\\n  17\\n\\nShow more\\n\\n[See all articles](https://in.linkedin.com/in/manaskmallik/recent-activity/articles/)\\n\\n## Sign in\\n\\nStay updated on your professional world\\n\\n[Sign in](https://www.linkedin.com/uas/login?session_redirect=%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&trk=article-ssr-frontend-pulse_xandr-ad-fallback_signin)\\n\\nBy clicking Continue to join or sign in, you agree to LinkedIn’s [User Agreement](/legal/user-agreement?trk=article-ssr-frontend-pulse_auth-button_user-agreement), [Privacy Policy](/legal/privacy-policy?trk=article-ssr-frontend-pulse_auth-button_privacy-policy), and [Cookie Policy](/legal/cookie-policy?trk=article-ssr-frontend-pulse_auth-button_cookie-policy).\\n\\nNew to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Funlocking-ai-autonomy-11-must-know-design-patterns-agentic-mallik-2uase&trk=article-ssr-frontend-pulse_xandr-ad-fallback_join-link)\\n\\n## Explore topics\\n\\n* [Sales](https://www.linkedin.com/pulse/topics/sales-s5/)\\n* [Marketing](https://www.linkedin.com/pulse/topics/marketing-s2461/)\\n* [IT Services](https://www.linkedin.com/pulse/topics/it-services-s57547/)\\n* [Business Administration](https://www.linkedin.com/pulse/topics/business-administration-s50111/)\\n* [HR Management](https://www.linkedin.com/pulse/topics/hr-management-s50359/)\\n* [Engineering](https://www.linkedin.com/pulse/topics/engineering-s166/)\\n* [Soft Skills](https://www.linkedin.com/pulse/topics/soft-skills-s2976/)\\n* [See All](https://www.linkedin.com/pulse/topics/home/)\\n\\n* LinkedIn\\n\\n  © 2025\\n* [About](https://about.linkedin.com?trk=d_flagship2_pulse_read_footer-about)\\n* [Accessibility](https://www.linkedin.com/accessibility?trk=d_flagship2_pulse_read_footer-accessibility)\\n* [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=d_flagship2_pulse_read_footer-user-agreement)\\n* [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=d_flagship2_pulse_read_footer-privacy-policy)\\n* [Your California Privacy Choices](https://www.linkedin.com/legal/california-privacy-disclosure?trk=d_flagship2_pulse_read_footer-california-privacy-rights-act)\\n* [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=d_flagship2_pulse_read_footer-cookie-policy)\\n* [Copyright Policy](https://www.linkedin.com/legal/copyright-policy?trk=d_flagship2_pulse_read_footer-copyright-policy)\\n* [Brand Policy](https://brand.linkedin.com/policies?trk=d_flagship2_pulse_read_footer-brand-policy)\\n* [Guest Controls](https://www.linkedin.com/psettings/guest-controls?trk=d_flagship2_pulse_read_footer-guest-controls)\\n* [Community Guidelines](https://www.linkedin.com/legal/professional-community-policies?trk=d_flagship2_pulse_read_footer-community-guide)\\n* + العربية (Arabic)\\n  + বাংলা (Bangla)\\n  + Čeština (Czech)\\n  + Dansk (Danish)\\n  + Deutsch (German)\\n  + Ελληνικά (Greek)\\n  + **English (English)**\\n  + Español (Spanish)\\n  + فارسی (Persian)\\n  + Suomi (Finnish)\\n  + Français (French)\\n  + हिंदी (Hindi)\\n  + Magyar (Hungarian)\\n  + Bahasa Indonesia (Indonesian)\\n  + Italiano (Italian)\\n  + עברית (Hebrew)\\n  + 日本語 (Japanese)\\n  + 한국어 (Korean)\\n  + मराठी (Marathi)\\n  + Bahasa Malaysia (Malay)\\n  + Nederlands (Dutch)\\n  + Norsk (Norwegian)\\n  + ਪੰਜਾਬੀ (Punjabi)\\n  + Polski (Polish)\\n  + Português (Portuguese)\\n  + Română (Romanian)\\n  + Русский (Russian)\\n  + Svenska (Swedish)\\n  + తెలుగు (Telugu)\\n  + ภาษาไทย (Thai)\\n  + Tagalog (Tagalog)\\n  + Türkçe (Turkish)\\n  + Українська (Ukrainian)\\n  + Tiếng Việt (Vietnamese)\\n  + 简体中文 (Chinese (Simplified))\\n  + 正體中文 (Chinese (Traditional))\\n\\n  Language\", '5 Agentic AI Design Patterns - by Avi Chawla\\n[![Daily Dose of Data Science](https://substackcdn.com/image/fetch/$s_!heKx!,w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5dc1fee-2d1e-4892-b219-4b96f6998ab5_288x288.png)](/)\\n\\n# [Daily Dose of Data Science](/)\\n\\nSubscribeSign in\\n\\n# 5 Agentic AI Design Patterns\\n\\n### ...explained visually\\n\\n[![Avi Chawla\\'s avatar](https://substackcdn.com/image/fetch/$s_!fRqh!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0dc0dc6-c4ff-4fe7-b467-bfb654e7dc6f_287x287.jpeg)](https://substack.com/%40avichawla)\\n\\n[Avi Chawla](https://substack.com/%40avichawla)\\n\\nJan 23, 2025\\n\\n56\\n\\n[1](https://blog.dailydoseofds.com/p/5-agentic-ai-design-patterns/comments)5\\n\\nShare\\n\\n### [Web scraping in pure English with Firecrawl Extract](https://www.firecrawl.dev/i/api)\\n\\nWith simple English prompts, you can now effortlessly extract clean, structured data from the web.\\n\\n**[Firecrawl Extract](https://www.firecrawl.dev/i/api)** does this as follows:\\n\\n[![](https://substackcdn.com/image/fetch/$s_!RaEY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf891ef7-4dae-4143-869d-e63549b2e6d3_1888x1520.png)](https://www.firecrawl.dev/i/api)\\n\\n* Provide the website URL and specify what you want to extract as a prompt.\\n* **[FireCrawl Extract](https://www.firecrawl.dev/i/api)** automatically generates the request parameters and a schema (all editable).\\n* Click “Run” and get clean, structured data in seconds.\\n\\nIn the above image, I asked it to extract the authors of this newsletter, and it returned the correct output—Avi Chawla and Akshay Pachaar.\\n\\n**[FireCrawl](https://www.firecrawl.dev/i/api)** also generates code snippets to run the same job programmatically.\\n\\n[Start scrapping with FireCrawl](https://www.firecrawl.dev/i/api)\\n\\nThanks to **[FireCrawl](https://www.firecrawl.dev/i/api)** for showing us their powerful scraping capabilities and partnering today!\\n\\n---\\n\\n### 5 Agentic AI Design Patterns\\n\\nAgentic behaviors allow LLMs to refine their output by incorporating self-evaluation, planning, and collaboration!\\n\\nThe following visual depicts the 5 most popular design patterns employed in building AI agents.\\n\\n[![](https://substackcdn.com/image/fetch/$s_!8ClH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4b81de-bce1-4937-9c09-5021e1cb3bdf_948x1072.gif)](https://substackcdn.com/image/fetch/%24s_%218ClH%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/6f4b81de-bce1-4937-9c09-5021e1cb3bdf_948x1072.gif)\\n\\nLet\\'s understand them below!\\n\\n> On a side note, we started a beginner-friendly crash course on RAGs recently with implementations, which covers:\\n>\\n> * [\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-1-with-implementations/)**[RAG fundamentals](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-1-with-implementations/)**[\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-1-with-implementations/)[\\u200b\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-2-with-implementations/)\\n> * [\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-2-with-implementations/)**[RAG evaluation](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-2-with-implementations/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-2-with-implementations/)\\n> * [\\u200b\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-2-with-implementations/)[\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-3-with-implementation/)**[RAG optimization](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-3-with-implementation/)**[\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-3-with-implementation/)[\\u200b\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-5-with-implementation/)\\n> * [\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-5-with-implementation/)**[Multimodal RAG](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-5-with-implementation/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-5-with-implementation/)\\n> * [\\u200b\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-5-with-implementation/)[\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-7-with-implementation/)**[Graph RAG](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-7-with-implementation/)**[\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-7-with-implementation/)\\n> * [\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-8-with-implementation/)**[Multivector retrieval using ColBERT](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-8-with-implementation/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-8-with-implementation/)\\n> * [\\u200b\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-8-with-implementation/)[\\u200b\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-9-with-implementation/)**[RAG over complex real word docs ft. ColPali](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-9-with-implementation/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-9-with-implementation/)\\n\\n---\\n\\n#### 1) Reflection pattern\\n\\n[![](https://substackcdn.com/image/fetch/$s_!Qjat!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8deb345-27cf-4bec-8e7f-f1cd25fabcab_716x546.gif)](https://substackcdn.com/image/fetch/%24s_%21Qjat%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/a8deb345-27cf-4bec-8e7f-f1cd25fabcab_716x546.gif)\\n\\nThe AI reviews its work to spot mistakes and iterate until it produces the final response.\\n\\n#### 2) Tool use pattern\\n\\n[![](https://substackcdn.com/image/fetch/$s_!B2nY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a9fbda7-77a8-4a7a-ac2c-077fb98e53a6_716x552.gif)](https://substackcdn.com/image/fetch/%24s_%21B2nY%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/1a9fbda7-77a8-4a7a-ac2c-077fb98e53a6_716x552.gif)\\n\\nTools allow LLMs to gather more information by:\\n\\n* Querying a vector database\\n* Executing Python scripts\\n* Invoking APIs, etc.\\n\\nThis is helpful since the LLM is not solely reliant on its internal knowledge.\\n\\n#### 3) ReAct (Reason and Act) pattern\\n\\n[![](https://substackcdn.com/image/fetch/$s_!3vHI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd02b2eaa-16c3-4f92-8f97-06329fbcccd4_716x550.gif)](https://substackcdn.com/image/fetch/%24s_%213vHI%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/d02b2eaa-16c3-4f92-8f97-06329fbcccd4_716x550.gif)\\n\\nReAct combines the above two patterns:\\n\\n* The Agent can reflect on the generated outputs.\\n* It can interact with the world using tools.\\n\\nThis makes it one of the most powerful patterns used today.\\n\\n#### 4) Planning pattern\\n\\n[![](https://substackcdn.com/image/fetch/$s_!W1ND!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F643b6891-84f6-4672-aa1f-4724c5ad2d12_716x526.gif)](https://substackcdn.com/image/fetch/%24s_%21W1ND%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/643b6891-84f6-4672-aa1f-4724c5ad2d12_716x526.gif)\\n\\nInstead of solving a request in one go, the AI creates a roadmap by:\\n\\n* Subdividing tasks\\n* Outlining objectives\\n\\nThis strategic thinking can solve tasks more effectively.\\n\\n#### 5) Multi-agent pattern\\n\\n[![](https://substackcdn.com/image/fetch/$s_!BpPm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686c08ca-989b-4083-9128-e6bc2a8c07b5_716x526.gif)](https://substackcdn.com/image/fetch/%24s_%21BpPm%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/686c08ca-989b-4083-9128-e6bc2a8c07b5_716x526.gif)\\n\\nIn this setup:\\n\\n* We have several agents.\\n* Each Agent is assigned a dedicated role and task.\\n* Each Agent can also access tools.\\n\\nAll agents work together to deliver the final outcome while delegating tasks to other agents if needed.\\n\\n---\\n\\nWe\\'ll soon dive deep into each of these patterns, showcasing real-world use cases and code implementations.\\n\\nIn the meantime, make sure you are fully equipped with everything we have covered so far like:\\n\\n* [\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-1-with-implementations/)**[RAG fundamentals](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-1-with-implementations/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-1-with-implementations/)\\n* [\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-2-with-implementations/)**[RAG evaluation](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-2-with-implementations/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-2-with-implementations/)\\n* [\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-3-with-implementation/)**[RAG optimization](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-3-with-implementation/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-3-with-implementation/)\\n* [\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-5-with-implementation/)**[Multimodal RAG](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-5-with-implementation/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-5-with-implementation/)\\n* [\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-7-with-implementation/)**[Graph RAG](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-7-with-implementation/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-7-with-implementation/)\\n* [\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-8-with-implementation/)**[Multivector retrieval using ColBERT](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-8-with-implementation/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-8-with-implementation/)\\n* [\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-9-with-implementation/)**[RAG over complex real word docs ft. ColPali](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-9-with-implementation/)**[\\u200b](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-9-with-implementation/)\\n\\nThanks for reading Daily Dose of Data Science! Subscribe below and receive a free data science PDF (530+ pages) with 150+ core data science and machine learning lessons.\\n\\nSubscribe\\n\\n---\\n\\n### **P.S. For those wanting to develop “Industry ML” expertise:**\\n\\n[![](https://substackcdn.com/image/fetch/$s_!cn8y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F939bede7-b0de-4770-a3e9-34d39488e776_2733x1020.png)](https://substackcdn.com/image/fetch/%24s_%21cn8y%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/939bede7-b0de-4770-a3e9-34d39488e776_2733x1020.png)\\n\\nAt the end of the day, all businesses care about *impact*. That’s it!\\n\\n* Can you reduce costs?\\n* Drive revenue?\\n* Can you scale ML models?\\n* Predict trends before they happen?\\n\\nWe have discussed several other topics (with implementations) in the past that align with such topics.\\n\\n[Develop \"Industry ML\" Skills](https://www.dailydoseofds.com/membership)\\n\\nHere are some of them:\\n\\n* Learn sophisticated graph architectures and how to train them on graph data: [A Crash Course on Graph Neural Networks – Part 1](https://www.dailydoseofds.com/a-crash-course-on-graph-neural-networks-implementation-included/).\\n* So many real-world NLP systems rely on pairwise context scoring. Learn scalable approaches here: [Bi-encoders and Cross-encoders for Sentence Pair Similarity Scoring – Part 1](https://www.dailydoseofds.com/bi-encoders-and-cross-encoders-for-sentence-pair-similarity-scoring-part-1/).\\n* Learn techniques to run large models on small devices: [Quantization: Optimize ML Models to Run Them on Tiny Hardware](https://www.dailydoseofds.com/quantization-optimize-ml-models-to-run-them-on-tiny-hardware/).\\n* Learn how to generate prediction intervals or sets with strong statistical guarantees for increasing trust: [Conformal Predictions: Build Confidence in Your ML Model’s Predictions](https://www.dailydoseofds.com/conformal-predictions-build-confidence-in-your-ml-models-predictions/).\\n* Learn how to identify causal relationships and answer business questions: [A Crash Course on Causality – Part 1](https://www.dailydoseofds.com/a-crash-course-on-causality-part-1/)\\n* Learn how to scale ML model training: [A Practical Guide to Scaling ML Model Training](https://www.dailydoseofds.com/how-to-scale-model-training/).\\n* Learn techniques to reliably roll out new models in production: [5 Must-Know Ways to Test ML Models in Production (Implementation Included)](https://www.dailydoseofds.com/5-must-know-ways-to-test-ml-models-in-production-implementation-included/)\\n* Learn how to build privacy-first ML systems: [Federated Learning: A Critical Step Towards Privacy-Preserving Machine Learning](https://www.dailydoseofds.com/federated-learning-a-critical-step-towards-privacy-preserving-machine-learning/).\\n* Learn how to compress ML models and reduce costs: [Model Compression: A Critical Step Towards Efficient Machine Learning](https://www.dailydoseofds.com/model-compression-a-critical-step-towards-efficient-machine-learning/).\\n\\nAll these resources will help you cultivate key skills that businesses and companies care about the most.\\n\\n56\\n\\n[1](https://blog.dailydoseofds.com/p/5-agentic-ai-design-patterns/comments)5\\n\\nShare\\n\\nPreviousNext\\n\\n#### Discussion about this post\\n\\nCommentsRestacks\\n\\n![User\\'s avatar](https://substackcdn.com/image/fetch/$s_!TnFC!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png)\\n\\n[![alex flow\\'s avatar](https://substackcdn.com/image/fetch/$s_!rx6Z!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6e46c74-d4cd-4a22-b576-a4d4ec74a433_144x144.png)](https://substack.com/profile/137824764-alex-flow?utm_source=comment)\\n\\n[alex flow](https://substack.com/profile/137824764-alex-flow?utm_source=substack-feed-item)\\n\\n[Feb 8](https://blog.dailydoseofds.com/p/5-agentic-ai-design-patterns/comment/92070901 \"Feb 8, 2025, 7:56 PM\")\\n\\nThis is amazing, what tool did you use to make such nice charts?\\n\\nExpand full comment\\n\\nReplyShare\\n\\nTopLatestDiscussions\\n\\nNo posts\\n\\nReady for more?\\n\\nSubscribe\\n\\n© 2025 Avi Chawla\\n\\n[Privacy](https://substack.com/privacy) ∙ [Terms](https://substack.com/tos) ∙ [Collection notice](https://substack.com/ccpa#personal-data-collected)\\n\\n[Start writing](https://substack.com/signup?utm_source=substack&utm_medium=web&utm_content=footer)[Get the app](https://substack.com/app/app-store-redirect?utm_campaign=app-marketing&utm_content=web-footer-button)\\n\\n[Substack](https://substack.com) is the home for great culture\\n\\nThis site requires JavaScript to run correctly. Please [turn on JavaScript](https://enable-javascript.com/) or unblock scripts']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools"
      ],
      "metadata": {
        "id": "yJXO6NaNKVQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e20a44-6dc6-4429-9dfb-6e75baccf439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StructuredTool(name='multiply', description='use to multiply numbers', args_schema=<class '__main__.CalculatorInput'>, return_direct=True, func=<function multiply at 0x78cde9365d00>),\n",
              " StructuredTool(name='search_web_extract_info', description='Search the web for a query and extracts useful information from the search links', args_schema=<class 'langchain_core.utils.pydantic.search_web_extract_info'>, func=<function search_web_extract_info at 0x78cde9366160>),\n",
              " StructuredTool(name='get_weather', description='Search weatherapi to get the current weather.', args_schema=<class 'langchain_core.utils.pydantic.get_weather'>, func=<function get_weather at 0x78cec98747c0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool calling for LLMs without native support for tool or function calling"
      ],
      "metadata": {
        "id": "_1Yc8d9MQDqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some models like ChatGPT have been fine-tuned for tool calling and provide a dedicated API for tool calling. Generally, such models are better at tool calling than non-fine-tuned models, and are recommended for use cases that require tool calling.\n",
        "\n",
        "Here we will explore an alternative method to invoke tools if you're using a model that does not natively support tool calling (even though we use ChatGPT here which supports it, we will assume it could be any LLM which doesn't support tool calling).\n",
        "\n",
        "We'll do this by simply writing a prompt that will get the model to invoke the appropriate tools."
      ],
      "metadata": {
        "id": "yIXJC1-9RXnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import render_text_description\n",
        "\n",
        "rendered_tools = render_text_description(tools)\n",
        "print(rendered_tools)"
      ],
      "metadata": {
        "id": "xr2Wt-iuHEuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb36771-7b90-46ad-947c-e50f4291e810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiply(a: float, b: float) -> float - use to multiply numbers\n",
            "search_web_extract_info(query: str) -> list - Search the web for a query and extracts useful information from the search links\n",
            "get_weather(query: str) -> list - Search weatherapi to get the current weather.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = f\"\"\"\\\n",
        "You are an assistant that has access to the following set of tools.\n",
        "Here are the names and descriptions for each tool:\n",
        "\n",
        "{rendered_tools}\n",
        "\n",
        "Given the user instructions, for each instruction do the following:\n",
        " - Return the name and input of the tool to use.\n",
        " - Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
        " - The `arguments` should be a dictionary, with keys corresponding\n",
        "   to the argument names and the values corresponding to the requested values.\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"user\", \"{input}\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "sO8AT_uiK3zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = [\n",
        "                  {\"input\" : \"What is 2.1 times 3.5\"},\n",
        "                  {\"input\" : \"What is the current weather in Gurgaon\"},\n",
        "                  {\"input\" : \"Tell me about the current state of Agentic AI in the industry\" }\n",
        "               ]"
      ],
      "metadata": {
        "id": "aNq3a5B9HEy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "chain = (prompt\n",
        "            |\n",
        "         chatgpt\n",
        "            |\n",
        "         JsonOutputParser())"
      ],
      "metadata": {
        "id": "GJWWhI0NHE3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses = chain.map().invoke(instructions)"
      ],
      "metadata": {
        "id": "a8O7pvViHE5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses"
      ],
      "metadata": {
        "id": "4F7Cqo6yMGzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc104363-8a06-47ff-a90b-3de625006109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'multiply', 'arguments': {'a': 2.1, 'b': 3.5}},\n",
              " {'name': 'get_weather', 'arguments': {'query': 'Gurgaon'}},\n",
              " {'name': 'search_web_extract_info',\n",
              "  'arguments': {'query': 'current state of Agentic AI in the industry 2024'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toolkit = {\n",
        "    \"multiply\": multiply,\n",
        "    \"search_web_extract_info\": search_web_extract_info,\n",
        "    \"get_weather\": get_weather\n",
        "}\n",
        "\n",
        "for tool_call in responses:\n",
        "    selected_tool = toolkit[tool_call[\"name\"].lower()]\n",
        "    print(f\"Calling tool: {tool_call['name']}\")\n",
        "    tool_output = selected_tool.invoke(tool_call[\"arguments\"])\n",
        "    print(tool_output)\n",
        "    print()"
      ],
      "metadata": {
        "id": "rLsWGvOkM5Qe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a709f1d3-e675-4f30-fac6-aaacc7e160c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling tool: multiply\n",
            "7.3500000000000005\n",
            "\n",
            "Calling tool: get_weather\n",
            "{'location': {'name': 'Gurgaon', 'region': 'Haryana', 'country': 'India', 'lat': 28.4667, 'lon': 77.0333, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1757943377, 'localtime': '2025-09-15 19:06'}, 'current': {'last_updated_epoch': 1757943000, 'last_updated': '2025-09-15 19:00', 'temp_c': 32.2, 'temp_f': 90.0, 'is_day': 0, 'condition': {'text': 'Mist', 'icon': '//cdn.weatherapi.com/weather/64x64/night/143.png', 'code': 1030}, 'wind_mph': 4.5, 'wind_kph': 7.2, 'wind_degree': 301, 'wind_dir': 'WNW', 'pressure_mb': 1003.0, 'pressure_in': 29.62, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 56, 'cloud': 25, 'feelslike_c': 33.2, 'feelslike_f': 91.7, 'windchill_c': 33.7, 'windchill_f': 92.6, 'heatindex_c': 35.5, 'heatindex_f': 95.9, 'dewpoint_c': 18.1, 'dewpoint_f': 64.7, 'vis_km': 5.0, 'vis_miles': 3.0, 'uv': 0.0, 'gust_mph': 7.3, 'gust_kph': 11.7, 'short_rad': 0, 'diff_rad': 0, 'dni': 0, 'gti': 0}}\n",
            "\n",
            "Calling tool: search_web_extract_info\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 2/5 [00:00<00:00,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction blocked for url:  https://market.us/report/agentic-ai-market/\n",
            "Extraction blocked for url:  https://www.gartner.com/en/newsroom/press-releases/2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:00<00:00,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction blocked for url:  https://scet.berkeley.edu/the-next-next-big-thing-agentic-ais-opportunities-and-risks/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Agentic AI frameworks for enterprise scale: A 2025 guide\\n[**IMPORTANT**: We changed our binary download resolvers. Update your config file now.](https://account.akka.io/token)\\n\\n[Akka Logo\\n![akka_logo](https://akka.io/hubfs/AKKA-2024/Images/akka_logo.svg)](https://akka.io/)\\n\\n* Product\\n* Developers\\n* [Stories](https://akka.io/customer-stories)\\n* [Blog](https://akka.io/blog)\\n* [Pricing](https://akka.io/pricing)\\n* Company\\n  + [About](https://akka.io/about-us)\\n  + [Customer Portal](https://portal.akka.io)\\n  + [Trust Center](https://trust.akka.io/)\\n  + [Professional Services](https://akka.io/professional-services)\\n  + [Partners](https://akka.io/partners)\\n  + [Support](https://support.akka.io)\\n\\n* [Contact Us](https://akka.io/contact-us)\\n* [Sign In](https://console.akka.io/login)\\n* [GET STARTED](https://akka.io/get-started)\\n\\n###### Overview\\n\\n[Akka Orchestration  Guide, moderate, and control long-running systems](https://akka.io/akka-orchestration)\\n\\n[Akka Agents  Create agents, MCP tools, and HTTP/gRPC APIs](https://akka.io/akka-agents)\\n\\n[Akka Memory  Durable, in-memory and sharded data](https://akka.io/akka-memory)\\n\\n[Akka Streaming  High performance stream processing](https://akka.io/akka-streaming)\\n\\n[Akka Automated Operations  Fully managed in your VPC or our severless environment](https://akka.io/automated-operations)\\n\\n[How Akka works  Unified data & logic + event-driven fabric](https://akka.io/how-akka-works)\\n\\n###### Stories\\n\\n* [![swiggy-logo-white](https://akka.io/hubfs/website/customer-stories/logos/swiggy-logo-white.png)\\n  2x latency improvement in Swiggy ML and AI platfor..](https://akka.io/blog/2x-latency-improvement-in-swiggy-ml-and-ai-platform)\\n* [![tubi-logo](https://akka.io/hubfs/website/logos/customer-logos/tubi-logo.svg)\\n  Hyper-personalized user experiences drive increase..](https://akka.io/customer-stories/personalized-user-experiences-drive-increased-advertising-revenue-at-tubi)\\n* [![llaama_logo_gray](https://akka.io/hubfs/website/logos/customer-logos/llaama_logo_gray.png)\\n  Llaama helps biopharma companies create AI-driven ..](https://akka.io/customer-stories/llaama-helps-biopharma-companies-create-ai-driven-treatments-with-akka)\\n* [![leap-rail-logo-white](https://akka.io/hubfs/website/customer-stories/logos/leap-rail-logo-white.svg)\\n  Innovative healthcare AI startup Leap Rail builds ..](https://akka.io/customer-stories/healthcare-ai-startup-leap-rail-akka)\\n* [![mrcall-white](https://akka.io/hubfs/website/customer-stories/logos/mrcall-white.svg)\\n  AI-powered call center MrCall responds to 1000s of..](https://akka.io/customer-stories/ai-powered-call-center-mrcall-uses-akka-for-simultaneous-voip-requests)\\n\\n[![agent-icon](https://akka.io/hs-fs/hubfs/website/static/ui/agent-icon.png?width=40&height=44&name=agent-icon.png)\\n\\n**What is agentic AI?**\\nAI is a game changer, but it’s not enough.](https://akka.io/what-is-agentic-ai)\\n\\n###### Resources\\n\\n* [Docs](https://doc.akka.io)\\n* [AI Samples](https://doc.akka.io/getting-started/samples.html)\\n* [Demos](https://akka.io/blog?tag=demo)\\n* [Release Notes](https://doc.akka.io/reference/release-notes.html)\\n* [Support](https://support.akka.io)\\n* [Discord](https://discord.com/invite/QZc652rgtf)\\n\\n###### Architecture\\n\\n* [Agentic AI](https://akka.io/what-is-agentic-ai)\\n* [Free Training](https://akkademy.akka.io/learn)\\n* [Reactive Principles](https://www.reactiveprinciples.org/)\\n* [Reactive Manifesto](https://www.reactivemanifesto.org/)\\n\\n###### Latest Blogs\\n\\n* [Trustworthy AI with Akka](https://akka.io/blog/trustworthy-ai-with-akka)\\n* [Agentic AI: Why Experience Matters More Than Hype](https://akka.io/blog/agentic-ai-why-experience-matters-more-than-hype)\\n* [News: Akka and Deloitte Canada Collaborate to Deliver Agentic AI at Scale](https://akka.io/blog/news-akka-and-deloitte)\\n\\n###### Benchmarks\\n\\n* [1.4M TPS](/akka-performance-benchmark/demo-benchmark-post-0-0-1)\\n* [9 ms latency](/akka-performance-benchmark/demo-benchmark-post)\\n* [$11.77 / month / 1K TPS](/akka-performance-benchmark/demo-benchmark-post-0-0-1)\\n* [see all](/akka-performance-benchmark)\\n\\n###### SDK\\n\\n* [entities](https://doc.akka.io/java/event-sourced-entities.html)\\n* [views](https://doc.akka.io/java/views.html)\\n* [endpoints](https://doc.akka.io/java/http-endpoints.html)\\n* [streaming](https://doc.akka.io/java/streaming.html)\\n* [timers](https://doc.akka.io/java/timed-actions.html)\\n* [workflows](https://doc.akka.io/java/workflows.html)\\n\\n###### Libraries\\n\\n* [actors](https://doc.akka.io/libraries/akka-core/current/typed/)\\n* [http](https://doc.akka.io/libraries/akka-http/current/)\\n* [streams](https://doc.akka.io/libraries/akka-core/current/stream/)\\n* [cluster](https://doc.akka.io/libraries/akka-core/current/typed/index-cluster.html)\\n* [event sourcing](https://doc.akka.io/libraries/akka-core/current/typed/index-persistence.html)\\n* [grpc](https://doc.akka.io/libraries/akka-grpc/current)\\n* [durable state](https://doc.akka.io/libraries/akka-core/current/typed/index-persistence-durable-state.html)\\n* [projections](https://doc.akka.io/libraries/akka-projection/current/)\\n* [persistence](https://doc.akka.io/libraries/akka-core/current/typed/index-persistence.html)\\n* [edge](https://doc.akka.io/libraries/akka-edge/current/index.html)\\n* [integrations](https://doc.akka.io/libraries/alpakka/current/)\\n* [observability](https://doc.akka.io/libraries/akka-insights/current/)\\n\\n[###### Try Akka for free\\n\\nDeploy and scale a multi-region app\\nNo credit card required](https://console.akka.io/register)\\n[###### Develop your own Akka app\\n\\nAkka account not required\\nFree and open SDK for offline dev](https://doc.akka.io/java/author-your-first-service.html)\\n[###### Request demo\\n\\nPersonalized demo\\nAkka app design consultation](https://akka.io/request-a-demo)\\n\\n# Agentic AI frameworks for enterprise scale: A 2025 guide\\n\\n18 minute read\\n\\nAugust 7, 2025\\n\\nAgentic AI systems are transforming the way enterprises approach business. Agentic AI systems are being used to improve incident response, improve productivity, and provide efficient customer support. [These applications, and many others](https://akka.io/blog/agentic-ai-use-cases), are prompting organizations to begin planning and building agentic systems. In January 2025, [Gartner](https://www.gartner.com/en/newsroom/press-releases/2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027) found that 61% of organizations had begun their foray into agentic AI development. They predict that 33% of enterprise software applications will have agentic AI by 2028 (up from 0% in 2024).\\n\\n**Placing a dose of reality in their forecast,** the same study found that 40% of agentic AI deployments will be canceled by 2027 due to rising costs, unclear value, or poor risk controls.\\n\\nTo help your organization select the correct [AI agent development framework](https://content.akka.io/gartner-hype-cycle-for-cloud-platform-services-2025), this article provides a structured guide of essential features to evaluate against your organization's requirements. We'll then compare five of the top agentic AI frameworks against these architectural features. By comparing your team's requirements with the features of these top tools, you will empower your framework by knowing which features will best benefit your organization's agentic needs.\\n\\n## **Why do frameworks matter for agentic AI systems?**\\n\\nWith all the promise of agentic AI, but also clear warnings about cost and ROI, how should organizations begin their foray into agentic AI? One clear way to speed a team's development in agentic AI is to utilize a framework.\\n\\nMembers of the data science and engineering teams may have some experience with creating agentic models, prompts, and agents. They may also have security, observability, LLM memory, and orchestration skills.\\n\\n**But does the team have a deep understanding of every facet of agentic AI?** Using a framework allows the team to leverage experts in all of these fields while building and deploying agentic systems.\\n\\nThere are now dozens of frameworks and tools that can be leveraged to build agentic AI systems, each with strong features to bring agents to life. Choosing the correct framework for your organization is a critical fork in the agentic AI development process. If a framework is chosen, but is unable to support or integrate with key parts of the existing enterprise and scale in/out on demand, **your project may end up in Gartner's 40% of canceled or abandoned projects.**\\n\\nClearly, picking the correct framework for your organization is a strategic decision with significant technical and business implications. Building with frameworks offers many advantages. Frameworks facilitate faster development, help teams avoid common pitfalls, and the organized design can lead to easier code maintenance. Frameworks also allow developers to focus on the logic and internal tools of their agents, not spending time reinventing code that others have perfected.\\n\\n## **Framework fundamentals: What differentiates agentic AI frameworks?**\\n\\n**So, what makes a great agentic AI framework?**\\n\\nBefore you can compare different frameworks, you need to know the core capabilities of agentic AI systems. Once you understand the components of agentic AI systems, you can compare your organization's requirements and how important each component will be for your agentic AIs.\\n\\nThe core capabilities of agentic AI systems described in this guide are: memory, reasoning, and orchestration. Additionally, we’ve added sections on issues central to any organization deploying infrastructure: security, error handling, infrastructure, and cost.\\n\\n**With that, let’s jump into the fundamentals of Agentic AI architectures!**\\n\\n### Memory\\n\\nWhen evaluating the memory of an agentic framework, look for support for both short-term and long-term memory. **Short-term memory** maintains context across a single task, much like an LLM remembers your conversation and customizes each response based on previous questions and responses. **Long-term memory** is when the agentic AI is able to retrieve information across many conversations over a long period of time.\\n\\nFor a customer service agent, this might be remembering a previous conversation, and discussing the ticket from that conversation. Or a knowledge retrieval bot may recall that a user prefers data in a chart versus raw data in a CSV file, and presents the data in a chart without the user asking for it.\\n\\nSome frameworks, like [Akka](/akka-memory), provide native memory modules, but most require users to integrate external systems. These can include vector databases for semantic search, or other forms like Redis, [Postgres](https://www.postgresql.org/), or in-memory caches depending on the use case.\\n\\n### Reasoning\\n\\n**Reasoning** is the cognitive process agents use to break down tasks, evaluate options, and decide on actions, often iterative or hierarchical in execution. One way to achieve this is through the use of reasoning algorithms. While goals are typically defined externally, reasoning algorithms help plan, adapt, and select actions to achieve those goals.\\n\\nCommon reasoning approaches include symbolic logic (e.g., rule-based inference), LLM-driven methods like chain-of-thought (CoT), and planning algorithms such as tree search or task decomposition.\\n\\nReasoning can be strictly programmed as steps, or can involve an algorithm like chain-of-thought where one or more LLMs have a “conversation” on how to address the problem, and evaluate the tasks created towards the solution. Each has its own distinct advantages and disadvantages.\\n\\n**The TL;DR is that the more elaborate reasoning strategies tend to improve success on complex tasks, but increase token usage and latency.**\\n\\nLLM-based reasoning is bounded by the model’s capabilities, but can be extended with tools, memory, or symbolic structures. For simple tasks, smaller, cheaper LLMs can be used, but for long reasoning tasks, the bigger, more expensive LLMs tend to perform better. The tradeoff here is often cost — reasoning can use thousands of tokens for each task.\\n\\n**So, when looking at your agentic AI framework:** What LLMs are supported? Is there a good selection, or are there just one or two options? Which reasoning algorithms are available?\\n\\n### Orchestration and workflows\\n\\nSo we have agents, and the agents are able to reach into both short and long-term memory. But what enables agents to collaborate, delegate, and achieve end-to-end task completion across memory, tools, and reasoning modules? The answer lies in orchestration and workflow control.\\n\\n[Orchestration](https://akka.io/blog/ai-orchestration-tools) coordinates the interactions between agents, tools, memory, and tasks, often using workflows that define control flow, sequencing, and error handling. There are many strong opinions on how to build the best workflows, and this will be apparent when comparing the frameworks. So, let’s walk through some of the basics.\\n\\n**Is the workflow engine centralized or decentralized?**\\n\\n**A centralized orchestration tool** is likely to be similar to workflow tools like [Temporal](/blog/temporal-alternatives) or Airflow, where each step is deterministic and defined in the workflow. The orchestration tool can monitor and log each step of every task execution, leading to better logging, easier debugging, and state management.\\n\\n**A decentralized workflow** allows agents to reason, plan, and invoke each other independently, often using local decision-making, message passing, or emergent collaboration. In addition, decentralized workflows remove the common problem with centralized ones, which is a single point of failure.\\n\\nIn reality, many agentic systems have a combination of a centralized orchestration engine, where sections of each workflow or task are completed in a decentralized manner.\\n\\n**Is your orchestration stateless or stateful?**\\n\\n[Stateful orchestration](https://docs.oracle.com/en/applications/jd-edwards/cross-product/9.2/eotos/understanding-a-stateful-orchestration.html) maintains intermediate state across steps or invocations, and the agent can pick up where it left off. Stateless orchestration treats each invocation as independent, often relying on external memory or context injection to maintain task coherence.\\n\\nDepending on the types of agentic AIs planned, some organizations may be happy with fully orchestrated agents. Other organizations may wish to lean-in on agent-led decentralized systems.\\n\\n### Architecture types\\n\\nAgentic workflows are generally composed of many agents that connect together to complete a task.\\n\\n* **Single-agent systems**: Focused problem-solving using one agent.\\n* **Multi-agent systems**: Multiple specialized agents collaborate to solve tasks.\\n* **Vertical architectures**: One agent leads the task and delegates tasks to additional agents. These agents return the results to the lead agent to continue the overall task.\\n* **Horizontal architectures**: Multiple agents work together collaboratively, but all as equals.\\n* **Hybrid approaches**: Combinations of the above systems.\\n\\n### Security\\n\\nSecurity is not exclusive to agentic AI systems, but, like all tools installed in the enterprise, agentic frameworks should be examined closely to ensure they meet security requirements.\\n\\nAgents will have access to proprietary information. How does the framework handle data governance? Is it easy to add filters to agent inputs and outputs to protect proprietary data? What guardrails are included?\\n\\nDoes your organization have compliance requirements? Some, but not all of the frameworks, meet the compliance requirements for HIPAA, SOC2, DORA, etc.\\n\\n### Error handling\\n\\nWhat happens when there is a problem? Agentic AIs are notorious for being hard to debug. How do the frameworks make debugging and monitoring agents easier?\\n\\nCan chats be replayed? Replaying chats can be an excellent way to detect incorrect answers and hallucinations. Can agentic flows add human-in-the-loop steps for checks and accuracy?\\n\\n### Cost management\\n\\nReasoning algorithms can use thousands of tokens at each step. Cost control is often a central reason that agentic AIs are cancelled. What tools are provided to track and limit token usage?\\n\\n### Infrastructure\\n\\nCan agents and all architecture be run in multiple regions across multiple providers around the world? And, how efficient are infrastructure resources managed by the runtime?\\n\\n### Ease of development\\n\\nHow easy is it to create an agent? Does the framework support rapid prototyping? Or is the development of agents a slower task?\\n\\nIs the framework production-ready? Can it easily scale with growth?\\n\\n## The top agentic frameworks: How they stack up?\\n\\nNow that we have laid out the fundamentals of what AI frameworks can support, let’s introduce five of the top agentic AI frameworks, and see how they stack up across the categories we have defined. In this review, we’ll examine Akka, LangChain (LangGraph), CrewAI, Microsoft AutoGen, and OpenAI Agent SDK.\\n\\n| Feature | Akka | LangChain (LangGraph) | CrewAI | Microsoft AutoGen | OpenAI Swarm |\\n| --- | --- | --- | --- | --- | --- |\\n| Memory | Built-in short & long-term | Built-in short & long-term | Short & long-term support | External database required | Short-term built-in, SQLite for long-term |\\n| LLM support | Anthropic, Gemini, HuggingFace, OpenAI | LLM agnostic | Many LLMs supported | OpenAI & Anthropic | OpenAI models (experimental) |\\n| Reasoning | Chain-of-thought & dynamic | Chain-of-thought & ReAct | Multiple reasoning types | Custom chain-of-thought & ReAct | OpenAI models (experimental) |\\n| Orchestration | Stateful workflow engine | Function/graph driven | Stateless event-driven | Simple task orchestration | LLM & code-based |\\n| Architecture types | Single / multi-agent, vertical / horizontal | Multi-agent, parallel, human-in-loop | Vertical focus, limited horizontal | Horizontal & vertical multi-agent | Multi-agent supported |\\n| Security | Compliance certified | No certifications | Optional Portkey integration | Not built-in | Basic guardrails |\\n| Error handling | Session replay, human-in-loop, monitoring | Strong guardrails, replay | Task-specific replay | No audit/replay | Tracing & debugging |\\n| Cost management | Dashboard with forecasting | LangSmith token tracking | Native + optional Portkey | Not built-in | Not available |\\n| Infrastructure | Multi-region replication | Single region, self-hostable | Self-hosted or enterprise | External infra required | OpenAI hosted only |\\n| Development | Streamlined SDK & DevEx | Complex setup, production-ready | Limited orchestration | Fast prototyping | Full SDK, early stage |\\n| Production ready | Enterprise-grade | Fully ready | Limited features | External infra needed | Early stage |\\n\\n### Akka\\n\\n![Akka enterprise agentic AI platform](https://akka.io/hubfs/website/blog/images/akka-enterprise-agentic-ai-platform-13.webp)\\n\\n[Akka](https://akka.io/) is an enterprise-grade agentic AI platform that provides a comprehensive, integrated solution for building production-ready agentic systems. Built on 15 years of experience powering distributed systems, Akka offers four core components that work seamlessly together: Orchestration, Agents, Memory, and Streaming.\\n\\nThe platform is designed for enterprise-scale performance, providing all necessary components in a single SDK rather than requiring teams to integrate multiple disparate tools.\\n\\n* **Memory**: [Akka Memory](https://akka.io/akka-memory) provides both short term and long term memory. The long term memory persists semantic knowledge, skills, and retrieved data across users, sessions, agents, and systems.\\n* [**LLMs supported**:](https://doc.akka.io/java/agents.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579#model) Anthropic, Gemini, HuggingFace, OpenAI.\\n* **Reasoning:** Chain-of-thought and ReAct dynamic reasoning are fully supported\\n* **Orchestration and workflows:** A workflow engine is a core part of the Akka SDK, and it is stateful, so no information is lost should a workflow stop or restart. [Dynamic Orchestration](https://doc.akka.io/getting-started/planner-agent/dynamic-team.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579) is also supported, where a simple framework is wrapped around agents that control most of the steps.\\n* **Architecture types**: Single and multiple agent workflows are supported. Vertical and horizontal architectures are easily created.\\n* **Security**: Fully compliant with many [compliance standards](https://akka.io/pricing).\\n* **Error handling:** Akka supports [session replay](https://doc.akka.io/getting-started/ask-akka-agent/endpoints.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579#_add_a_session_history_view), [human-in-the-loop](https://doc.akka.io/java/agents.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579#_human_in_the_loop), and has [logging and monitoring built-in](https://doc.akka.io/operations/observability-and-monitoring/index.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579).\\n* **Cost management:** [Dashboard monitoring](https://doc.akka.io/operations/organizations/billing.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579) of cloud spend, with forecasting.\\n* **Infrastructure**: Akka transparently and continuously replicates application data across all configured [regions](https://doc.akka.io/concepts/multi-region.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579).\\n* **Documentation**: Excellent and complete documentation. Agentic search to quickly find content.\\n* **Ease of development**: [SDKs, composable components](https://akka.io/blog/announcing-akkas-agentic-ai-release), and a streamlined developer experience means that developers can become productive quickly. Akka is the only framework reviewed with a customized agentic AI powering the developer documentation.\\n\\n### LangChain (LangGraph)\\n\\n![LangChain and LangGraph tools illustration](https://akka.io/hubfs/website/blog/images/langchain-langgraph-tools.webp)\\n\\n[Langchain](https://www.langchain.com/) and [Langgraph](https://www.langchain.com/langgraph) are complementary tools used to build Angentic AIs.\\n\\n* **Memory**: Both [short and long term memory](https://langchain-ai.github.io/langgraph/concepts/memory/?h=memory#collection) are supported out of the box.\\n* **LLM usage**:[LangGraph is ambivalent](https://langchain-ai.github.io/langgraph/concepts/faq/?h=llm#does-langgraph-work-with-oss-llms) to what LLMs are used under the hood.\\n* **Reasoning**:Native support for chain-of-thought and [ReAct](https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/?h=react) dynamic reasoning.\\n* **Orchestration and workflows**: [Function or graph](https://langchain-ai.github.io/langgraph/concepts/functional_api/?h=graph+vs#overview) driven architectures.\\n* **Architecture types**:[Supports multiple agents](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/), agents running in parallel, human in the loop.\\n* **Security**:LangChain and LangGraph hold no compliance certifications at this time.\\n* **Error handling**:Strong guardrail support with native libraries. Deterministic system means that replay is possible, and agents can restart if there is an error.\\n* **Cost management**:[LangSmith](https://python.langchain.com/docs/how_to/llm_token_usage_tracking/) offers token tracking.\\n* **Infrastructure**: Single region. Can be [self hosted](https://langchain-ai.github.io/langgraphjs/concepts/deployment_options/).\\n* **Ease of development**:Setting up a development environment can be complex. Fully production ready.\\n\\n### CrewAI\\n\\n![CrewAI memory support features overview](https://akka.io/hubfs/website/blog/images/crewai-memory-support.webp)\\n\\n* **Memory**: Short and long term [memory support](https://docs.crewai.com/en/concepts/memory#how-it-works).\\n* **Reasoning/LLM usage**: CrewAI supports many LLMs ([full list](https://docs.crewai.com/en/concepts/llms#provider-configuration-examples)). Many [reasoning types](https://docs.crewai.com/en/learn/llm-selection-guide#b-model-capability-mapping) are supported.\\n* **Orchestration and workflows**: Stateless, simple orchestration through [event driven graphs](https://docs.crewai.com/en/guides/flows/first-flow#taking-control-of-ai-workflows-with-flows).\\n* **Architecture types**: Vertical agent support, limited horizontal agent support.\\n* **Security**: Audit and observability logs available with [optional integration with Portkey](https://docs.crewai.com/en/observability/portkey#logs).\\n* **Error handling**: Replay is available for specific tasks. Guardrails must be programmed into agents.\\n* **Cost management**: Token management with [optional Portkey integration](https://docs.crewai.com/en/observability/portkey#logs). Token usage tracked [natively](https://docs.crewai.com/en/learn/sequential-process#usage-metrics).\\n* **Infrastructure**: Can be self hosted, or use CrewAI enterprise.\\n* **Ease of development**:Lacks advanced orchestration capabilities.\\n\\n### **Microsoft AutoGen**\\n\\n![Microsoft AutoGen memory support diagram](https://akka.io/hubfs/website/blog/images/microsoft-autogen-memory.webp)\\n\\n* **Memory**: Not supported. Requires [external memory database](https://microsoft.github.io/autogen/stable/reference/python/autogen_core.memory.html) for both short and long term memory.\\n* **Reasoning**: OpenAI and Anthropic [LLMs](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/agents.html#using-tools-and-workbench). Chain-of-thought and ReAct type reasoning can be build with custom agents.\\n* **Orchestration and workflow**s: Simple task [orchestration agent.](https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/mixture-of-agents.html)\\n* **Architecture types**: [Horizontal and vertical multi-agent](https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/intro.html) workflows are supported.\\n* **Security**: Not built in.\\n* **Error Handling**: No Audit or replay logs.\\n* **Cost management**: No token management built in.\\n* **Ease of development:** Fast prototyping. Requires external infra to run in production.\\n\\n### OpenAI Swarm\\n\\n![OpenAI Swarm framework overview](https://akka.io/hubfs/website/blog/images/openai-swarm-framework.webp)\\n\\n[Open AI Agents](https://openai.github.io/openai-agents-python/) is a lightweight framework used to build agentic AIs. Developed by the OpenAI team, it is open source, built on the original OpenAI Swarms.\\n\\n* **Memory**: Short term memory is built in. [Long term memory requires SQLite](https://openai.github.io/openai-agents-python/ref/memory/).\\n* **Reasoning**: Designed for OpenAI models. Experimental\\n* **Orchestration** **and workflows**: [Orchestration](https://openai.github.io/openai-agents-python/multi_agent/) by LLMs and via code.\\n* **Architecture** **types (single/multi agent)**: [Multi agent is supported](https://openai.github.io/openai-agents-python/multi_agent/).\\n* **Security**: [Guardrails](https://openai.github.io/openai-agents-python/guardrails/) are designed to monitor inputs and outputs to stay inside limits.\\n* **Error Handling**: [Tracing and debugging](https://openai.github.io/openai-agents-python/tracing/) of all workflows built in. Visualization plugin gives a visual map of the orchestration path.\\n* **Cost management**: No token management available.\\n* **Infrastructure**: Hosted by OpenAI. Not advertised multi region support.\\n* **Ease of development**: Fully featured SDK, but still early.\\n\\n## **Framework selection strategy: Key considerations checklist**\\n\\n**With this wealth of data on top agentic AI frameworks, what are some tricks to finalize a selection?**\\n\\nStart with matching the enterprise’s key goals (reasoning, scalability, agent coordination) with the features offered by the frameworks described.\\n\\n* Is your organization looking for structured centralized agent control, or more autonomy and flexibility? (Or are you looking for a mixture of both?)\\n* Is community support, and community driven extensions of interest, or is the goal all-in-one first party integrations with your existing infrastructure?\\n* How important is built in cost-control? Agentic AIs (especially reasoning AIs) can use thousands of tokens for each task.\\n\\n### Test frameworks with a proof of concept\\n\\nIf your selection process has narrowed the choices down to a few options, it may make sense to build a proof of concept/pilot project with the finalists.\\n\\nPick a project with limited scope, but one that also has a high impact. This is not the time to try all the bells and whistles, but to look at the most important aspects of the frameworks that will be leveraged by the majority of the planned agents.\\n\\n**Before building, create a checklist that defines success criteria.**\\n\\n* What integrations are planned? RAG tooling? APIs? Will you need a standalone memory store, observability or other tools?\\n* How easy is setting up orchestration or building the workflows?\\n* Do the agents interface and connect well with your existing infrastructure and tooling?\\n* How easy is it to test and benchmark the Agents?\\n* Does observability and logging mesh well with existing systems?\\n* Is retracing conversations and tasks easy?\\n* How fast are the agents? Is the latency acceptable for the intended use cases?\\n* Is token usage within an acceptable range? Are there tools to cut off token usage?\\n* Is changing LLMs a simple or arduous task?\\n* Are the agents created production ready? Or will additional work be needed to scale?\\n\\nThis can also be an opportunity to gauge the team’s readiness and preparedness to build agentic AIs. How well do they work with the tools at hand? Was the learning curve easier for one tool over another?\\n\\n## Building production-ready agentic AI with Akka\\n\\nBuilding agentic AI agents is challenging, with many new infrastructural and coding paradigms. Using an agentic AI framework is a way to jump start development, while also keeping the team on track and avoiding common pitfalls.\\n\\nIn this guide, we have walked through many of the critical features in agentic AI frameworks. Every organization has different needs and requirements for agentic AI agents, but it is likely that this guide will help you narrow your search from many frameworks to one or two.\\n\\nWhen examining the way agentic AIs frameworks contribute core architectural features and capabilities, Akka’s feature set includes all of the critical tooling required to build modern agentic AI systems.\\n\\nWith built in orchestration, short and long term memory, wide LLM support, and easy agent creation, [Akka](https://akka.io/) is built in with all of the agentic tools required to build reasoning agents. Akka supports vertical agents, where one agent guides others, as well as horizontal, where all the agents work together to solve tasks.\\n\\nAkka's session replay, human-in-the-loop, and full observability, means that debugging and testing agents is a straightforward process. Finally, Akka’s agentic framework is compliant with several compliance frameworks, and supports multi-region deployment — allowing for fast international use of agents.\\n\\nPerhaps most importantly for teams new to developing agentic AIs, [Akka’s documentation](https://doc.akka.io/?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579) is complete and easy to parse. Interestingly, of the agentic AIs reviewed, Akka’s docs is the only one with an agentic AI that provides answers and links to help developers quickly discover the solution to any question they might have.\\n\\nWhile all of the frameworks in this guide are very good, [Akka](https://akka.io/) stands out, and is a great option for building your agentic AI agents. [Schedule a demo today to get started!](https://akka.io/contact-us)\\n\\nPosted By\\n\\n![Team Akka](https://akka.io/hubfs/branding/akka/akka-on-square.png)\\n[Team Akka](https://akka.io/blog/author/akka)\\n\\n[BlogPost 195142906672 News: Akka and Deloitte Canada Collaborate to Deliver Agentic AI at Scale, BlogPost 194107227229 Beyond the Hype: How to address AI agent dev framework obstacles, BlogPost 194056058935 Agentic AI frameworks for enterprise scale: A 2025 guide, BlogPost 194055379614 Inngest vs. Temporal: Which one should you choose?, BlogPost 194057112451 The 10 best Temporal alternatives for enterprise teams, BlogPost 194015533703 Agentic AI architecture 101: An enterprise guide, BlogPost 193600943409 TechEdge AI talks with Tyler about agentic systems, BlogPost 193133281680 Adopting agentic AI systems for financial services applications, BlogPost 192904641421 Creating Certainty in the Age of Agentic AI, BlogPost 192478734216 News: Akka Introduces Agentic AI Platform, BlogPost 189460288108 News: Akka launches new deployment options for agentic AI at scale, BlogPost 189297554022 25 LangChain Alternatives You MUST Consider In 2025, BlogPost 189297958484 21 Agentic AI Use Cases & Examples Shaping the Future of AI, BlogPost 189214992018 What is AI Orchestration? 21+ Tools to Consider in 2025, BlogPost 189304919573 35+ Agentic AI Tools to Watch in 2025, BlogPost 183075549513 Webinar: introducing Akka 3, BlogPost 182846636428 News: Lightbend launches Akka 3 to make it easy to build and run apps that react to change; rebrands company as Akka, BlogPost 182051790759 Akka 3 - FAQ, BlogPost 180270489182 Lightbend and Scalac partner to enable enterprises to leverage the power of Akka, BlogPost 179857675901 Webinar: Akka 24.05 release highlights]\\n\\nPosts by this author\\n\\n* [News: Akka and Deloitte Canada Collaborate to Deliver Agentic AI at Scale](https://akka.io/blog/news-akka-and-deloitte)\\n* [Beyond the Hype: How to address AI agent dev framework obstacles](https://akka.io/blog/beyond-the-hype-how-to-address-ai-agent-dev-framework-obstacles)\\n* [TechEdge AI talks with Tyler about agentic systems](https://akka.io/blog/akka-ceo-on-architecting-agentic-scalable-distributed-systems)\\n* [Adopting agentic AI systems for financial services applications](https://akka.io/blog/adopting-agentic-ai-systems-for-financial-services-applications)\\n\\nShare this article\\n\\n[SEE ALL BLOGS](/blog)\\n\\n## When AI Needs an SLA\\n\\n[Get Started](https://akka.io/get-started)\\n\\n[REQUEST A DEMO](/request-a-demo)\\n\\n###### Akka\\n\\n* [Documentation](https://doc.akka.io/)\\n* [Akka Newsletter](https://akka.io/newsletter)\\n* [Akkademy](https://akkademy.akka.io/)\\n* [Source Code](https://github.com/akka/akka)\\n* [License Key](https://account.akka.io/key)\\n* [Secure Repository Token](https://account.akka.io/token)\\n\\n######\\n\\n* [Agentic AI](https://akka.io/what-is-agentic-ai)\\n* [Support](https://support.akka.io/)\\n* [Discord](https://discord.com/invite/QZc652rgtf)\\n* [Security Announcements](https://doc.akka.io/reference/security-announcements/)\\n* [Trust Center](https://trust.akka.io/?__hstc=247344155.471e0e910b344218c486300987347be8.1713479425822.1731260004446.1731275910872.288&__hssc=247344155.12.1731275910872&__hsfp=3744600849)\\n\\n###### Follow Us\\n\\n©2025 Lightbend, Inc. dba Akka. All rights reserved.\\n\\n[Terms](https://akka.io/legal/terms-of-use)\\n\\n[Privacy Policy](https://akka.io/legal/privacy)\\n\\n[Patents](https://akka.io/legal/patents)\\n\\nCookie Settings\\n\\n![Footer Logo](https://akka.io/hubfs/AKKA-2024/Images/Vector.png)\", '10+ Agentic AI Trends and Examples\\n[![AIMultiple Research](/images/logo-white.svg)![AIMultiple Research](/images/logo-blue.svg)![AIMultiple Research](/images/logo-white.svg)](/)\\n\\nAI\\n\\nAI CodingAI FoundationsAI HardwareAI in IndustriesDocument AutomationGenerative AIGenerative AI ApplicationsLarge Language ModelsMCPRAG\\n\\nAgentic AI\\n\\nAgent Architectures & ToolsAI Agent ApplicationsOpen-Source Agents\\n\\nCybersecurity\\n\\nCybersecurity SoftwareData PrivacyData SecurityIdentity & Access ManagementSecurity Tools & TechniquesThreats & Attacks\\n\\nData\\n\\nData CollectionData Quality & GovernanceDatasetsSurveys & Market ResearchSynthetic DataWeb Data ScrapingWeb Proxies for Data\\n\\nEnterprise Software\\n\\nCloud ComputingCommunication & MessagingCRME-CommerceFile TransferNetwork MonitoringProcess Intelligence & AutomationRobotic Process Automation (RPA)Workload Automation\\n\\nAI\\n\\nAI Coding\\n\\n[AI Code](https://research.aimultiple.com/ai-code/)[AI Code Editor](https://research.aimultiple.com/ai-code-editor/)[AI Code Review Tools](https://research.aimultiple.com/ai-code-review-tools/)[AI Coding Benchmark](https://research.aimultiple.com/ai-coding-benchmark/)[Screenshot to Code](https://research.aimultiple.com/screenshot-to-code/)\\n\\nAI Foundations\\n\\n[AI Bias](https://research.aimultiple.com/ai-bias/)[AI Ethics](https://research.aimultiple.com/ai-ethics/)[AI Governance Tools](https://research.aimultiple.com/ai-governance-tools/)[AI Hallucination](https://research.aimultiple.com/ai-hallucination/)[AI Improvement](https://research.aimultiple.com/ai-improvement/)[AI Reasoning](https://research.aimultiple.com/ai-reasoning/)[Artificial General Intelligence Singularity Timing](https://research.aimultiple.com/artificial-general-intelligence-singularity-timing/)[Enterprise Generative AI](https://research.aimultiple.com/enterprise-generative-ai/)\\n\\nAI Hardware\\n\\n[AI Chip Makers](https://research.aimultiple.com/ai-chip-makers/)[Cloud GPU](https://research.aimultiple.com/cloud-gpu/)[Cloud GPU Providers](https://research.aimultiple.com/cloud-gpu-providers/)[Free Cloud GPU](https://research.aimultiple.com/free-cloud-gpu/)[Serverless GPU](https://research.aimultiple.com/serverless-gpu/)\\n\\nAI in Industries\\n\\n[AI in Fashion](https://research.aimultiple.com/ai-in-fashion/)[AI Use Cases](https://research.aimultiple.com/ai-usecases/)[CRM AI](https://research.aimultiple.com/crm-ai/)[Healthcare AI Use Cases](https://research.aimultiple.com/healthcare-ai-use-cases/)[Legal AI Software](https://research.aimultiple.com/legal-ai-software/)[Logistics AI](https://research.aimultiple.com/logistics-ai/)[Manufacturing AI](https://research.aimultiple.com/manufacturing-ai/)[Supply Chain AI](https://research.aimultiple.com/supply-chain-ai/)\\n\\nDocument Automation\\n\\n[Handwriting Recognition](https://research.aimultiple.com/handwriting-recognition/)[Invoice OCR](https://research.aimultiple.com/invoice-ocr/)[OCR Accuracy](https://research.aimultiple.com/ocr-accuracy/)[Receipt OCR](https://research.aimultiple.com/receipt-ocr/)\\n\\nGenerative AI\\n\\n[Generative AI Copyright](https://research.aimultiple.com/generative-ai-copyright/)[Generative AI Services](https://research.aimultiple.com/generative-ai-services/)\\n\\nGenerative AI Applications\\n\\n[AI Avatar](https://research.aimultiple.com/ai-avatar/)[Generative AI in Email Marketing](https://research.aimultiple.com/generative-ai-for-email-marketing/)[AI Video Maker](https://research.aimultiple.com/ai-video-maker/)[Cloud LLM](https://research.aimultiple.com/cloud-llm/)[Generative AI Applications](https://research.aimultiple.com/generative-ai-applications/)[Generative AI Finance](https://research.aimultiple.com/generative-ai-finance/)[Generative AI in Education](https://research.aimultiple.com/generative-ai-in-education/)[Generative AI in Marketing](https://research.aimultiple.com/generative-ai-in-marketing/)[Generative AI Legal](https://research.aimultiple.com/generative-ai-legal/)[Speech to Text](https://research.aimultiple.com/speech-to-text/)\\n\\nLarge Language Models\\n\\n[AI Gateway](https://research.aimultiple.com/ai-gateway/)[AI Models](https://aimultiple.com/ai-models)[Chatbot vs Chatgpt](https://research.aimultiple.com/chatbot-vs-chatgpt/)[Large Language Models](https://research.aimultiple.com/large-language-models/)[Large Language Models Examples](https://research.aimultiple.com/large-language-models-examples/)[Large Language Model Evaluation](https://research.aimultiple.com/large-language-model-evaluation/)[LLM Orchestration](https://research.aimultiple.com/llm-orchestration/)[LLM Pricing](https://research.aimultiple.com/llm-pricing/)\\n\\nMCP\\n\\n[Browser MCP](https://research.aimultiple.com/browser-mcp/)[Figma to Code](https://research.aimultiple.com/figma-to-code/)[MCP Gateway](https://research.aimultiple.com/mcp-gateway/)[MCP Servers](https://aimultiple.com/mcp-servers)\\n\\nRAG\\n\\n[Agentic RAG](https://research.aimultiple.com/agentic-rag/)[Retrieval Augmented Generation](https://research.aimultiple.com/retrieval-augmented-generation/)\\n\\nAgentic AI\\n\\nCybersecurity\\n\\nData\\n\\nEnterprise Software\\n\\nSubscribe\\n\\nWe follow [ethical norms](https://aimultiple.com/commitments) & [our process](https://aimultiple.com/methodology) for objectivity.\\n\\nThis research is not [funded](https://aimultiple.com/funding) by any sponsors.\\n\\nTABLE OF CONTENTS\\n\\n10+ agentic AI trends and examples\\n\\n1. Towards autonomous, self-healing data pipelines\\n\\n2. Tooling over process\\n\\n3. Vertical AI agents in specialized industries\\n\\n4. Integration of AI agents with the physical world\\n\\n5. Growing shift towards open source models\\n\\n6. Transformative Artificial Intelligence\\n\\n7. AI agent building frameworks\\n\\n8. Combining synthetic and real-world data\\n\\n9. Agentic AI reshaping team roles\\n\\n10. The human element in agentic AI\\n\\n11. Emergence of new AI agent pricing models\\n\\nAgentic AI explained\\n\\nAgentic AI vs generative AI\\n\\nThe impact of AI agents on business growth\\n\\n[10+ agentic AI trends and examples](#10-agentic-ai-trends-and-examples)[1. Towards autonomous, self-healing data pipelines](#1-towards-autonomous-self-healing-data-pipelines)[2. Tooling over process](#2-tooling-over-process)[3. Vertical AI agents in specialized industries](#3-vertical-ai-agents-in-specialized-industries)[4. Integration of AI agents with the physical world](#4-integration-of-ai-agents-with-the-physical-world)[5. Growing shift towards open source models](#5-growing-shift-towards-open-source-models)[6. Transformative Artificial Intelligence](#6-transformative-artificial-intelligence)[7. AI agent building frameworks](#7-ai-agent-building-frameworks)[8. Combining synthetic and real-world data](#8-combining-synthetic-and-real-world-data)[9. Agentic AI reshaping team roles](#9-agentic-ai-reshaping-team-roles)[10. The human element in agentic AI](#10-the-human-element-in-agentic-ai)[11. Emergence of new AI agent pricing models](#11-emergence-of-new-ai-agent-pricing-models)[Agentic AI explained](#agentic-ai-explained)[Agentic AI vs generative AI](#agentic-ai-vs-generative-ai)[The impact of AI agents on business growth](#the-impact-of-ai-agents-on-business-growth)\\n\\nTable of contents\\n\\n[10+ agentic AI trends and examples](#10-agentic-ai-trends-and-examples)[1. Towards autonomous, self-healing data pipelines](#1-towards-autonomous-self-healing-data-pipelines)[2. Tooling over process](#2-tooling-over-process)[3. Vertical AI agents in specialized industries](#3-vertical-ai-agents-in-specialized-industries)[4. Integration of AI agents with the physical world](#4-integration-of-ai-agents-with-the-physical-world)[5. Growing shift towards open source models](#5-growing-shift-towards-open-source-models)[6. Transformative Artificial Intelligence](#6-transformative-artificial-intelligence)[7. AI agent building frameworks](#7-ai-agent-building-frameworks)[8. Combining synthetic and real-world data](#8-combining-synthetic-and-real-world-data)[9. Agentic AI reshaping team roles](#9-agentic-ai-reshaping-team-roles)[10. The human element in agentic AI](#10-the-human-element-in-agentic-ai)[11. Emergence of new AI agent pricing models](#11-emergence-of-new-ai-agent-pricing-models)[Agentic AI explained](#agentic-ai-explained)[Agentic AI vs generative AI](#agentic-ai-vs-generative-ai)[The impact of AI agents on business growth](#the-impact-of-ai-agents-on-business-growth)\\n\\n[Agentic AI](/agentic-ai)\\n\\nUpdated on **Aug 1, 2025**\\n\\n# 10+ Agentic AI Trends and Examples\\n\\n![Headshot of Cem Dilmegani](https://research.aimultiple.com/wp-content/uploads/2024/07/headshot-of-Cem-Dilmegani-160x160.png.webp)\\n\\n[Cem Dilmegani](/author/cem-dilmegani/)\\n\\nwith  Mert Palazoğlu\\n\\n![Mail](/images/mail-article.svg)[![Linkedin](/images/linkedin-article.svg)](https://www.linkedin.com/sharing/share-offsite/?url=https://aimultiple.com/agentic-ai-trends/)[![X](/images/x-article.svg)](https://x.com/share?url=https://aimultiple.com/agentic-ai-trends/)\\n\\nSee our [ethical norms](https://aimultiple.com/commitments)\\n\\nxml encoding=\"UTF-8\"\\n\\nThe future of [agentic AI](https://research.aimultiple.com/agentic-ai/) isn’t just about improving tools or streamlining business workflows. It’s about integrating AI deeply and transforming business approaches by restructuring current frameworks.\\n\\nKey takeaways:\\n\\n* Agentic systems evolve to handle complex, **unpredictable real-world operations** instead of relying on structured data.\\n* Agentic AI shifts from being a tool to a **co-worker** in decision-making.\\n* As AI agents become more integrated into business operations, **new [agent pricing](https://research.aimultiple.com/ai-agent-pricing/) models** based on task completion or hourly rates (e.g., AI nurses) are emerging.\\n\\n## 10+ agentic AI trends and examples\\n\\nUpdated at 05-27-2025\\n\\n| # | Agentic AI trend | Example(s) |\\n| --- | --- | --- |\\n| 1 | **[Towards autonomous, self-healing data pipelines](#1-towards-autonomous-self-healing-data-pipelines)** | • Monte Carlo: Data observability.   • PraisonAI: Autonomous MLOps pipelines. |\\n| 2 | **[Tooling over process](#2-tooling-over-process)** | • Automation without deep expertise. |\\n| 3 | **[Vertical AI agents in specialized industries](#3-vertical-ai-agents-in-specialized-industries)** | • Customer service: Automated query handling.   • Healthcare: Medical coding & scheduling.   • Developers: Code suggestions & debugging.   • QA testers: Automated testing. |\\n| 4 | **[Integration of AI agents with the physical world](#4-integration-of-ai-agents-with-the-physical-world)** | • NVIDIA & GE Healthcare: Diagnostic imaging with AI agents. |\\n| 5 | **[Growing shift towards open source models](#5-growing-shift-towards-open-source-models)** | • Open-source models: Anthropic and Mistral |\\n| 6 | **[Transformative Artificial Intelligence](#6-transformative-artificial-intelligence)** | • Waymo: Autonomous cars.   • Amazon Robotics: Warehouse robots.   • DeepMind’s MedPaLM: Healthcare diagnostic agents. |\\n| 7 | **[AI agent building frameworks](#7-ai-agent-building-frameworks)** | • CrewAI: Workflow management.   • Camel: Workflow automation.   • AutoGen: Data & content automation.   • LangChain: NLP automation. |\\n| 8 | **[Combining synthetic and real-world data](#8-combining-synthetic-and-real-world-data)** | • Waymo: Synthetic data simulation to detect rare events.   • NVIDIA: Robotic training with synthetic environments. |\\n| 9 | **[Agentic AI reshaping team roles](#9-agentic-ai-reshaping-team-roles)** | • AI automation: Engineers scale systems, analysts manage workflows. |\\n| 10 | **[The human element in agentic AI](#10-the-human-element-in-agentic-ai)** | • Human-AI collaboration: Teams co-working with AI to boost productivity. |\\n| 11 | **[Emergence of new AI agent pricing models](#11-emergence-of-new-ai-agent-pricing-models)** | • Hippocratic AI: Agentic nurses at $10/hour. |\\n\\n## 1. Towards autonomous, self-healing data pipelines\\n\\nAs organizations scale their AI and analytics initiatives, maintaining **high data quality** across pipelines becomes increasingly complex. Traditional approaches like adding manual checks, patching pipelines reactively, or scaling data engineering teams may become difficult to scale.\\n\\nInstead of relying on human-driven monitoring and repairs, future data pipelines will be embedded with **AI agents with reinforcement learning and modular architectures** that can:\\n\\n* **Monitor pipeline health and identify problems early,** using observability and metadata.\\n* **Diagnose root causes** (e.g., schema drift, missing data, delayed upstream feeds).\\n* **Autonomously repair** issues (e.g., roll back to last good configuration, re-ingest failed batches, or dynamically adjust transformations).\\n\\n**Real-world examples**:\\n\\n* Companies like **Monte Carlo** are developing “data observability” platforms to give AI agents a full view of how the pipeline works.[1](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-1-1431321 \"https://www.montecarlodata.com/blog-monte-carlo-observability-agents\")\\n* **Enhancing CI/CD Pipelines with agentic AI:** Research into **autonomous** [**MLOps**](https://research.aimultiple.com/mlops-/) **pipelines** (e.g., self-healing feature stores) is accelerating.[2](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-2-1431322 \"https://www.marktechpost.com/2025/04/27/building-fully-autonomous-data-analysis-pipelines-with-the-praisonai-agent-framework-a-coding-implementation/\")\\n\\n## 2. Tooling over process\\n\\nThe traditional debate of “process vs. tooling” is becoming less relevant with the rise of agentic AI.\\n\\nWhile strong processes are still important, agentic AI tools, which autonomously plan, decide, and execute multi-step tasks, are starting to **replace** the need for complex process design in some areas.\\n\\n* **Self-directed agents** can automate workflows end-to-end without requiring users to manually manage every step.\\n* **Non-technical users** can now deploy automations (e.g., data pipeline management, cybersecurity threat hunting) without deep expertise.\\n\\nIn effect, agentic tools are shifting the conversation: instead of optimizing the process around human teams, the tools become the new operational model.\\n\\nOver the next years, enterprises may shift away from isolated tools toward full-process, operationalized agentic AI solutions.\\n\\n## 3. Vertical AI agents in specialized industries\\n\\nThere is a shift from general-purpose foundation models (like ChatGPT) to more specialized [AI agents](https://research.aimultiple.com/ai-agent-tools/) (like Cursor AI code editor). This shift towards narrow agents is built for specific roles and offers key advantages to streamline business operations, including:\\n\\n* Higher accuracy in industry-specific tasks.\\n* Improved efficiency through automation of domain-specific workflows.\\n* Deep integration into business systems for tailored solutions.\\n\\n**Examples of vertical AI agents:**\\n\\n* [**AI agents in customer service**](https://research.aimultiple.com/ai-agents-customer-service/)**:** Respond to queries in natural language, interpret context, and generate human-like responses.\\n* [**AI agents in healthcare**](https://research.aimultiple.com/agentic-ai-healthcare/)**:** Automate healthcare processes, execute several business tasks such as medical coding, appointment scheduling, and office administration.\\n* [**AI agents as developers**](https://research.aimultiple.com/agentic-ai/#1-ai-agents-as-developers)**:** Automate code suggestions, debugging, and software testing.\\n* [**AI agents**](https://research.aimultiple.com/ai-agents/#tool-use-benchmark-results) **as computer users:** Automate everyday tasks like reminders and security monitoring.\\n* **AI QA testers:** Automated software testing systems.\\n\\n## 4. Integration of AI agents with the physical world\\n\\n**AI agents** increasingly integrate more deeply with [**Internet of Things (IoT)**](https://research.aimultiple.com/iot-applications/) **devices and the physical world**. Applications span various environments, including smart homes, offices, and cities, where AI agents autonomously control devices.\\n\\n**Real world example:**\\n\\nTech companies like **NVIDIA** and **GE HealthCare** are already working together on **agentic robotic systems** like **X-ray** and **ultrasound** technologies, where AI agents use medical imaging to interact with the physical world.[3](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-3-1431323 \"https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai\")\\n\\n## 5. Growing shift towards open source models\\n\\nFor years, proprietary AI models controlled by a few large tech companies dominated the landscape. But this is quickly changing with open source models like **Anthropic** and **Mistral.**\\n\\n* For **B2B (business-to-business)** companies, **open-source models** are favored due to their lower operational costs. This is especially true for smaller models that are often sufficient for specific, well-defined tasks. Companies can fine-tune AI models in-house, reducing reliance on costly third-party APIs.\\n* For developers, **smaller, open-source models** can be fine-tuned to specific business functions or domains,\\n\\n**Proprietary models response:** OpenAI strives to make its models more accessible. Models like ChatGPT have already cut prices by roughly **50%**. They charge us around $5 per million tokens for inputs and $10 per million tokens for outputs. Onboarding a product used to cost us 50 cents.[4](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-4-1431324 \"https://openai.com/api/pricing/\")\\n\\n## 6. Transformative Artificial Intelligence\\n\\nUnlike narrow AI, which focuses on static tasks, Transformative Artificial Intelligence (TAI) leverages [agentic](https://research.aimultiple.com/agentic-ai/) capabilities to drive **adaptive, high-impact change** at scale.\\n\\nTransformative Artificial Intelligence (TAI) systems can:\\n\\n* **Understand and deconstruct complex goals**, even under uncertainty.\\n* **Use external tools and APIs** to take actions in dynamic environments.\\n* **Adapt strategies over time**, learning from feedback and context.\\n* **Coordinate with humans and other agents** to achieve long-term objectives.\\n\\n**Real-world examples:**\\n\\n* **Autonomous vehicles** (e.g., Waymo, Tesla FSD)\\n* **Warehouse robots** (e.g., Amazon Robotics)\\n* **Healthcare diagnostic agents** (e.g., Google DeepMind’s MedPaLM)\\n\\n## 7. AI agent building frameworks\\n\\nWe have seen the rise of many [AI agent building frameworks](https://research.aimultiple.com/ai-agent-builders/) like **OpenAI Swarm, LangGraph, Microsoft Autogen, CrewAI, Vertex AI,** and **Langflow**. The frameworks offer pre-packaged tools and templates that enable the development of AI agents tailored for various use cases.\\n\\n| AI agent builder | | Specialization |\\n| --- | --- | --- |\\n| 1. | ![CrewAI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/4f91e65b-9c79-4bff-9bbb-46bc87c4b4ee.png) [CrewAI](#crewai) | Workflow management |\\n| 2. | ![Camel logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/56616e31-1ac5-4205-9aba-33215c165941.png) [Camel](#camel) | Workflow management |\\n| 3. | ![AutoGen logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/db438390-0d16-401b-a5b8-bae2461ce536.png) [AutoGen](#autogen) | Data and content automation |\\n| 4. | ![ChatDev logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/f96f59cc-0f42-4c9c-809e-5c3d44afa691.png) [ChatDev](#chatdev) | Collaboration |\\n| 5. | ![LangChain logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/abf2b36f-2c6e-46f9-9cb5-5ef26b1e108a.png) [LangChain](#langchain) | NLP task automation |\\n| Show More (6) |\\n| 6. | ![Copilot Studio logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/b95892ff-8598-4ec5-a605-d28d9c684fd1.png) [Copilot Studio](#copilot-studio) | Workflow management |\\n| 7. | ![Vertex AI Builder logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/e6ff0732-89b8-40c5-bc68-3891db0fb4c3.png) [Vertex AI Builder](#vertex-ai-builder) | Workflow management |\\n| 8. | ![Beam AI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/8a617d69-4aee-412d-9500-1b29b751d6d5.png) [Beam AI](#beam-ai) | Model training |\\n| 9. | ![Lindy logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/a3c5bbc5-4a05-4646-bb29-038140cfa0f2.png) [Lindy](#lindy) | General-purpose |\\n| 10. | ![Bricklayer AI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/fe7510f9-c5cb-491b-9637-38902b8d1ea0.webp) [Bricklayer AI](#bricklayer-ai) | Incident response |\\n| 11. | ![Vonage AI Studio logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/0a6ad7b4-f6ab-4c85-8a87-0e5ffdd62f14.png) [Vonage AI Studio](#vonage-ai-studio) | NLP task automation |\\n\\n1.\\n\\n![CrewAI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/4f91e65b-9c79-4bff-9bbb-46bc87c4b4ee.png)\\n\\n[CrewAI](#crewai)\\n\\nWorkflow management\\n\\n2.\\n\\n![Camel logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/56616e31-1ac5-4205-9aba-33215c165941.png)\\n\\n[Camel](#camel)\\n\\nWorkflow management\\n\\n3.\\n\\n![AutoGen logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/db438390-0d16-401b-a5b8-bae2461ce536.png)\\n\\n[AutoGen](#autogen)\\n\\nData and content automation\\n\\n4.\\n\\n![ChatDev logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/f96f59cc-0f42-4c9c-809e-5c3d44afa691.png)\\n\\n[ChatDev](#chatdev)\\n\\nCollaboration\\n\\n5.\\n\\n![LangChain logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/abf2b36f-2c6e-46f9-9cb5-5ef26b1e108a.png)\\n\\n[LangChain](#langchain)\\n\\nNLP task automation\\n\\nShow More (6)\\n\\n6.\\n\\n![Copilot Studio logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/b95892ff-8598-4ec5-a605-d28d9c684fd1.png)\\n\\n[Copilot Studio](#copilot-studio)\\n\\nWorkflow management\\n\\n7.\\n\\n![Vertex AI Builder logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/e6ff0732-89b8-40c5-bc68-3891db0fb4c3.png)\\n\\n[Vertex AI Builder](#vertex-ai-builder)\\n\\nWorkflow management\\n\\n8.\\n\\n![Beam AI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/8a617d69-4aee-412d-9500-1b29b751d6d5.png)\\n\\n[Beam AI](#beam-ai)\\n\\nModel training\\n\\n9.\\n\\n![Lindy logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/a3c5bbc5-4a05-4646-bb29-038140cfa0f2.png)\\n\\n[Lindy](#lindy)\\n\\nGeneral-purpose\\n\\n10.\\n\\n![Bricklayer AI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/fe7510f9-c5cb-491b-9637-38902b8d1ea0.webp)\\n\\n[Bricklayer AI](#bricklayer-ai)\\n\\nIncident response\\n\\n11.\\n\\n![Vonage AI Studio logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/0a6ad7b4-f6ab-4c85-8a87-0e5ffdd62f14.png)\\n\\n[Vonage AI Studio](#vonage-ai-studio)\\n\\nNLP task automation\\n\\nAI agent building frameworks enabled users to expand their use cases by allowing:\\n\\n* **LLM integration**: Selecting[LLMs](https://research.aimultiple.com/large-language-models-examples/) like OpenAI, Anthropic, or Mistral to create specialized agents for your needs.\\n* **Knowledge base integration**: Integrate custom documents (json, PDFs, websites) for improved accuracy and relevance.\\n* **Built-in memory management**: Automatically track conversation histories for personalized interactions.\\n* **Custom tool integration**: Allow agents to perform tasks like payments, web searches, and API calls.\\n\\n## 8. Combining synthetic and real-world data\\n\\nCompanies are increasingly combining synthetic and real-world data to train their AI models effectively.\\n\\nWhile real-world data offers valuable insights, it often faces limitations such as scarcity, privacy concerns, and inherent biases. Synthetic data, however, provides a controlled environment where AI can be trained on diverse scenarios.\\n\\n**Real-world examples**:\\n\\n* Companies like **Waymo** use synthetic data to simulate these rare events, which are then integrated with real-world driving data to train their AI models.[5](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-5-1431325 \"https://waymo.com/research/surfelgan-synthesizing-realistic-sensor-data-for-autonomous-driving/\")\\n* **NVIDIA** creates synthetic environments to train robotic agents for physical-world tasks like factory automation and autonomous surgery assistance.[6](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-6-1431326 \"https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai\")\\n\\n## 9. Agentic AI reshaping team roles\\n\\nAgentic AI redefines how responsibilities are distributed between analysts and engineers. Teams are taking on expanded responsibilities. Analysts are being empowered to build and manage pipelines, while engineers increasingly automate core workflows.\\n\\nTwo major forces are driving this shift:\\n\\n* **Advances in AI-enabled pipeline automation:** Agentic systems can autonomously handle multi-step workflows such as data ingestion, validation, and incident detection. As automation advances, engineers can manage larger systems with fewer resources, while analysts independently maintain workflows.\\n* **Increased demand for AI and data products:** As business leaders seek faster and broader access to data, teams are expected to do more with fewer resources. Analysts are taking more technical tasks, while engineers focus on scaling and automating infrastructure.\\n\\n## 10. The human element in agentic AI\\n\\nThe true success of **agentic AI** depends largely on how well humans can **integrate and use these systems**.\\n\\n**Key points:**\\n\\n* **Human-AI collaboration**: The effectiveness of agentic AI will rely on how effectively **teams** can collaborate with AI agents, using them as **co-workers**.\\n* **Cultural shift**: Adopting agentic AI will require a significant shift in **organizational culture**, focusing not just on technology adoption but also on allowing people to work alongside AI to reach new heights of productivity.\\n\\n## 11. Emergence of new AI agent pricing models\\n\\nThe adoption of digital **co-workers** might reshape how businesses value tasks traditionally performed by humans.\\n\\nThis transition is driving the rise of agentic business models that favor salary-based compensation over conventional software licensing structures.\\n\\n**Real world example:**\\n\\nHippocratic AI’s agentic nurses, which are priced at $10 per hour, are lower than the median hourly wage of **~$43** for human registered nurses.[7](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-7-1431327 \"https://www.hippocraticai.com/ai-agent-app-store#:~:text=The%20base%20rate%20is%20typically,is%20entirely%20up%20to%20you.\") [8](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-8-1431328 \"https://www.indeed.com/career/registered-nurse/salaries\")\\n\\n**For more:** [AI agent pricing](https://research.aimultiple.com/ai-agent-pricing/).\\n\\n## Agentic AI explained\\n\\nAgentic AI refers to AI systems capable of acting autonomously, adapting in real-time, and solving complex multi-step problems based on context and objectives.\\n\\nIt combines multiple AI agents, leveraging large language models (LLMs) and reasoning capabilities.\\n\\n**Key features:**\\n\\n* **Autonomous decision-making**: Acts independently with minimal human intervention.\\n* **Real-time adaptation**: Adjusts to changing circumstances and evolving situations.\\n* **Multi-agent collaboration**: Multiple agents work together to solve complex problems.\\n* **Reasoning**: Uses reasoning and natural language understanding to process and respond to challenges.\\n\\n**Read more:** [Levels of agentic systems](https://research.aimultiple.com/ai-agent-tools/#levels-of-agentic-ai-systems).\\n\\n## Agentic AI vs generative AI\\n\\n[**Generative AI**](https://research.aimultiple.com/generative-ai-applications/) generates content (text, images, etc.) based on input data or prompts.. It uses deep learning models that mimic the human brain’s learning and decision-making processes.\\n\\nBy analyzing large datasets, these models identify patterns and generate content in response to natural language requests, relying on technologies like [robotic process automation (RPA)](https://research.aimultiple.com/robotic-process-automation-use-cases/).\\n\\n[**Agentic AI**](https://research.aimultiple.com/agentic-ai/) refers to AI systems that autonomously make decisions and act towards achieving complex goals with minimal supervision. It combines the flexibility of [large language models (LLMs)](https://research.aimultiple.com/large-language-models/) with the precision of traditional programming.\\n\\nUnlike generative AI, which is reactive to input, agentic AI proactively adapts to situations and makes context-based decisions. It’s used in applications like robotics, complex analysis, and virtual assistants.\\n\\nUpdated at 04-30-2025\\n\\n| Feature | Agentic AI | Generative AI |\\n| --- | --- | --- |\\n| Primary function | Goal-oriented action & decision-making | Content generation (text, code, images, etc.) |\\n| Autonomy | High – Operates with minimal human oversight | Variable – May require user prompts or guidance |\\n| Learning | Reinforced Learning – Improves through experience | Data-driven learning – Learns from existing data |\\n| Task complexity | High – Solves complex, multi-step problems | Moderate – Generates content but doesn’t handle complex tasks autonomously |\\n\\n## The impact of AI agents on business growth\\n\\nCapgemini claims that ~80% of surveyed organizations plan to integrate AI agents within 1-3 years for tasks like email generation, coding, and data analysis. [9](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-9-1431329 \"https://www.capgemini.com/us-en/insights/research-library/generative-ai-in-organizations-2024/\")\\n\\nHowever, the true impact will come from orchestrating these agents to complete not only individual tasks but also **entire software development lifecycles**.\\n\\nCompanies could deploy specialized agents for code generation or automated testing, all working together and adjusting in real-time based on human feedback.\\n\\n**More generally,\\xa0 AI agents can simplify the automation of complex use cases in four ways:**\\n\\n* **Adaptability to unpredictable scenarios:** Unlike deterministic rule-based systems that fail when faced with unexpected conditions, AI agents trained on large datasets can respond flexibly to unforeseen situations.\\n* **Use of natural language for workflow automation:** Agentic tools allow users to design and modify workflows using natural language instructions.\\n* **Autonomous integration with existing systems:** Since agentic tools are built on foundation models, AI agents can autonomously interact with software platforms and tools.\\n* **Continuous learning and improvement:** Agentic tools can continually learn from interactions and feedback, improving their performance without needing extensive manual retraining.\\n\\nFurther reading\\n\\n* [Compare 20 LLM Security Tools & Open-Source Frameworks](https://research.aimultiple.com/llm-security-tools/)\\n* [What are the Top 10 LLM Security Risks](https://research.aimultiple.com/llm-security/)\\n* [Open-source AI Agents](https://research.aimultiple.com/open-source-ai-agents/)\\n* [Compare 50+ AI Agent Tools](https://research.aimultiple.com/ai-agent-tools/)\\n\\n### External Links\\n\\n* 1. [Monte Carlo Launches Observability Agents To Accelerate Data + AI Monitoring And Troubleshooting.](https://www.montecarlodata.com/blog-monte-carlo-observability-agents)\\n* 2. [Building Fully Autonomous Data Analysis Pipelines with the PraisonAI Agent Framework: A Coding Implementation - MarkTechPost.](https://www.marktechpost.com/2025/04/27/building-fully-autonomous-data-analysis-pipelines-with-the-praisonai-agent-framework-a-coding-implementation/) *MarkTechPost AI Media Inc*\\n* 3. [NVIDIA and GE HealthCare Collaborate to Advance the Development of Autonomous Diagnostic Imaging With Physical AI | NVIDIA Newsroom.](https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai)\\n* 4. [Pricing | OpenAI.](https://openai.com/api/pricing/)\\n* 5. [SurfelGAN: Synthesizing Realistic Sensor Data for Autonomous Driving.](https://waymo.com/research/surfelgan-synthesizing-realistic-sensor-data-for-autonomous-driving/)\\n* 6. [NVIDIA and GE HealthCare Collaborate to Advance the Development of Autonomous Diagnostic Imaging With Physical AI | NVIDIA Newsroom.](https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai)\\n* 7. [AI Agent App Store — Hippocratic AI.](https://www.hippocraticai.com/ai-agent-app-store#:~:text=The%20base%20rate%20is%20typically,is%20entirely%20up%20to%20you.)\\n* 8. [Security Check - Indeed.com.](https://www.indeed.com/career/registered-nurse/salaries)\\n* 9. [Generative AI in organizations 2024 - Capgemini USA.](https://www.capgemini.com/us-en/insights/research-library/generative-ai-in-organizations-2024/)\\n\\nShare This Article\\n\\n![Mail](/images/mail-article.svg)[![Linkedin](/images/linkedin-article.svg)](https://www.linkedin.com/sharing/share-offsite/?url=https://aimultiple.com/agentic-ai-trends/)[![X](/images/x-article.svg)](https://x.com/share?url=https://aimultiple.com/agentic-ai-trends/)\\n\\n[![Headshot of Cem Dilmegani](https://research.aimultiple.com/wp-content/uploads/2024/07/headshot-of-Cem-Dilmegani-160x160.png.webp)](/author/cem-dilmegani/)\\n\\n[Follow on](https://www.linkedin.com/in/cem-dilmegani/)\\n\\nCem has been the principal analyst at AIMultiple since 2017. AIMultiple informs hundreds of thousands of businesses (as per similarWeb) including 55% of Fortune 500 every month.\\n\\n[Follow on](https://www.linkedin.com/in/cem-dilmegani/)\\n\\nResearched by\\n\\n[![Headshot of Mert Palazoğlu](https://research.aimultiple.com/wp-content/uploads/2024/07/mert-150x150.png.webp)](/author/mert-palazoglu/)\\n\\nMert Palazoglu is an industry analyst at AIMultiple focused on customer service and network security with a few years of experience. He holds a bachelor\\'s degree in management.\\n\\n### Next to Read\\n\\n### [Agentic AI Architecture for Industrial Systems](/industrial-agentic-ai/)\\n\\nSep 124 min read\\n\\n### [Agentic Mesh: The Future of Scalable AI Collaboration](/agentic-mesh/)\\n\\nSep 96 min read\\n\\n### [Optimizing Agentic Coding: How I use Claude Code](/agentic-coding/)\\n\\nAug 237 min read\\n\\n### Comments\\n\\nYour email address will not be published. All fields are required.\\n\\n0 Comments\\n\\nPost Comment\\n\\n## Related research\\n\\n[![](https://research.aimultiple.com/wp-content/uploads/feauture-image.svg)](/industrial-agentic-ai/)\\n\\n### [Agentic AI Architecture for Industrial Systems](/industrial-agentic-ai/)\\n\\nSep 124 min read\\n\\n[![](https://research.aimultiple.com/wp-content/uploads/feauture-image.svg)](/agentic-ai-stack/)\\n\\n### [The 7 Layers of Agentic AI Stack](/agentic-ai-stack/)\\n\\nSep 95 min read\\n\\n![AIMultiple](/images/aimultiple-logo.svg)\\n\\nAIMultiple[About](https://aimultiple.com/about)[Career](https://www.linkedin.com/company/aimultiple/jobs/)[Commitments](https://aimultiple.com/commitments)[Contact](https://aimultiple.com/contact-us)[Culture](https://aimultiple.com/culture)[How we are funded](https://aimultiple.com/funding)[How we test](https://aimultiple.com/how-we-test)[Methodology](https://aimultiple.com/methodology)[Services](https://aimultiple.com/services)\\n\\nFollow us on:\\n\\nAI[Agentic AI Frameworks](https://aimultiple.com/agentic-ai-frameworks)[AI Agents](https://research.aimultiple.com/category/ai-agents/)[AI Coding](https://aimultiple.com/ai-coding)[AI Foundations](https://research.aimultiple.com/category/ai-foundations/)[AI Hardware](https://aimultiple.com/ai-hardware)[AI in Industries](https://research.aimultiple.com/category/ai-in-industries/)[AI Models](https://aimultiple.com/ai-models)[AI Memory](https://research.aimultiple.com/category/ai-memory/)[Computer Vision](https://research.aimultiple.com/category/computer-vision/) [Document Automation](https://aimultiple.com/document-automation)[GenAI Applications](https://research.aimultiple.com/category/genai-applications/)[MCP Servers](https://aimultiple.com/mcp-servers)[Large Language Models](https://aimultiple.com/llm)[Retrieval Augmented Generation](https://aimultiple.com/rag)\\n\\nData[Analytics](https://research.aimultiple.com/category/analytics/)[Data Collection](https://research.aimultiple.com/category/data-collection/)[Data Science](https://research.aimultiple.com/category/data-science/)[Data Quality](https://research.aimultiple.com/category/data-quality/)[Machine Learning Operations](https://research.aimultiple.com/category/mlops/)[Proxy Comparisons](https://research.aimultiple.com/category/proxy-comparisons/)[Proxy Types](https://research.aimultiple.com/category/proxy-types/)[Scraping Tools](https://research.aimultiple.com/category/scraping-tools/)[Survey Reviews](https://research.aimultiple.com/category/survey-reviews/)[Synthetic Data](https://research.aimultiple.com/category/synthetic-data/)[Web Data Scraping](https://research.aimultiple.com/category/web-data-scraping/)[Web Proxies](https://research.aimultiple.com/category/web-proxies/)\\n\\nEnterprise Software[Cloud Computing](https://research.aimultiple.com/category/cloud-computing/)[Communication](https://research.aimultiple.com/category/communication/)[Customer Relationship Management](https://research.aimultiple.com/category/crm/)[E-Commerce](https://research.aimultiple.com/category/e-commerce/)[Extended Reality](https://research.aimultiple.com/category/extended-reality/)[Industry Software](https://research.aimultiple.com/category/industry-software/)[Internet of Things](https://research.aimultiple.com/category/iot/)[Managed File Transfer](https://research.aimultiple.com/category/managed-file-transfer/)[Process Improvement](https://research.aimultiple.com/category/process-improvement/)[Robotic Process Automation](https://research.aimultiple.com/category/rpa/)[Sustainability](https://research.aimultiple.com/category/sustainability/)[Workload Automation](https://research.aimultiple.com/category/workload-automation/)']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in tool_output:\n",
        "    print(doc)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOS3qwf6tKNF",
        "outputId": "14331fef-a7e8-4e15-cbed-048475f013e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agentic AI frameworks for enterprise scale: A 2025 guide\n",
            "[**IMPORTANT**: We changed our binary download resolvers. Update your config file now.](https://account.akka.io/token)\n",
            "\n",
            "[Akka Logo\n",
            "![akka_logo](https://akka.io/hubfs/AKKA-2024/Images/akka_logo.svg)](https://akka.io/)\n",
            "\n",
            "* Product\n",
            "* Developers\n",
            "* [Stories](https://akka.io/customer-stories)\n",
            "* [Blog](https://akka.io/blog)\n",
            "* [Pricing](https://akka.io/pricing)\n",
            "* Company\n",
            "  + [About](https://akka.io/about-us)\n",
            "  + [Customer Portal](https://portal.akka.io)\n",
            "  + [Trust Center](https://trust.akka.io/)\n",
            "  + [Professional Services](https://akka.io/professional-services)\n",
            "  + [Partners](https://akka.io/partners)\n",
            "  + [Support](https://support.akka.io)\n",
            "\n",
            "* [Contact Us](https://akka.io/contact-us)\n",
            "* [Sign In](https://console.akka.io/login)\n",
            "* [GET STARTED](https://akka.io/get-started)\n",
            "\n",
            "###### Overview\n",
            "\n",
            "[Akka Orchestration  Guide, moderate, and control long-running systems](https://akka.io/akka-orchestration)\n",
            "\n",
            "[Akka Agents  Create agents, MCP tools, and HTTP/gRPC APIs](https://akka.io/akka-agents)\n",
            "\n",
            "[Akka Memory  Durable, in-memory and sharded data](https://akka.io/akka-memory)\n",
            "\n",
            "[Akka Streaming  High performance stream processing](https://akka.io/akka-streaming)\n",
            "\n",
            "[Akka Automated Operations  Fully managed in your VPC or our severless environment](https://akka.io/automated-operations)\n",
            "\n",
            "[How Akka works  Unified data & logic + event-driven fabric](https://akka.io/how-akka-works)\n",
            "\n",
            "###### Stories\n",
            "\n",
            "* [![swiggy-logo-white](https://akka.io/hubfs/website/customer-stories/logos/swiggy-logo-white.png)\n",
            "  2x latency improvement in Swiggy ML and AI platfor..](https://akka.io/blog/2x-latency-improvement-in-swiggy-ml-and-ai-platform)\n",
            "* [![tubi-logo](https://akka.io/hubfs/website/logos/customer-logos/tubi-logo.svg)\n",
            "  Hyper-personalized user experiences drive increase..](https://akka.io/customer-stories/personalized-user-experiences-drive-increased-advertising-revenue-at-tubi)\n",
            "* [![llaama_logo_gray](https://akka.io/hubfs/website/logos/customer-logos/llaama_logo_gray.png)\n",
            "  Llaama helps biopharma companies create AI-driven ..](https://akka.io/customer-stories/llaama-helps-biopharma-companies-create-ai-driven-treatments-with-akka)\n",
            "* [![leap-rail-logo-white](https://akka.io/hubfs/website/customer-stories/logos/leap-rail-logo-white.svg)\n",
            "  Innovative healthcare AI startup Leap Rail builds ..](https://akka.io/customer-stories/healthcare-ai-startup-leap-rail-akka)\n",
            "* [![mrcall-white](https://akka.io/hubfs/website/customer-stories/logos/mrcall-white.svg)\n",
            "  AI-powered call center MrCall responds to 1000s of..](https://akka.io/customer-stories/ai-powered-call-center-mrcall-uses-akka-for-simultaneous-voip-requests)\n",
            "\n",
            "[![agent-icon](https://akka.io/hs-fs/hubfs/website/static/ui/agent-icon.png?width=40&height=44&name=agent-icon.png)\n",
            "\n",
            "**What is agentic AI?**\n",
            "AI is a game changer, but it’s not enough.](https://akka.io/what-is-agentic-ai)\n",
            "\n",
            "###### Resources\n",
            "\n",
            "* [Docs](https://doc.akka.io)\n",
            "* [AI Samples](https://doc.akka.io/getting-started/samples.html)\n",
            "* [Demos](https://akka.io/blog?tag=demo)\n",
            "* [Release Notes](https://doc.akka.io/reference/release-notes.html)\n",
            "* [Support](https://support.akka.io)\n",
            "* [Discord](https://discord.com/invite/QZc652rgtf)\n",
            "\n",
            "###### Architecture\n",
            "\n",
            "* [Agentic AI](https://akka.io/what-is-agentic-ai)\n",
            "* [Free Training](https://akkademy.akka.io/learn)\n",
            "* [Reactive Principles](https://www.reactiveprinciples.org/)\n",
            "* [Reactive Manifesto](https://www.reactivemanifesto.org/)\n",
            "\n",
            "###### Latest Blogs\n",
            "\n",
            "* [Trustworthy AI with Akka](https://akka.io/blog/trustworthy-ai-with-akka)\n",
            "* [Agentic AI: Why Experience Matters More Than Hype](https://akka.io/blog/agentic-ai-why-experience-matters-more-than-hype)\n",
            "* [News: Akka and Deloitte Canada Collaborate to Deliver Agentic AI at Scale](https://akka.io/blog/news-akka-and-deloitte)\n",
            "\n",
            "###### Benchmarks\n",
            "\n",
            "* [1.4M TPS](/akka-performance-benchmark/demo-benchmark-post-0-0-1)\n",
            "* [9 ms latency](/akka-performance-benchmark/demo-benchmark-post)\n",
            "* [$11.77 / month / 1K TPS](/akka-performance-benchmark/demo-benchmark-post-0-0-1)\n",
            "* [see all](/akka-performance-benchmark)\n",
            "\n",
            "###### SDK\n",
            "\n",
            "* [entities](https://doc.akka.io/java/event-sourced-entities.html)\n",
            "* [views](https://doc.akka.io/java/views.html)\n",
            "* [endpoints](https://doc.akka.io/java/http-endpoints.html)\n",
            "* [streaming](https://doc.akka.io/java/streaming.html)\n",
            "* [timers](https://doc.akka.io/java/timed-actions.html)\n",
            "* [workflows](https://doc.akka.io/java/workflows.html)\n",
            "\n",
            "###### Libraries\n",
            "\n",
            "* [actors](https://doc.akka.io/libraries/akka-core/current/typed/)\n",
            "* [http](https://doc.akka.io/libraries/akka-http/current/)\n",
            "* [streams](https://doc.akka.io/libraries/akka-core/current/stream/)\n",
            "* [cluster](https://doc.akka.io/libraries/akka-core/current/typed/index-cluster.html)\n",
            "* [event sourcing](https://doc.akka.io/libraries/akka-core/current/typed/index-persistence.html)\n",
            "* [grpc](https://doc.akka.io/libraries/akka-grpc/current)\n",
            "* [durable state](https://doc.akka.io/libraries/akka-core/current/typed/index-persistence-durable-state.html)\n",
            "* [projections](https://doc.akka.io/libraries/akka-projection/current/)\n",
            "* [persistence](https://doc.akka.io/libraries/akka-core/current/typed/index-persistence.html)\n",
            "* [edge](https://doc.akka.io/libraries/akka-edge/current/index.html)\n",
            "* [integrations](https://doc.akka.io/libraries/alpakka/current/)\n",
            "* [observability](https://doc.akka.io/libraries/akka-insights/current/)\n",
            "\n",
            "[###### Try Akka for free\n",
            "\n",
            "Deploy and scale a multi-region app\n",
            "No credit card required](https://console.akka.io/register)\n",
            "[###### Develop your own Akka app\n",
            "\n",
            "Akka account not required\n",
            "Free and open SDK for offline dev](https://doc.akka.io/java/author-your-first-service.html)\n",
            "[###### Request demo\n",
            "\n",
            "Personalized demo\n",
            "Akka app design consultation](https://akka.io/request-a-demo)\n",
            "\n",
            "# Agentic AI frameworks for enterprise scale: A 2025 guide\n",
            "\n",
            "18 minute read\n",
            "\n",
            "August 7, 2025\n",
            "\n",
            "Agentic AI systems are transforming the way enterprises approach business. Agentic AI systems are being used to improve incident response, improve productivity, and provide efficient customer support. [These applications, and many others](https://akka.io/blog/agentic-ai-use-cases), are prompting organizations to begin planning and building agentic systems. In January 2025, [Gartner](https://www.gartner.com/en/newsroom/press-releases/2025-06-25-gartner-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027) found that 61% of organizations had begun their foray into agentic AI development. They predict that 33% of enterprise software applications will have agentic AI by 2028 (up from 0% in 2024).\n",
            "\n",
            "**Placing a dose of reality in their forecast,** the same study found that 40% of agentic AI deployments will be canceled by 2027 due to rising costs, unclear value, or poor risk controls.\n",
            "\n",
            "To help your organization select the correct [AI agent development framework](https://content.akka.io/gartner-hype-cycle-for-cloud-platform-services-2025), this article provides a structured guide of essential features to evaluate against your organization's requirements. We'll then compare five of the top agentic AI frameworks against these architectural features. By comparing your team's requirements with the features of these top tools, you will empower your framework by knowing which features will best benefit your organization's agentic needs.\n",
            "\n",
            "## **Why do frameworks matter for agentic AI systems?**\n",
            "\n",
            "With all the promise of agentic AI, but also clear warnings about cost and ROI, how should organizations begin their foray into agentic AI? One clear way to speed a team's development in agentic AI is to utilize a framework.\n",
            "\n",
            "Members of the data science and engineering teams may have some experience with creating agentic models, prompts, and agents. They may also have security, observability, LLM memory, and orchestration skills.\n",
            "\n",
            "**But does the team have a deep understanding of every facet of agentic AI?** Using a framework allows the team to leverage experts in all of these fields while building and deploying agentic systems.\n",
            "\n",
            "There are now dozens of frameworks and tools that can be leveraged to build agentic AI systems, each with strong features to bring agents to life. Choosing the correct framework for your organization is a critical fork in the agentic AI development process. If a framework is chosen, but is unable to support or integrate with key parts of the existing enterprise and scale in/out on demand, **your project may end up in Gartner's 40% of canceled or abandoned projects.**\n",
            "\n",
            "Clearly, picking the correct framework for your organization is a strategic decision with significant technical and business implications. Building with frameworks offers many advantages. Frameworks facilitate faster development, help teams avoid common pitfalls, and the organized design can lead to easier code maintenance. Frameworks also allow developers to focus on the logic and internal tools of their agents, not spending time reinventing code that others have perfected.\n",
            "\n",
            "## **Framework fundamentals: What differentiates agentic AI frameworks?**\n",
            "\n",
            "**So, what makes a great agentic AI framework?**\n",
            "\n",
            "Before you can compare different frameworks, you need to know the core capabilities of agentic AI systems. Once you understand the components of agentic AI systems, you can compare your organization's requirements and how important each component will be for your agentic AIs.\n",
            "\n",
            "The core capabilities of agentic AI systems described in this guide are: memory, reasoning, and orchestration. Additionally, we’ve added sections on issues central to any organization deploying infrastructure: security, error handling, infrastructure, and cost.\n",
            "\n",
            "**With that, let’s jump into the fundamentals of Agentic AI architectures!**\n",
            "\n",
            "### Memory\n",
            "\n",
            "When evaluating the memory of an agentic framework, look for support for both short-term and long-term memory. **Short-term memory** maintains context across a single task, much like an LLM remembers your conversation and customizes each response based on previous questions and responses. **Long-term memory** is when the agentic AI is able to retrieve information across many conversations over a long period of time.\n",
            "\n",
            "For a customer service agent, this might be remembering a previous conversation, and discussing the ticket from that conversation. Or a knowledge retrieval bot may recall that a user prefers data in a chart versus raw data in a CSV file, and presents the data in a chart without the user asking for it.\n",
            "\n",
            "Some frameworks, like [Akka](/akka-memory), provide native memory modules, but most require users to integrate external systems. These can include vector databases for semantic search, or other forms like Redis, [Postgres](https://www.postgresql.org/), or in-memory caches depending on the use case.\n",
            "\n",
            "### Reasoning\n",
            "\n",
            "**Reasoning** is the cognitive process agents use to break down tasks, evaluate options, and decide on actions, often iterative or hierarchical in execution. One way to achieve this is through the use of reasoning algorithms. While goals are typically defined externally, reasoning algorithms help plan, adapt, and select actions to achieve those goals.\n",
            "\n",
            "Common reasoning approaches include symbolic logic (e.g., rule-based inference), LLM-driven methods like chain-of-thought (CoT), and planning algorithms such as tree search or task decomposition.\n",
            "\n",
            "Reasoning can be strictly programmed as steps, or can involve an algorithm like chain-of-thought where one or more LLMs have a “conversation” on how to address the problem, and evaluate the tasks created towards the solution. Each has its own distinct advantages and disadvantages.\n",
            "\n",
            "**The TL;DR is that the more elaborate reasoning strategies tend to improve success on complex tasks, but increase token usage and latency.**\n",
            "\n",
            "LLM-based reasoning is bounded by the model’s capabilities, but can be extended with tools, memory, or symbolic structures. For simple tasks, smaller, cheaper LLMs can be used, but for long reasoning tasks, the bigger, more expensive LLMs tend to perform better. The tradeoff here is often cost — reasoning can use thousands of tokens for each task.\n",
            "\n",
            "**So, when looking at your agentic AI framework:** What LLMs are supported? Is there a good selection, or are there just one or two options? Which reasoning algorithms are available?\n",
            "\n",
            "### Orchestration and workflows\n",
            "\n",
            "So we have agents, and the agents are able to reach into both short and long-term memory. But what enables agents to collaborate, delegate, and achieve end-to-end task completion across memory, tools, and reasoning modules? The answer lies in orchestration and workflow control.\n",
            "\n",
            "[Orchestration](https://akka.io/blog/ai-orchestration-tools) coordinates the interactions between agents, tools, memory, and tasks, often using workflows that define control flow, sequencing, and error handling. There are many strong opinions on how to build the best workflows, and this will be apparent when comparing the frameworks. So, let’s walk through some of the basics.\n",
            "\n",
            "**Is the workflow engine centralized or decentralized?**\n",
            "\n",
            "**A centralized orchestration tool** is likely to be similar to workflow tools like [Temporal](/blog/temporal-alternatives) or Airflow, where each step is deterministic and defined in the workflow. The orchestration tool can monitor and log each step of every task execution, leading to better logging, easier debugging, and state management.\n",
            "\n",
            "**A decentralized workflow** allows agents to reason, plan, and invoke each other independently, often using local decision-making, message passing, or emergent collaboration. In addition, decentralized workflows remove the common problem with centralized ones, which is a single point of failure.\n",
            "\n",
            "In reality, many agentic systems have a combination of a centralized orchestration engine, where sections of each workflow or task are completed in a decentralized manner.\n",
            "\n",
            "**Is your orchestration stateless or stateful?**\n",
            "\n",
            "[Stateful orchestration](https://docs.oracle.com/en/applications/jd-edwards/cross-product/9.2/eotos/understanding-a-stateful-orchestration.html) maintains intermediate state across steps or invocations, and the agent can pick up where it left off. Stateless orchestration treats each invocation as independent, often relying on external memory or context injection to maintain task coherence.\n",
            "\n",
            "Depending on the types of agentic AIs planned, some organizations may be happy with fully orchestrated agents. Other organizations may wish to lean-in on agent-led decentralized systems.\n",
            "\n",
            "### Architecture types\n",
            "\n",
            "Agentic workflows are generally composed of many agents that connect together to complete a task.\n",
            "\n",
            "* **Single-agent systems**: Focused problem-solving using one agent.\n",
            "* **Multi-agent systems**: Multiple specialized agents collaborate to solve tasks.\n",
            "* **Vertical architectures**: One agent leads the task and delegates tasks to additional agents. These agents return the results to the lead agent to continue the overall task.\n",
            "* **Horizontal architectures**: Multiple agents work together collaboratively, but all as equals.\n",
            "* **Hybrid approaches**: Combinations of the above systems.\n",
            "\n",
            "### Security\n",
            "\n",
            "Security is not exclusive to agentic AI systems, but, like all tools installed in the enterprise, agentic frameworks should be examined closely to ensure they meet security requirements.\n",
            "\n",
            "Agents will have access to proprietary information. How does the framework handle data governance? Is it easy to add filters to agent inputs and outputs to protect proprietary data? What guardrails are included?\n",
            "\n",
            "Does your organization have compliance requirements? Some, but not all of the frameworks, meet the compliance requirements for HIPAA, SOC2, DORA, etc.\n",
            "\n",
            "### Error handling\n",
            "\n",
            "What happens when there is a problem? Agentic AIs are notorious for being hard to debug. How do the frameworks make debugging and monitoring agents easier?\n",
            "\n",
            "Can chats be replayed? Replaying chats can be an excellent way to detect incorrect answers and hallucinations. Can agentic flows add human-in-the-loop steps for checks and accuracy?\n",
            "\n",
            "### Cost management\n",
            "\n",
            "Reasoning algorithms can use thousands of tokens at each step. Cost control is often a central reason that agentic AIs are cancelled. What tools are provided to track and limit token usage?\n",
            "\n",
            "### Infrastructure\n",
            "\n",
            "Can agents and all architecture be run in multiple regions across multiple providers around the world? And, how efficient are infrastructure resources managed by the runtime?\n",
            "\n",
            "### Ease of development\n",
            "\n",
            "How easy is it to create an agent? Does the framework support rapid prototyping? Or is the development of agents a slower task?\n",
            "\n",
            "Is the framework production-ready? Can it easily scale with growth?\n",
            "\n",
            "## The top agentic frameworks: How they stack up?\n",
            "\n",
            "Now that we have laid out the fundamentals of what AI frameworks can support, let’s introduce five of the top agentic AI frameworks, and see how they stack up across the categories we have defined. In this review, we’ll examine Akka, LangChain (LangGraph), CrewAI, Microsoft AutoGen, and OpenAI Agent SDK.\n",
            "\n",
            "| Feature | Akka | LangChain (LangGraph) | CrewAI | Microsoft AutoGen | OpenAI Swarm |\n",
            "| --- | --- | --- | --- | --- | --- |\n",
            "| Memory | Built-in short & long-term | Built-in short & long-term | Short & long-term support | External database required | Short-term built-in, SQLite for long-term |\n",
            "| LLM support | Anthropic, Gemini, HuggingFace, OpenAI | LLM agnostic | Many LLMs supported | OpenAI & Anthropic | OpenAI models (experimental) |\n",
            "| Reasoning | Chain-of-thought & dynamic | Chain-of-thought & ReAct | Multiple reasoning types | Custom chain-of-thought & ReAct | OpenAI models (experimental) |\n",
            "| Orchestration | Stateful workflow engine | Function/graph driven | Stateless event-driven | Simple task orchestration | LLM & code-based |\n",
            "| Architecture types | Single / multi-agent, vertical / horizontal | Multi-agent, parallel, human-in-loop | Vertical focus, limited horizontal | Horizontal & vertical multi-agent | Multi-agent supported |\n",
            "| Security | Compliance certified | No certifications | Optional Portkey integration | Not built-in | Basic guardrails |\n",
            "| Error handling | Session replay, human-in-loop, monitoring | Strong guardrails, replay | Task-specific replay | No audit/replay | Tracing & debugging |\n",
            "| Cost management | Dashboard with forecasting | LangSmith token tracking | Native + optional Portkey | Not built-in | Not available |\n",
            "| Infrastructure | Multi-region replication | Single region, self-hostable | Self-hosted or enterprise | External infra required | OpenAI hosted only |\n",
            "| Development | Streamlined SDK & DevEx | Complex setup, production-ready | Limited orchestration | Fast prototyping | Full SDK, early stage |\n",
            "| Production ready | Enterprise-grade | Fully ready | Limited features | External infra needed | Early stage |\n",
            "\n",
            "### Akka\n",
            "\n",
            "![Akka enterprise agentic AI platform](https://akka.io/hubfs/website/blog/images/akka-enterprise-agentic-ai-platform-13.webp)\n",
            "\n",
            "[Akka](https://akka.io/) is an enterprise-grade agentic AI platform that provides a comprehensive, integrated solution for building production-ready agentic systems. Built on 15 years of experience powering distributed systems, Akka offers four core components that work seamlessly together: Orchestration, Agents, Memory, and Streaming.\n",
            "\n",
            "The platform is designed for enterprise-scale performance, providing all necessary components in a single SDK rather than requiring teams to integrate multiple disparate tools.\n",
            "\n",
            "* **Memory**: [Akka Memory](https://akka.io/akka-memory) provides both short term and long term memory. The long term memory persists semantic knowledge, skills, and retrieved data across users, sessions, agents, and systems.\n",
            "* [**LLMs supported**:](https://doc.akka.io/java/agents.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579#model) Anthropic, Gemini, HuggingFace, OpenAI.\n",
            "* **Reasoning:** Chain-of-thought and ReAct dynamic reasoning are fully supported\n",
            "* **Orchestration and workflows:** A workflow engine is a core part of the Akka SDK, and it is stateful, so no information is lost should a workflow stop or restart. [Dynamic Orchestration](https://doc.akka.io/getting-started/planner-agent/dynamic-team.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579) is also supported, where a simple framework is wrapped around agents that control most of the steps.\n",
            "* **Architecture types**: Single and multiple agent workflows are supported. Vertical and horizontal architectures are easily created.\n",
            "* **Security**: Fully compliant with many [compliance standards](https://akka.io/pricing).\n",
            "* **Error handling:** Akka supports [session replay](https://doc.akka.io/getting-started/ask-akka-agent/endpoints.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579#_add_a_session_history_view), [human-in-the-loop](https://doc.akka.io/java/agents.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579#_human_in_the_loop), and has [logging and monitoring built-in](https://doc.akka.io/operations/observability-and-monitoring/index.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579).\n",
            "* **Cost management:** [Dashboard monitoring](https://doc.akka.io/operations/organizations/billing.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579) of cloud spend, with forecasting.\n",
            "* **Infrastructure**: Akka transparently and continuously replicates application data across all configured [regions](https://doc.akka.io/concepts/multi-region.html?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579).\n",
            "* **Documentation**: Excellent and complete documentation. Agentic search to quickly find content.\n",
            "* **Ease of development**: [SDKs, composable components](https://akka.io/blog/announcing-akkas-agentic-ai-release), and a streamlined developer experience means that developers can become productive quickly. Akka is the only framework reviewed with a customized agentic AI powering the developer documentation.\n",
            "\n",
            "### LangChain (LangGraph)\n",
            "\n",
            "![LangChain and LangGraph tools illustration](https://akka.io/hubfs/website/blog/images/langchain-langgraph-tools.webp)\n",
            "\n",
            "[Langchain](https://www.langchain.com/) and [Langgraph](https://www.langchain.com/langgraph) are complementary tools used to build Angentic AIs.\n",
            "\n",
            "* **Memory**: Both [short and long term memory](https://langchain-ai.github.io/langgraph/concepts/memory/?h=memory#collection) are supported out of the box.\n",
            "* **LLM usage**:[LangGraph is ambivalent](https://langchain-ai.github.io/langgraph/concepts/faq/?h=llm#does-langgraph-work-with-oss-llms) to what LLMs are used under the hood.\n",
            "* **Reasoning**:Native support for chain-of-thought and [ReAct](https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/?h=react) dynamic reasoning.\n",
            "* **Orchestration and workflows**: [Function or graph](https://langchain-ai.github.io/langgraph/concepts/functional_api/?h=graph+vs#overview) driven architectures.\n",
            "* **Architecture types**:[Supports multiple agents](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/), agents running in parallel, human in the loop.\n",
            "* **Security**:LangChain and LangGraph hold no compliance certifications at this time.\n",
            "* **Error handling**:Strong guardrail support with native libraries. Deterministic system means that replay is possible, and agents can restart if there is an error.\n",
            "* **Cost management**:[LangSmith](https://python.langchain.com/docs/how_to/llm_token_usage_tracking/) offers token tracking.\n",
            "* **Infrastructure**: Single region. Can be [self hosted](https://langchain-ai.github.io/langgraphjs/concepts/deployment_options/).\n",
            "* **Ease of development**:Setting up a development environment can be complex. Fully production ready.\n",
            "\n",
            "### CrewAI\n",
            "\n",
            "![CrewAI memory support features overview](https://akka.io/hubfs/website/blog/images/crewai-memory-support.webp)\n",
            "\n",
            "* **Memory**: Short and long term [memory support](https://docs.crewai.com/en/concepts/memory#how-it-works).\n",
            "* **Reasoning/LLM usage**: CrewAI supports many LLMs ([full list](https://docs.crewai.com/en/concepts/llms#provider-configuration-examples)). Many [reasoning types](https://docs.crewai.com/en/learn/llm-selection-guide#b-model-capability-mapping) are supported.\n",
            "* **Orchestration and workflows**: Stateless, simple orchestration through [event driven graphs](https://docs.crewai.com/en/guides/flows/first-flow#taking-control-of-ai-workflows-with-flows).\n",
            "* **Architecture types**: Vertical agent support, limited horizontal agent support.\n",
            "* **Security**: Audit and observability logs available with [optional integration with Portkey](https://docs.crewai.com/en/observability/portkey#logs).\n",
            "* **Error handling**: Replay is available for specific tasks. Guardrails must be programmed into agents.\n",
            "* **Cost management**: Token management with [optional Portkey integration](https://docs.crewai.com/en/observability/portkey#logs). Token usage tracked [natively](https://docs.crewai.com/en/learn/sequential-process#usage-metrics).\n",
            "* **Infrastructure**: Can be self hosted, or use CrewAI enterprise.\n",
            "* **Ease of development**:Lacks advanced orchestration capabilities.\n",
            "\n",
            "### **Microsoft AutoGen**\n",
            "\n",
            "![Microsoft AutoGen memory support diagram](https://akka.io/hubfs/website/blog/images/microsoft-autogen-memory.webp)\n",
            "\n",
            "* **Memory**: Not supported. Requires [external memory database](https://microsoft.github.io/autogen/stable/reference/python/autogen_core.memory.html) for both short and long term memory.\n",
            "* **Reasoning**: OpenAI and Anthropic [LLMs](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/agents.html#using-tools-and-workbench). Chain-of-thought and ReAct type reasoning can be build with custom agents.\n",
            "* **Orchestration and workflow**s: Simple task [orchestration agent.](https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/mixture-of-agents.html)\n",
            "* **Architecture types**: [Horizontal and vertical multi-agent](https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/design-patterns/intro.html) workflows are supported.\n",
            "* **Security**: Not built in.\n",
            "* **Error Handling**: No Audit or replay logs.\n",
            "* **Cost management**: No token management built in.\n",
            "* **Ease of development:** Fast prototyping. Requires external infra to run in production.\n",
            "\n",
            "### OpenAI Swarm\n",
            "\n",
            "![OpenAI Swarm framework overview](https://akka.io/hubfs/website/blog/images/openai-swarm-framework.webp)\n",
            "\n",
            "[Open AI Agents](https://openai.github.io/openai-agents-python/) is a lightweight framework used to build agentic AIs. Developed by the OpenAI team, it is open source, built on the original OpenAI Swarms.\n",
            "\n",
            "* **Memory**: Short term memory is built in. [Long term memory requires SQLite](https://openai.github.io/openai-agents-python/ref/memory/).\n",
            "* **Reasoning**: Designed for OpenAI models. Experimental\n",
            "* **Orchestration** **and workflows**: [Orchestration](https://openai.github.io/openai-agents-python/multi_agent/) by LLMs and via code.\n",
            "* **Architecture** **types (single/multi agent)**: [Multi agent is supported](https://openai.github.io/openai-agents-python/multi_agent/).\n",
            "* **Security**: [Guardrails](https://openai.github.io/openai-agents-python/guardrails/) are designed to monitor inputs and outputs to stay inside limits.\n",
            "* **Error Handling**: [Tracing and debugging](https://openai.github.io/openai-agents-python/tracing/) of all workflows built in. Visualization plugin gives a visual map of the orchestration path.\n",
            "* **Cost management**: No token management available.\n",
            "* **Infrastructure**: Hosted by OpenAI. Not advertised multi region support.\n",
            "* **Ease of development**: Fully featured SDK, but still early.\n",
            "\n",
            "## **Framework selection strategy: Key considerations checklist**\n",
            "\n",
            "**With this wealth of data on top agentic AI frameworks, what are some tricks to finalize a selection?**\n",
            "\n",
            "Start with matching the enterprise’s key goals (reasoning, scalability, agent coordination) with the features offered by the frameworks described.\n",
            "\n",
            "* Is your organization looking for structured centralized agent control, or more autonomy and flexibility? (Or are you looking for a mixture of both?)\n",
            "* Is community support, and community driven extensions of interest, or is the goal all-in-one first party integrations with your existing infrastructure?\n",
            "* How important is built in cost-control? Agentic AIs (especially reasoning AIs) can use thousands of tokens for each task.\n",
            "\n",
            "### Test frameworks with a proof of concept\n",
            "\n",
            "If your selection process has narrowed the choices down to a few options, it may make sense to build a proof of concept/pilot project with the finalists.\n",
            "\n",
            "Pick a project with limited scope, but one that also has a high impact. This is not the time to try all the bells and whistles, but to look at the most important aspects of the frameworks that will be leveraged by the majority of the planned agents.\n",
            "\n",
            "**Before building, create a checklist that defines success criteria.**\n",
            "\n",
            "* What integrations are planned? RAG tooling? APIs? Will you need a standalone memory store, observability or other tools?\n",
            "* How easy is setting up orchestration or building the workflows?\n",
            "* Do the agents interface and connect well with your existing infrastructure and tooling?\n",
            "* How easy is it to test and benchmark the Agents?\n",
            "* Does observability and logging mesh well with existing systems?\n",
            "* Is retracing conversations and tasks easy?\n",
            "* How fast are the agents? Is the latency acceptable for the intended use cases?\n",
            "* Is token usage within an acceptable range? Are there tools to cut off token usage?\n",
            "* Is changing LLMs a simple or arduous task?\n",
            "* Are the agents created production ready? Or will additional work be needed to scale?\n",
            "\n",
            "This can also be an opportunity to gauge the team’s readiness and preparedness to build agentic AIs. How well do they work with the tools at hand? Was the learning curve easier for one tool over another?\n",
            "\n",
            "## Building production-ready agentic AI with Akka\n",
            "\n",
            "Building agentic AI agents is challenging, with many new infrastructural and coding paradigms. Using an agentic AI framework is a way to jump start development, while also keeping the team on track and avoiding common pitfalls.\n",
            "\n",
            "In this guide, we have walked through many of the critical features in agentic AI frameworks. Every organization has different needs and requirements for agentic AI agents, but it is likely that this guide will help you narrow your search from many frameworks to one or two.\n",
            "\n",
            "When examining the way agentic AIs frameworks contribute core architectural features and capabilities, Akka’s feature set includes all of the critical tooling required to build modern agentic AI systems.\n",
            "\n",
            "With built in orchestration, short and long term memory, wide LLM support, and easy agent creation, [Akka](https://akka.io/) is built in with all of the agentic tools required to build reasoning agents. Akka supports vertical agents, where one agent guides others, as well as horizontal, where all the agents work together to solve tasks.\n",
            "\n",
            "Akka's session replay, human-in-the-loop, and full observability, means that debugging and testing agents is a straightforward process. Finally, Akka’s agentic framework is compliant with several compliance frameworks, and supports multi-region deployment — allowing for fast international use of agents.\n",
            "\n",
            "Perhaps most importantly for teams new to developing agentic AIs, [Akka’s documentation](https://doc.akka.io/?__hstc=45788219.7da309ff7ade2a7bb0b02cc2cc3c5853.1754601381311.1754601381311.1754601381311.1&__hssc=45788219.1.1754601381311&__hsfp=3863828579) is complete and easy to parse. Interestingly, of the agentic AIs reviewed, Akka’s docs is the only one with an agentic AI that provides answers and links to help developers quickly discover the solution to any question they might have.\n",
            "\n",
            "While all of the frameworks in this guide are very good, [Akka](https://akka.io/) stands out, and is a great option for building your agentic AI agents. [Schedule a demo today to get started!](https://akka.io/contact-us)\n",
            "\n",
            "Posted By\n",
            "\n",
            "![Team Akka](https://akka.io/hubfs/branding/akka/akka-on-square.png)\n",
            "[Team Akka](https://akka.io/blog/author/akka)\n",
            "\n",
            "[BlogPost 195142906672 News: Akka and Deloitte Canada Collaborate to Deliver Agentic AI at Scale, BlogPost 194107227229 Beyond the Hype: How to address AI agent dev framework obstacles, BlogPost 194056058935 Agentic AI frameworks for enterprise scale: A 2025 guide, BlogPost 194055379614 Inngest vs. Temporal: Which one should you choose?, BlogPost 194057112451 The 10 best Temporal alternatives for enterprise teams, BlogPost 194015533703 Agentic AI architecture 101: An enterprise guide, BlogPost 193600943409 TechEdge AI talks with Tyler about agentic systems, BlogPost 193133281680 Adopting agentic AI systems for financial services applications, BlogPost 192904641421 Creating Certainty in the Age of Agentic AI, BlogPost 192478734216 News: Akka Introduces Agentic AI Platform, BlogPost 189460288108 News: Akka launches new deployment options for agentic AI at scale, BlogPost 189297554022 25 LangChain Alternatives You MUST Consider In 2025, BlogPost 189297958484 21 Agentic AI Use Cases & Examples Shaping the Future of AI, BlogPost 189214992018 What is AI Orchestration? 21+ Tools to Consider in 2025, BlogPost 189304919573 35+ Agentic AI Tools to Watch in 2025, BlogPost 183075549513 Webinar: introducing Akka 3, BlogPost 182846636428 News: Lightbend launches Akka 3 to make it easy to build and run apps that react to change; rebrands company as Akka, BlogPost 182051790759 Akka 3 - FAQ, BlogPost 180270489182 Lightbend and Scalac partner to enable enterprises to leverage the power of Akka, BlogPost 179857675901 Webinar: Akka 24.05 release highlights]\n",
            "\n",
            "Posts by this author\n",
            "\n",
            "* [News: Akka and Deloitte Canada Collaborate to Deliver Agentic AI at Scale](https://akka.io/blog/news-akka-and-deloitte)\n",
            "* [Beyond the Hype: How to address AI agent dev framework obstacles](https://akka.io/blog/beyond-the-hype-how-to-address-ai-agent-dev-framework-obstacles)\n",
            "* [TechEdge AI talks with Tyler about agentic systems](https://akka.io/blog/akka-ceo-on-architecting-agentic-scalable-distributed-systems)\n",
            "* [Adopting agentic AI systems for financial services applications](https://akka.io/blog/adopting-agentic-ai-systems-for-financial-services-applications)\n",
            "\n",
            "Share this article\n",
            "\n",
            "[SEE ALL BLOGS](/blog)\n",
            "\n",
            "## When AI Needs an SLA\n",
            "\n",
            "[Get Started](https://akka.io/get-started)\n",
            "\n",
            "[REQUEST A DEMO](/request-a-demo)\n",
            "\n",
            "###### Akka\n",
            "\n",
            "* [Documentation](https://doc.akka.io/)\n",
            "* [Akka Newsletter](https://akka.io/newsletter)\n",
            "* [Akkademy](https://akkademy.akka.io/)\n",
            "* [Source Code](https://github.com/akka/akka)\n",
            "* [License Key](https://account.akka.io/key)\n",
            "* [Secure Repository Token](https://account.akka.io/token)\n",
            "\n",
            "######\n",
            "\n",
            "* [Agentic AI](https://akka.io/what-is-agentic-ai)\n",
            "* [Support](https://support.akka.io/)\n",
            "* [Discord](https://discord.com/invite/QZc652rgtf)\n",
            "* [Security Announcements](https://doc.akka.io/reference/security-announcements/)\n",
            "* [Trust Center](https://trust.akka.io/?__hstc=247344155.471e0e910b344218c486300987347be8.1713479425822.1731260004446.1731275910872.288&__hssc=247344155.12.1731275910872&__hsfp=3744600849)\n",
            "\n",
            "###### Follow Us\n",
            "\n",
            "©2025 Lightbend, Inc. dba Akka. All rights reserved.\n",
            "\n",
            "[Terms](https://akka.io/legal/terms-of-use)\n",
            "\n",
            "[Privacy Policy](https://akka.io/legal/privacy)\n",
            "\n",
            "[Patents](https://akka.io/legal/patents)\n",
            "\n",
            "Cookie Settings\n",
            "\n",
            "![Footer Logo](https://akka.io/hubfs/AKKA-2024/Images/Vector.png)\n",
            "\n",
            "10+ Agentic AI Trends and Examples\n",
            "[![AIMultiple Research](/images/logo-white.svg)![AIMultiple Research](/images/logo-blue.svg)![AIMultiple Research](/images/logo-white.svg)](/)\n",
            "\n",
            "AI\n",
            "\n",
            "AI CodingAI FoundationsAI HardwareAI in IndustriesDocument AutomationGenerative AIGenerative AI ApplicationsLarge Language ModelsMCPRAG\n",
            "\n",
            "Agentic AI\n",
            "\n",
            "Agent Architectures & ToolsAI Agent ApplicationsOpen-Source Agents\n",
            "\n",
            "Cybersecurity\n",
            "\n",
            "Cybersecurity SoftwareData PrivacyData SecurityIdentity & Access ManagementSecurity Tools & TechniquesThreats & Attacks\n",
            "\n",
            "Data\n",
            "\n",
            "Data CollectionData Quality & GovernanceDatasetsSurveys & Market ResearchSynthetic DataWeb Data ScrapingWeb Proxies for Data\n",
            "\n",
            "Enterprise Software\n",
            "\n",
            "Cloud ComputingCommunication & MessagingCRME-CommerceFile TransferNetwork MonitoringProcess Intelligence & AutomationRobotic Process Automation (RPA)Workload Automation\n",
            "\n",
            "AI\n",
            "\n",
            "AI Coding\n",
            "\n",
            "[AI Code](https://research.aimultiple.com/ai-code/)[AI Code Editor](https://research.aimultiple.com/ai-code-editor/)[AI Code Review Tools](https://research.aimultiple.com/ai-code-review-tools/)[AI Coding Benchmark](https://research.aimultiple.com/ai-coding-benchmark/)[Screenshot to Code](https://research.aimultiple.com/screenshot-to-code/)\n",
            "\n",
            "AI Foundations\n",
            "\n",
            "[AI Bias](https://research.aimultiple.com/ai-bias/)[AI Ethics](https://research.aimultiple.com/ai-ethics/)[AI Governance Tools](https://research.aimultiple.com/ai-governance-tools/)[AI Hallucination](https://research.aimultiple.com/ai-hallucination/)[AI Improvement](https://research.aimultiple.com/ai-improvement/)[AI Reasoning](https://research.aimultiple.com/ai-reasoning/)[Artificial General Intelligence Singularity Timing](https://research.aimultiple.com/artificial-general-intelligence-singularity-timing/)[Enterprise Generative AI](https://research.aimultiple.com/enterprise-generative-ai/)\n",
            "\n",
            "AI Hardware\n",
            "\n",
            "[AI Chip Makers](https://research.aimultiple.com/ai-chip-makers/)[Cloud GPU](https://research.aimultiple.com/cloud-gpu/)[Cloud GPU Providers](https://research.aimultiple.com/cloud-gpu-providers/)[Free Cloud GPU](https://research.aimultiple.com/free-cloud-gpu/)[Serverless GPU](https://research.aimultiple.com/serverless-gpu/)\n",
            "\n",
            "AI in Industries\n",
            "\n",
            "[AI in Fashion](https://research.aimultiple.com/ai-in-fashion/)[AI Use Cases](https://research.aimultiple.com/ai-usecases/)[CRM AI](https://research.aimultiple.com/crm-ai/)[Healthcare AI Use Cases](https://research.aimultiple.com/healthcare-ai-use-cases/)[Legal AI Software](https://research.aimultiple.com/legal-ai-software/)[Logistics AI](https://research.aimultiple.com/logistics-ai/)[Manufacturing AI](https://research.aimultiple.com/manufacturing-ai/)[Supply Chain AI](https://research.aimultiple.com/supply-chain-ai/)\n",
            "\n",
            "Document Automation\n",
            "\n",
            "[Handwriting Recognition](https://research.aimultiple.com/handwriting-recognition/)[Invoice OCR](https://research.aimultiple.com/invoice-ocr/)[OCR Accuracy](https://research.aimultiple.com/ocr-accuracy/)[Receipt OCR](https://research.aimultiple.com/receipt-ocr/)\n",
            "\n",
            "Generative AI\n",
            "\n",
            "[Generative AI Copyright](https://research.aimultiple.com/generative-ai-copyright/)[Generative AI Services](https://research.aimultiple.com/generative-ai-services/)\n",
            "\n",
            "Generative AI Applications\n",
            "\n",
            "[AI Avatar](https://research.aimultiple.com/ai-avatar/)[Generative AI in Email Marketing](https://research.aimultiple.com/generative-ai-for-email-marketing/)[AI Video Maker](https://research.aimultiple.com/ai-video-maker/)[Cloud LLM](https://research.aimultiple.com/cloud-llm/)[Generative AI Applications](https://research.aimultiple.com/generative-ai-applications/)[Generative AI Finance](https://research.aimultiple.com/generative-ai-finance/)[Generative AI in Education](https://research.aimultiple.com/generative-ai-in-education/)[Generative AI in Marketing](https://research.aimultiple.com/generative-ai-in-marketing/)[Generative AI Legal](https://research.aimultiple.com/generative-ai-legal/)[Speech to Text](https://research.aimultiple.com/speech-to-text/)\n",
            "\n",
            "Large Language Models\n",
            "\n",
            "[AI Gateway](https://research.aimultiple.com/ai-gateway/)[AI Models](https://aimultiple.com/ai-models)[Chatbot vs Chatgpt](https://research.aimultiple.com/chatbot-vs-chatgpt/)[Large Language Models](https://research.aimultiple.com/large-language-models/)[Large Language Models Examples](https://research.aimultiple.com/large-language-models-examples/)[Large Language Model Evaluation](https://research.aimultiple.com/large-language-model-evaluation/)[LLM Orchestration](https://research.aimultiple.com/llm-orchestration/)[LLM Pricing](https://research.aimultiple.com/llm-pricing/)\n",
            "\n",
            "MCP\n",
            "\n",
            "[Browser MCP](https://research.aimultiple.com/browser-mcp/)[Figma to Code](https://research.aimultiple.com/figma-to-code/)[MCP Gateway](https://research.aimultiple.com/mcp-gateway/)[MCP Servers](https://aimultiple.com/mcp-servers)\n",
            "\n",
            "RAG\n",
            "\n",
            "[Agentic RAG](https://research.aimultiple.com/agentic-rag/)[Retrieval Augmented Generation](https://research.aimultiple.com/retrieval-augmented-generation/)\n",
            "\n",
            "Agentic AI\n",
            "\n",
            "Cybersecurity\n",
            "\n",
            "Data\n",
            "\n",
            "Enterprise Software\n",
            "\n",
            "Subscribe\n",
            "\n",
            "We follow [ethical norms](https://aimultiple.com/commitments) & [our process](https://aimultiple.com/methodology) for objectivity.\n",
            "\n",
            "This research is not [funded](https://aimultiple.com/funding) by any sponsors.\n",
            "\n",
            "TABLE OF CONTENTS\n",
            "\n",
            "10+ agentic AI trends and examples\n",
            "\n",
            "1. Towards autonomous, self-healing data pipelines\n",
            "\n",
            "2. Tooling over process\n",
            "\n",
            "3. Vertical AI agents in specialized industries\n",
            "\n",
            "4. Integration of AI agents with the physical world\n",
            "\n",
            "5. Growing shift towards open source models\n",
            "\n",
            "6. Transformative Artificial Intelligence\n",
            "\n",
            "7. AI agent building frameworks\n",
            "\n",
            "8. Combining synthetic and real-world data\n",
            "\n",
            "9. Agentic AI reshaping team roles\n",
            "\n",
            "10. The human element in agentic AI\n",
            "\n",
            "11. Emergence of new AI agent pricing models\n",
            "\n",
            "Agentic AI explained\n",
            "\n",
            "Agentic AI vs generative AI\n",
            "\n",
            "The impact of AI agents on business growth\n",
            "\n",
            "[10+ agentic AI trends and examples](#10-agentic-ai-trends-and-examples)[1. Towards autonomous, self-healing data pipelines](#1-towards-autonomous-self-healing-data-pipelines)[2. Tooling over process](#2-tooling-over-process)[3. Vertical AI agents in specialized industries](#3-vertical-ai-agents-in-specialized-industries)[4. Integration of AI agents with the physical world](#4-integration-of-ai-agents-with-the-physical-world)[5. Growing shift towards open source models](#5-growing-shift-towards-open-source-models)[6. Transformative Artificial Intelligence](#6-transformative-artificial-intelligence)[7. AI agent building frameworks](#7-ai-agent-building-frameworks)[8. Combining synthetic and real-world data](#8-combining-synthetic-and-real-world-data)[9. Agentic AI reshaping team roles](#9-agentic-ai-reshaping-team-roles)[10. The human element in agentic AI](#10-the-human-element-in-agentic-ai)[11. Emergence of new AI agent pricing models](#11-emergence-of-new-ai-agent-pricing-models)[Agentic AI explained](#agentic-ai-explained)[Agentic AI vs generative AI](#agentic-ai-vs-generative-ai)[The impact of AI agents on business growth](#the-impact-of-ai-agents-on-business-growth)\n",
            "\n",
            "Table of contents\n",
            "\n",
            "[10+ agentic AI trends and examples](#10-agentic-ai-trends-and-examples)[1. Towards autonomous, self-healing data pipelines](#1-towards-autonomous-self-healing-data-pipelines)[2. Tooling over process](#2-tooling-over-process)[3. Vertical AI agents in specialized industries](#3-vertical-ai-agents-in-specialized-industries)[4. Integration of AI agents with the physical world](#4-integration-of-ai-agents-with-the-physical-world)[5. Growing shift towards open source models](#5-growing-shift-towards-open-source-models)[6. Transformative Artificial Intelligence](#6-transformative-artificial-intelligence)[7. AI agent building frameworks](#7-ai-agent-building-frameworks)[8. Combining synthetic and real-world data](#8-combining-synthetic-and-real-world-data)[9. Agentic AI reshaping team roles](#9-agentic-ai-reshaping-team-roles)[10. The human element in agentic AI](#10-the-human-element-in-agentic-ai)[11. Emergence of new AI agent pricing models](#11-emergence-of-new-ai-agent-pricing-models)[Agentic AI explained](#agentic-ai-explained)[Agentic AI vs generative AI](#agentic-ai-vs-generative-ai)[The impact of AI agents on business growth](#the-impact-of-ai-agents-on-business-growth)\n",
            "\n",
            "[Agentic AI](/agentic-ai)\n",
            "\n",
            "Updated on **Aug 1, 2025**\n",
            "\n",
            "# 10+ Agentic AI Trends and Examples\n",
            "\n",
            "![Headshot of Cem Dilmegani](https://research.aimultiple.com/wp-content/uploads/2024/07/headshot-of-Cem-Dilmegani-160x160.png.webp)\n",
            "\n",
            "[Cem Dilmegani](/author/cem-dilmegani/)\n",
            "\n",
            "with  Mert Palazoğlu\n",
            "\n",
            "![Mail](/images/mail-article.svg)[![Linkedin](/images/linkedin-article.svg)](https://www.linkedin.com/sharing/share-offsite/?url=https://aimultiple.com/agentic-ai-trends/)[![X](/images/x-article.svg)](https://x.com/share?url=https://aimultiple.com/agentic-ai-trends/)\n",
            "\n",
            "See our [ethical norms](https://aimultiple.com/commitments)\n",
            "\n",
            "xml encoding=\"UTF-8\"\n",
            "\n",
            "The future of [agentic AI](https://research.aimultiple.com/agentic-ai/) isn’t just about improving tools or streamlining business workflows. It’s about integrating AI deeply and transforming business approaches by restructuring current frameworks.\n",
            "\n",
            "Key takeaways:\n",
            "\n",
            "* Agentic systems evolve to handle complex, **unpredictable real-world operations** instead of relying on structured data.\n",
            "* Agentic AI shifts from being a tool to a **co-worker** in decision-making.\n",
            "* As AI agents become more integrated into business operations, **new [agent pricing](https://research.aimultiple.com/ai-agent-pricing/) models** based on task completion or hourly rates (e.g., AI nurses) are emerging.\n",
            "\n",
            "## 10+ agentic AI trends and examples\n",
            "\n",
            "Updated at 05-27-2025\n",
            "\n",
            "| # | Agentic AI trend | Example(s) |\n",
            "| --- | --- | --- |\n",
            "| 1 | **[Towards autonomous, self-healing data pipelines](#1-towards-autonomous-self-healing-data-pipelines)** | • Monte Carlo: Data observability.   • PraisonAI: Autonomous MLOps pipelines. |\n",
            "| 2 | **[Tooling over process](#2-tooling-over-process)** | • Automation without deep expertise. |\n",
            "| 3 | **[Vertical AI agents in specialized industries](#3-vertical-ai-agents-in-specialized-industries)** | • Customer service: Automated query handling.   • Healthcare: Medical coding & scheduling.   • Developers: Code suggestions & debugging.   • QA testers: Automated testing. |\n",
            "| 4 | **[Integration of AI agents with the physical world](#4-integration-of-ai-agents-with-the-physical-world)** | • NVIDIA & GE Healthcare: Diagnostic imaging with AI agents. |\n",
            "| 5 | **[Growing shift towards open source models](#5-growing-shift-towards-open-source-models)** | • Open-source models: Anthropic and Mistral |\n",
            "| 6 | **[Transformative Artificial Intelligence](#6-transformative-artificial-intelligence)** | • Waymo: Autonomous cars.   • Amazon Robotics: Warehouse robots.   • DeepMind’s MedPaLM: Healthcare diagnostic agents. |\n",
            "| 7 | **[AI agent building frameworks](#7-ai-agent-building-frameworks)** | • CrewAI: Workflow management.   • Camel: Workflow automation.   • AutoGen: Data & content automation.   • LangChain: NLP automation. |\n",
            "| 8 | **[Combining synthetic and real-world data](#8-combining-synthetic-and-real-world-data)** | • Waymo: Synthetic data simulation to detect rare events.   • NVIDIA: Robotic training with synthetic environments. |\n",
            "| 9 | **[Agentic AI reshaping team roles](#9-agentic-ai-reshaping-team-roles)** | • AI automation: Engineers scale systems, analysts manage workflows. |\n",
            "| 10 | **[The human element in agentic AI](#10-the-human-element-in-agentic-ai)** | • Human-AI collaboration: Teams co-working with AI to boost productivity. |\n",
            "| 11 | **[Emergence of new AI agent pricing models](#11-emergence-of-new-ai-agent-pricing-models)** | • Hippocratic AI: Agentic nurses at $10/hour. |\n",
            "\n",
            "## 1. Towards autonomous, self-healing data pipelines\n",
            "\n",
            "As organizations scale their AI and analytics initiatives, maintaining **high data quality** across pipelines becomes increasingly complex. Traditional approaches like adding manual checks, patching pipelines reactively, or scaling data engineering teams may become difficult to scale.\n",
            "\n",
            "Instead of relying on human-driven monitoring and repairs, future data pipelines will be embedded with **AI agents with reinforcement learning and modular architectures** that can:\n",
            "\n",
            "* **Monitor pipeline health and identify problems early,** using observability and metadata.\n",
            "* **Diagnose root causes** (e.g., schema drift, missing data, delayed upstream feeds).\n",
            "* **Autonomously repair** issues (e.g., roll back to last good configuration, re-ingest failed batches, or dynamically adjust transformations).\n",
            "\n",
            "**Real-world examples**:\n",
            "\n",
            "* Companies like **Monte Carlo** are developing “data observability” platforms to give AI agents a full view of how the pipeline works.[1](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-1-1431321 \"https://www.montecarlodata.com/blog-monte-carlo-observability-agents\")\n",
            "* **Enhancing CI/CD Pipelines with agentic AI:** Research into **autonomous** [**MLOps**](https://research.aimultiple.com/mlops-/) **pipelines** (e.g., self-healing feature stores) is accelerating.[2](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-2-1431322 \"https://www.marktechpost.com/2025/04/27/building-fully-autonomous-data-analysis-pipelines-with-the-praisonai-agent-framework-a-coding-implementation/\")\n",
            "\n",
            "## 2. Tooling over process\n",
            "\n",
            "The traditional debate of “process vs. tooling” is becoming less relevant with the rise of agentic AI.\n",
            "\n",
            "While strong processes are still important, agentic AI tools, which autonomously plan, decide, and execute multi-step tasks, are starting to **replace** the need for complex process design in some areas.\n",
            "\n",
            "* **Self-directed agents** can automate workflows end-to-end without requiring users to manually manage every step.\n",
            "* **Non-technical users** can now deploy automations (e.g., data pipeline management, cybersecurity threat hunting) without deep expertise.\n",
            "\n",
            "In effect, agentic tools are shifting the conversation: instead of optimizing the process around human teams, the tools become the new operational model.\n",
            "\n",
            "Over the next years, enterprises may shift away from isolated tools toward full-process, operationalized agentic AI solutions.\n",
            "\n",
            "## 3. Vertical AI agents in specialized industries\n",
            "\n",
            "There is a shift from general-purpose foundation models (like ChatGPT) to more specialized [AI agents](https://research.aimultiple.com/ai-agent-tools/) (like Cursor AI code editor). This shift towards narrow agents is built for specific roles and offers key advantages to streamline business operations, including:\n",
            "\n",
            "* Higher accuracy in industry-specific tasks.\n",
            "* Improved efficiency through automation of domain-specific workflows.\n",
            "* Deep integration into business systems for tailored solutions.\n",
            "\n",
            "**Examples of vertical AI agents:**\n",
            "\n",
            "* [**AI agents in customer service**](https://research.aimultiple.com/ai-agents-customer-service/)**:** Respond to queries in natural language, interpret context, and generate human-like responses.\n",
            "* [**AI agents in healthcare**](https://research.aimultiple.com/agentic-ai-healthcare/)**:** Automate healthcare processes, execute several business tasks such as medical coding, appointment scheduling, and office administration.\n",
            "* [**AI agents as developers**](https://research.aimultiple.com/agentic-ai/#1-ai-agents-as-developers)**:** Automate code suggestions, debugging, and software testing.\n",
            "* [**AI agents**](https://research.aimultiple.com/ai-agents/#tool-use-benchmark-results) **as computer users:** Automate everyday tasks like reminders and security monitoring.\n",
            "* **AI QA testers:** Automated software testing systems.\n",
            "\n",
            "## 4. Integration of AI agents with the physical world\n",
            "\n",
            "**AI agents** increasingly integrate more deeply with [**Internet of Things (IoT)**](https://research.aimultiple.com/iot-applications/) **devices and the physical world**. Applications span various environments, including smart homes, offices, and cities, where AI agents autonomously control devices.\n",
            "\n",
            "**Real world example:**\n",
            "\n",
            "Tech companies like **NVIDIA** and **GE HealthCare** are already working together on **agentic robotic systems** like **X-ray** and **ultrasound** technologies, where AI agents use medical imaging to interact with the physical world.[3](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-3-1431323 \"https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai\")\n",
            "\n",
            "## 5. Growing shift towards open source models\n",
            "\n",
            "For years, proprietary AI models controlled by a few large tech companies dominated the landscape. But this is quickly changing with open source models like **Anthropic** and **Mistral.**\n",
            "\n",
            "* For **B2B (business-to-business)** companies, **open-source models** are favored due to their lower operational costs. This is especially true for smaller models that are often sufficient for specific, well-defined tasks. Companies can fine-tune AI models in-house, reducing reliance on costly third-party APIs.\n",
            "* For developers, **smaller, open-source models** can be fine-tuned to specific business functions or domains,\n",
            "\n",
            "**Proprietary models response:** OpenAI strives to make its models more accessible. Models like ChatGPT have already cut prices by roughly **50%**. They charge us around $5 per million tokens for inputs and $10 per million tokens for outputs. Onboarding a product used to cost us 50 cents.[4](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-4-1431324 \"https://openai.com/api/pricing/\")\n",
            "\n",
            "## 6. Transformative Artificial Intelligence\n",
            "\n",
            "Unlike narrow AI, which focuses on static tasks, Transformative Artificial Intelligence (TAI) leverages [agentic](https://research.aimultiple.com/agentic-ai/) capabilities to drive **adaptive, high-impact change** at scale.\n",
            "\n",
            "Transformative Artificial Intelligence (TAI) systems can:\n",
            "\n",
            "* **Understand and deconstruct complex goals**, even under uncertainty.\n",
            "* **Use external tools and APIs** to take actions in dynamic environments.\n",
            "* **Adapt strategies over time**, learning from feedback and context.\n",
            "* **Coordinate with humans and other agents** to achieve long-term objectives.\n",
            "\n",
            "**Real-world examples:**\n",
            "\n",
            "* **Autonomous vehicles** (e.g., Waymo, Tesla FSD)\n",
            "* **Warehouse robots** (e.g., Amazon Robotics)\n",
            "* **Healthcare diagnostic agents** (e.g., Google DeepMind’s MedPaLM)\n",
            "\n",
            "## 7. AI agent building frameworks\n",
            "\n",
            "We have seen the rise of many [AI agent building frameworks](https://research.aimultiple.com/ai-agent-builders/) like **OpenAI Swarm, LangGraph, Microsoft Autogen, CrewAI, Vertex AI,** and **Langflow**. The frameworks offer pre-packaged tools and templates that enable the development of AI agents tailored for various use cases.\n",
            "\n",
            "| AI agent builder | | Specialization |\n",
            "| --- | --- | --- |\n",
            "| 1. | ![CrewAI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/4f91e65b-9c79-4bff-9bbb-46bc87c4b4ee.png) [CrewAI](#crewai) | Workflow management |\n",
            "| 2. | ![Camel logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/56616e31-1ac5-4205-9aba-33215c165941.png) [Camel](#camel) | Workflow management |\n",
            "| 3. | ![AutoGen logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/db438390-0d16-401b-a5b8-bae2461ce536.png) [AutoGen](#autogen) | Data and content automation |\n",
            "| 4. | ![ChatDev logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/f96f59cc-0f42-4c9c-809e-5c3d44afa691.png) [ChatDev](#chatdev) | Collaboration |\n",
            "| 5. | ![LangChain logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/abf2b36f-2c6e-46f9-9cb5-5ef26b1e108a.png) [LangChain](#langchain) | NLP task automation |\n",
            "| Show More (6) |\n",
            "| 6. | ![Copilot Studio logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/b95892ff-8598-4ec5-a605-d28d9c684fd1.png) [Copilot Studio](#copilot-studio) | Workflow management |\n",
            "| 7. | ![Vertex AI Builder logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/e6ff0732-89b8-40c5-bc68-3891db0fb4c3.png) [Vertex AI Builder](#vertex-ai-builder) | Workflow management |\n",
            "| 8. | ![Beam AI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/8a617d69-4aee-412d-9500-1b29b751d6d5.png) [Beam AI](#beam-ai) | Model training |\n",
            "| 9. | ![Lindy logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/a3c5bbc5-4a05-4646-bb29-038140cfa0f2.png) [Lindy](#lindy) | General-purpose |\n",
            "| 10. | ![Bricklayer AI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/fe7510f9-c5cb-491b-9637-38902b8d1ea0.webp) [Bricklayer AI](#bricklayer-ai) | Incident response |\n",
            "| 11. | ![Vonage AI Studio logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/0a6ad7b4-f6ab-4c85-8a87-0e5ffdd62f14.png) [Vonage AI Studio](#vonage-ai-studio) | NLP task automation |\n",
            "\n",
            "1.\n",
            "\n",
            "![CrewAI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/4f91e65b-9c79-4bff-9bbb-46bc87c4b4ee.png)\n",
            "\n",
            "[CrewAI](#crewai)\n",
            "\n",
            "Workflow management\n",
            "\n",
            "2.\n",
            "\n",
            "![Camel logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/56616e31-1ac5-4205-9aba-33215c165941.png)\n",
            "\n",
            "[Camel](#camel)\n",
            "\n",
            "Workflow management\n",
            "\n",
            "3.\n",
            "\n",
            "![AutoGen logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/db438390-0d16-401b-a5b8-bae2461ce536.png)\n",
            "\n",
            "[AutoGen](#autogen)\n",
            "\n",
            "Data and content automation\n",
            "\n",
            "4.\n",
            "\n",
            "![ChatDev logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/f96f59cc-0f42-4c9c-809e-5c3d44afa691.png)\n",
            "\n",
            "[ChatDev](#chatdev)\n",
            "\n",
            "Collaboration\n",
            "\n",
            "5.\n",
            "\n",
            "![LangChain logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/abf2b36f-2c6e-46f9-9cb5-5ef26b1e108a.png)\n",
            "\n",
            "[LangChain](#langchain)\n",
            "\n",
            "NLP task automation\n",
            "\n",
            "Show More (6)\n",
            "\n",
            "6.\n",
            "\n",
            "![Copilot Studio logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/b95892ff-8598-4ec5-a605-d28d9c684fd1.png)\n",
            "\n",
            "[Copilot Studio](#copilot-studio)\n",
            "\n",
            "Workflow management\n",
            "\n",
            "7.\n",
            "\n",
            "![Vertex AI Builder logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/e6ff0732-89b8-40c5-bc68-3891db0fb4c3.png)\n",
            "\n",
            "[Vertex AI Builder](#vertex-ai-builder)\n",
            "\n",
            "Workflow management\n",
            "\n",
            "8.\n",
            "\n",
            "![Beam AI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/8a617d69-4aee-412d-9500-1b29b751d6d5.png)\n",
            "\n",
            "[Beam AI](#beam-ai)\n",
            "\n",
            "Model training\n",
            "\n",
            "9.\n",
            "\n",
            "![Lindy logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/a3c5bbc5-4a05-4646-bb29-038140cfa0f2.png)\n",
            "\n",
            "[Lindy](#lindy)\n",
            "\n",
            "General-purpose\n",
            "\n",
            "10.\n",
            "\n",
            "![Bricklayer AI logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/fe7510f9-c5cb-491b-9637-38902b8d1ea0.webp)\n",
            "\n",
            "[Bricklayer AI](#bricklayer-ai)\n",
            "\n",
            "Incident response\n",
            "\n",
            "11.\n",
            "\n",
            "![Vonage AI Studio logo](https://cdn.aimultiple.com/cdn-cgi/image/width=100,quality=100,format=webp/media/0a6ad7b4-f6ab-4c85-8a87-0e5ffdd62f14.png)\n",
            "\n",
            "[Vonage AI Studio](#vonage-ai-studio)\n",
            "\n",
            "NLP task automation\n",
            "\n",
            "AI agent building frameworks enabled users to expand their use cases by allowing:\n",
            "\n",
            "* **LLM integration**: Selecting[LLMs](https://research.aimultiple.com/large-language-models-examples/) like OpenAI, Anthropic, or Mistral to create specialized agents for your needs.\n",
            "* **Knowledge base integration**: Integrate custom documents (json, PDFs, websites) for improved accuracy and relevance.\n",
            "* **Built-in memory management**: Automatically track conversation histories for personalized interactions.\n",
            "* **Custom tool integration**: Allow agents to perform tasks like payments, web searches, and API calls.\n",
            "\n",
            "## 8. Combining synthetic and real-world data\n",
            "\n",
            "Companies are increasingly combining synthetic and real-world data to train their AI models effectively.\n",
            "\n",
            "While real-world data offers valuable insights, it often faces limitations such as scarcity, privacy concerns, and inherent biases. Synthetic data, however, provides a controlled environment where AI can be trained on diverse scenarios.\n",
            "\n",
            "**Real-world examples**:\n",
            "\n",
            "* Companies like **Waymo** use synthetic data to simulate these rare events, which are then integrated with real-world driving data to train their AI models.[5](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-5-1431325 \"https://waymo.com/research/surfelgan-synthesizing-realistic-sensor-data-for-autonomous-driving/\")\n",
            "* **NVIDIA** creates synthetic environments to train robotic agents for physical-world tasks like factory automation and autonomous surgery assistance.[6](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-6-1431326 \"https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai\")\n",
            "\n",
            "## 9. Agentic AI reshaping team roles\n",
            "\n",
            "Agentic AI redefines how responsibilities are distributed between analysts and engineers. Teams are taking on expanded responsibilities. Analysts are being empowered to build and manage pipelines, while engineers increasingly automate core workflows.\n",
            "\n",
            "Two major forces are driving this shift:\n",
            "\n",
            "* **Advances in AI-enabled pipeline automation:** Agentic systems can autonomously handle multi-step workflows such as data ingestion, validation, and incident detection. As automation advances, engineers can manage larger systems with fewer resources, while analysts independently maintain workflows.\n",
            "* **Increased demand for AI and data products:** As business leaders seek faster and broader access to data, teams are expected to do more with fewer resources. Analysts are taking more technical tasks, while engineers focus on scaling and automating infrastructure.\n",
            "\n",
            "## 10. The human element in agentic AI\n",
            "\n",
            "The true success of **agentic AI** depends largely on how well humans can **integrate and use these systems**.\n",
            "\n",
            "**Key points:**\n",
            "\n",
            "* **Human-AI collaboration**: The effectiveness of agentic AI will rely on how effectively **teams** can collaborate with AI agents, using them as **co-workers**.\n",
            "* **Cultural shift**: Adopting agentic AI will require a significant shift in **organizational culture**, focusing not just on technology adoption but also on allowing people to work alongside AI to reach new heights of productivity.\n",
            "\n",
            "## 11. Emergence of new AI agent pricing models\n",
            "\n",
            "The adoption of digital **co-workers** might reshape how businesses value tasks traditionally performed by humans.\n",
            "\n",
            "This transition is driving the rise of agentic business models that favor salary-based compensation over conventional software licensing structures.\n",
            "\n",
            "**Real world example:**\n",
            "\n",
            "Hippocratic AI’s agentic nurses, which are priced at $10 per hour, are lower than the median hourly wage of **~$43** for human registered nurses.[7](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-7-1431327 \"https://www.hippocraticai.com/ai-agent-app-store#:~:text=The%20base%20rate%20is%20typically,is%20entirely%20up%20to%20you.\") [8](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-8-1431328 \"https://www.indeed.com/career/registered-nurse/salaries\")\n",
            "\n",
            "**For more:** [AI agent pricing](https://research.aimultiple.com/ai-agent-pricing/).\n",
            "\n",
            "## Agentic AI explained\n",
            "\n",
            "Agentic AI refers to AI systems capable of acting autonomously, adapting in real-time, and solving complex multi-step problems based on context and objectives.\n",
            "\n",
            "It combines multiple AI agents, leveraging large language models (LLMs) and reasoning capabilities.\n",
            "\n",
            "**Key features:**\n",
            "\n",
            "* **Autonomous decision-making**: Acts independently with minimal human intervention.\n",
            "* **Real-time adaptation**: Adjusts to changing circumstances and evolving situations.\n",
            "* **Multi-agent collaboration**: Multiple agents work together to solve complex problems.\n",
            "* **Reasoning**: Uses reasoning and natural language understanding to process and respond to challenges.\n",
            "\n",
            "**Read more:** [Levels of agentic systems](https://research.aimultiple.com/ai-agent-tools/#levels-of-agentic-ai-systems).\n",
            "\n",
            "## Agentic AI vs generative AI\n",
            "\n",
            "[**Generative AI**](https://research.aimultiple.com/generative-ai-applications/) generates content (text, images, etc.) based on input data or prompts.. It uses deep learning models that mimic the human brain’s learning and decision-making processes.\n",
            "\n",
            "By analyzing large datasets, these models identify patterns and generate content in response to natural language requests, relying on technologies like [robotic process automation (RPA)](https://research.aimultiple.com/robotic-process-automation-use-cases/).\n",
            "\n",
            "[**Agentic AI**](https://research.aimultiple.com/agentic-ai/) refers to AI systems that autonomously make decisions and act towards achieving complex goals with minimal supervision. It combines the flexibility of [large language models (LLMs)](https://research.aimultiple.com/large-language-models/) with the precision of traditional programming.\n",
            "\n",
            "Unlike generative AI, which is reactive to input, agentic AI proactively adapts to situations and makes context-based decisions. It’s used in applications like robotics, complex analysis, and virtual assistants.\n",
            "\n",
            "Updated at 04-30-2025\n",
            "\n",
            "| Feature | Agentic AI | Generative AI |\n",
            "| --- | --- | --- |\n",
            "| Primary function | Goal-oriented action & decision-making | Content generation (text, code, images, etc.) |\n",
            "| Autonomy | High – Operates with minimal human oversight | Variable – May require user prompts or guidance |\n",
            "| Learning | Reinforced Learning – Improves through experience | Data-driven learning – Learns from existing data |\n",
            "| Task complexity | High – Solves complex, multi-step problems | Moderate – Generates content but doesn’t handle complex tasks autonomously |\n",
            "\n",
            "## The impact of AI agents on business growth\n",
            "\n",
            "Capgemini claims that ~80% of surveyed organizations plan to integrate AI agents within 1-3 years for tasks like email generation, coding, and data analysis. [9](https://research.aimultiple.com/agentic-ai-trends/#easy-footnote-bottom-9-1431329 \"https://www.capgemini.com/us-en/insights/research-library/generative-ai-in-organizations-2024/\")\n",
            "\n",
            "However, the true impact will come from orchestrating these agents to complete not only individual tasks but also **entire software development lifecycles**.\n",
            "\n",
            "Companies could deploy specialized agents for code generation or automated testing, all working together and adjusting in real-time based on human feedback.\n",
            "\n",
            "**More generally,  AI agents can simplify the automation of complex use cases in four ways:**\n",
            "\n",
            "* **Adaptability to unpredictable scenarios:** Unlike deterministic rule-based systems that fail when faced with unexpected conditions, AI agents trained on large datasets can respond flexibly to unforeseen situations.\n",
            "* **Use of natural language for workflow automation:** Agentic tools allow users to design and modify workflows using natural language instructions.\n",
            "* **Autonomous integration with existing systems:** Since agentic tools are built on foundation models, AI agents can autonomously interact with software platforms and tools.\n",
            "* **Continuous learning and improvement:** Agentic tools can continually learn from interactions and feedback, improving their performance without needing extensive manual retraining.\n",
            "\n",
            "Further reading\n",
            "\n",
            "* [Compare 20 LLM Security Tools & Open-Source Frameworks](https://research.aimultiple.com/llm-security-tools/)\n",
            "* [What are the Top 10 LLM Security Risks](https://research.aimultiple.com/llm-security/)\n",
            "* [Open-source AI Agents](https://research.aimultiple.com/open-source-ai-agents/)\n",
            "* [Compare 50+ AI Agent Tools](https://research.aimultiple.com/ai-agent-tools/)\n",
            "\n",
            "### External Links\n",
            "\n",
            "* 1. [Monte Carlo Launches Observability Agents To Accelerate Data + AI Monitoring And Troubleshooting.](https://www.montecarlodata.com/blog-monte-carlo-observability-agents)\n",
            "* 2. [Building Fully Autonomous Data Analysis Pipelines with the PraisonAI Agent Framework: A Coding Implementation - MarkTechPost.](https://www.marktechpost.com/2025/04/27/building-fully-autonomous-data-analysis-pipelines-with-the-praisonai-agent-framework-a-coding-implementation/) *MarkTechPost AI Media Inc*\n",
            "* 3. [NVIDIA and GE HealthCare Collaborate to Advance the Development of Autonomous Diagnostic Imaging With Physical AI | NVIDIA Newsroom.](https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai)\n",
            "* 4. [Pricing | OpenAI.](https://openai.com/api/pricing/)\n",
            "* 5. [SurfelGAN: Synthesizing Realistic Sensor Data for Autonomous Driving.](https://waymo.com/research/surfelgan-synthesizing-realistic-sensor-data-for-autonomous-driving/)\n",
            "* 6. [NVIDIA and GE HealthCare Collaborate to Advance the Development of Autonomous Diagnostic Imaging With Physical AI | NVIDIA Newsroom.](https://nvidianews.nvidia.com/news/nvidia-and-ge-healthcare-collaborate-to-advance-the-development-of-autonomous-diagnostic-imaging-with-physical-ai)\n",
            "* 7. [AI Agent App Store — Hippocratic AI.](https://www.hippocraticai.com/ai-agent-app-store#:~:text=The%20base%20rate%20is%20typically,is%20entirely%20up%20to%20you.)\n",
            "* 8. [Security Check - Indeed.com.](https://www.indeed.com/career/registered-nurse/salaries)\n",
            "* 9. [Generative AI in organizations 2024 - Capgemini USA.](https://www.capgemini.com/us-en/insights/research-library/generative-ai-in-organizations-2024/)\n",
            "\n",
            "Share This Article\n",
            "\n",
            "![Mail](/images/mail-article.svg)[![Linkedin](/images/linkedin-article.svg)](https://www.linkedin.com/sharing/share-offsite/?url=https://aimultiple.com/agentic-ai-trends/)[![X](/images/x-article.svg)](https://x.com/share?url=https://aimultiple.com/agentic-ai-trends/)\n",
            "\n",
            "[![Headshot of Cem Dilmegani](https://research.aimultiple.com/wp-content/uploads/2024/07/headshot-of-Cem-Dilmegani-160x160.png.webp)](/author/cem-dilmegani/)\n",
            "\n",
            "[Follow on](https://www.linkedin.com/in/cem-dilmegani/)\n",
            "\n",
            "Cem has been the principal analyst at AIMultiple since 2017. AIMultiple informs hundreds of thousands of businesses (as per similarWeb) including 55% of Fortune 500 every month.\n",
            "\n",
            "[Follow on](https://www.linkedin.com/in/cem-dilmegani/)\n",
            "\n",
            "Researched by\n",
            "\n",
            "[![Headshot of Mert Palazoğlu](https://research.aimultiple.com/wp-content/uploads/2024/07/mert-150x150.png.webp)](/author/mert-palazoglu/)\n",
            "\n",
            "Mert Palazoglu is an industry analyst at AIMultiple focused on customer service and network security with a few years of experience. He holds a bachelor's degree in management.\n",
            "\n",
            "### Next to Read\n",
            "\n",
            "### [Agentic AI Architecture for Industrial Systems](/industrial-agentic-ai/)\n",
            "\n",
            "Sep 124 min read\n",
            "\n",
            "### [Agentic Mesh: The Future of Scalable AI Collaboration](/agentic-mesh/)\n",
            "\n",
            "Sep 96 min read\n",
            "\n",
            "### [Optimizing Agentic Coding: How I use Claude Code](/agentic-coding/)\n",
            "\n",
            "Aug 237 min read\n",
            "\n",
            "### Comments\n",
            "\n",
            "Your email address will not be published. All fields are required.\n",
            "\n",
            "0 Comments\n",
            "\n",
            "Post Comment\n",
            "\n",
            "## Related research\n",
            "\n",
            "[![](https://research.aimultiple.com/wp-content/uploads/feauture-image.svg)](/industrial-agentic-ai/)\n",
            "\n",
            "### [Agentic AI Architecture for Industrial Systems](/industrial-agentic-ai/)\n",
            "\n",
            "Sep 124 min read\n",
            "\n",
            "[![](https://research.aimultiple.com/wp-content/uploads/feauture-image.svg)](/agentic-ai-stack/)\n",
            "\n",
            "### [The 7 Layers of Agentic AI Stack](/agentic-ai-stack/)\n",
            "\n",
            "Sep 95 min read\n",
            "\n",
            "![AIMultiple](/images/aimultiple-logo.svg)\n",
            "\n",
            "AIMultiple[About](https://aimultiple.com/about)[Career](https://www.linkedin.com/company/aimultiple/jobs/)[Commitments](https://aimultiple.com/commitments)[Contact](https://aimultiple.com/contact-us)[Culture](https://aimultiple.com/culture)[How we are funded](https://aimultiple.com/funding)[How we test](https://aimultiple.com/how-we-test)[Methodology](https://aimultiple.com/methodology)[Services](https://aimultiple.com/services)\n",
            "\n",
            "Follow us on:\n",
            "\n",
            "AI[Agentic AI Frameworks](https://aimultiple.com/agentic-ai-frameworks)[AI Agents](https://research.aimultiple.com/category/ai-agents/)[AI Coding](https://aimultiple.com/ai-coding)[AI Foundations](https://research.aimultiple.com/category/ai-foundations/)[AI Hardware](https://aimultiple.com/ai-hardware)[AI in Industries](https://research.aimultiple.com/category/ai-in-industries/)[AI Models](https://aimultiple.com/ai-models)[AI Memory](https://research.aimultiple.com/category/ai-memory/)[Computer Vision](https://research.aimultiple.com/category/computer-vision/) [Document Automation](https://aimultiple.com/document-automation)[GenAI Applications](https://research.aimultiple.com/category/genai-applications/)[MCP Servers](https://aimultiple.com/mcp-servers)[Large Language Models](https://aimultiple.com/llm)[Retrieval Augmented Generation](https://aimultiple.com/rag)\n",
            "\n",
            "Data[Analytics](https://research.aimultiple.com/category/analytics/)[Data Collection](https://research.aimultiple.com/category/data-collection/)[Data Science](https://research.aimultiple.com/category/data-science/)[Data Quality](https://research.aimultiple.com/category/data-quality/)[Machine Learning Operations](https://research.aimultiple.com/category/mlops/)[Proxy Comparisons](https://research.aimultiple.com/category/proxy-comparisons/)[Proxy Types](https://research.aimultiple.com/category/proxy-types/)[Scraping Tools](https://research.aimultiple.com/category/scraping-tools/)[Survey Reviews](https://research.aimultiple.com/category/survey-reviews/)[Synthetic Data](https://research.aimultiple.com/category/synthetic-data/)[Web Data Scraping](https://research.aimultiple.com/category/web-data-scraping/)[Web Proxies](https://research.aimultiple.com/category/web-proxies/)\n",
            "\n",
            "Enterprise Software[Cloud Computing](https://research.aimultiple.com/category/cloud-computing/)[Communication](https://research.aimultiple.com/category/communication/)[Customer Relationship Management](https://research.aimultiple.com/category/crm/)[E-Commerce](https://research.aimultiple.com/category/e-commerce/)[Extended Reality](https://research.aimultiple.com/category/extended-reality/)[Industry Software](https://research.aimultiple.com/category/industry-software/)[Internet of Things](https://research.aimultiple.com/category/iot/)[Managed File Transfer](https://research.aimultiple.com/category/managed-file-transfer/)[Process Improvement](https://research.aimultiple.com/category/process-improvement/)[Robotic Process Automation](https://research.aimultiple.com/category/rpa/)[Sustainability](https://research.aimultiple.com/category/sustainability/)[Workload Automation](https://research.aimultiple.com/category/workload-automation/)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}